{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 개요\n",
    "> **Agent는 대형 언어 모델을 두뇌로 사용하여, 목표를 스스로 이해하고 외부 도구와 상호작용하며 실제 작업을 자율적으로 수행하는 지능형 인공지능 시스템이다.**\n",
    "\n",
    "- Agent는 **대형 언어 모델(LLM, Large Language Model)과 다양한 도구(Tool)를 결합하여, 사용자의 복잡한 요청을 스스로 분석하고 처리하도록 설계된 지능형 인공지능 시스템이다.**\n",
    "기존의 단순한 챗봇이 “질문 → 답변” 구조로 동작한다면, \n",
    "  - Agent는 **목표 설정 → 판단 → 실행 → 결과 반영**의 전 과정을 스스로 수행하는 구조를 가진다.\n",
    "\n",
    "- Agent는 주어진 목표를 달성하기 위해 자율적으로 **외부 환경(도구, API, 데이터베이스, 파일 시스템 등)과 상호작용하며 의사 결정을 내리고 실제 행동을 수행한다.**\n",
    "이때 Agent의 **핵심적인 의사 결정과 추론 과정은 대형 언어 모델(LLM)이 담당**하며, **사람의 개입은 최소화**한다.\n",
    "\n",
    "- 즉, Agent는 단순히 정보를 말해주는 존재가 아니라, **\"문제를 이해하고, 해결 방법을 계획하고, 직접 실행까지 담당하는 인공지능 작업 수행자\"이다.**\n",
    "\n",
    "- AI 시스템을 구현할 때, **워크플로우**(**Workflow**)는 사전에 정의된 절차에 따라 실행 단계가 고정적인 구현 방식이라면, **에이전트**(**Agent**)는 주어진 목표를 달성하기 위해 스스로 계획을 수립하고, 상황을 판단하여 행동을 결정·실행하는 자율적인 방식이다.\n",
    "\n",
    "\n",
    "\n",
    "## Agent의 주요 특징\n",
    "\n",
    "1. **자율성** (Autonomy)\n",
    "   - Agent는 **사전 정의된 규칙**(Rule-based)에 의존하지 않고, LLM을 통해 현재 상황을 인지하고 추론하여 스스로 결정을 내리고 다음 행동을 계획할 수 있다.\n",
    "   - 즉, 사용자가 일일이 수행 단계를 지시하지 않아도, Agent는 **현재 상황을 해석하고 다음 행동을 동적으로 결정한다.**\n",
    "\n",
    "2. **목표 지향성** (Goal-Oriented)\n",
    "    - Agent는 단순히 질문에 답변하는 **단순한 대화 상대가 아니라, 특정 목표와 복잡한 작업을 달성하기 위해 설계된 시스템**으로 최종 목표에 도달할 때 까지 반복적으로 행동한다.\n",
    "    - Agent는 어떤 처리를 할 때 항상 **\"이 행동이 목표 달성에 도움이 되는가\"를 기준**으로 판단한다.\n",
    "\n",
    "3. **도구 활용** (Tool Utilization)\n",
    "    - Agent는 대형 언어 모델의 언어 이해 능력, 사전 학습 정보에만 의존하지 않고, 다양한 **외부 도구와 API를 함께 활용하여 실제 작업을 수행**한다.\n",
    "    - 이를 통해 LLM이 처리할 수없는 **최신 정보 검색, 복잡한 계산, 외부 시스템 제어**등과 같은 작업이 가능하다. 이를 통해 Agent는 **\"말만 하는 AI\"가 아니라 \"실제로 일을 처리하는 AI\"로 기능한다.**\n",
    "\n",
    "4. **인간 개입 최소화** (Human-in-the-loop 최소화)\n",
    "    - Agent는 **문제 분석, 의사 결정, 행동 실행의 대부분을 스스로 결정하고 수행하도록 설계된다.**\n",
    "    - 사람은 **초기 목표 제시, 결과 확인 및 실행 최종 승인** 정도에 만 개입한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다양한 Agent 활용 사례\n",
    "\n",
    "- **미국 국세청(IRS) 세무처리에 도입된 AI 에이전트**\n",
    "    - 미국 국세청(IRS)은 Salesforce Agentforce 기반 AI 에이전트를 도입해 세무 업무에서의 보조·분석 기능을 강화하고 업무 효율을 높이고 있다.\n",
    "\n",
    "-  **고객 추천 및 개인화된 콘텐츠 제공**\n",
    "    - Netflix, Amazon 같은 OTT 플랫폼은 사용자의 취향 변화에 따라 추천 시스템을 적응시키는 학습형 에이전트를 활용해 콘텐츠/제품 추천을 개선해 나간다.\n",
    "\n",
    "- **영업 지원용 AI 에이전트**\n",
    "    - Oracle은 영업 전문가를 위한 AI 에이전트를 도입해 고객 미팅 후 CRM 업데이트, 고객 데이터 분석·보고서 생성 같은 반복 작업을 자동화하고 있다.\n",
    "\n",
    "- **물류 최적화 및 배송 계획**\n",
    "    - Uber Freight, J.B. Hunt 등에서는 AI 에이전트를 활용해 실시간 교통·날씨 데이터 분석을 통해 가장 효율적인 배송 경로를 계산한다.\n",
    "\n",
    "- **AWS의 클라우드 자동화 에이전트**\n",
    "    - Amazon Web Services는 보안, DevOps, 일반 작업을 자동화하는 AI 에이전트들을 출시하며 클라우드 인프라 운영과 보안 모니터링을 강화하고 있다.\n",
    "\n",
    "- **삼성SDS AI 에이전트 플랫폼**\n",
    "    - 삼성SDS는 **사용자 개입 없이 스스로 판단·문제 해결이 가능한 AI 에이전트 플랫폼 ‘패브릭스(Fabrics)’**를 공개했다. 이를 통해 기업 내부에서 자동화된 의사결정과 작업 실행을 지원한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct 패턴\n",
    "- Agent 구현의 바탕이 되는 이론.\n",
    "\n",
    "## 1. 개요\n",
    "\n",
    "ReAct는 **Reasoning**(추론)과 **Acting**(행동)을 결합한 AI Agent의 프롬프팅 패턴이다. 대형 언어 모델(LLM)이 단순히 답변을 생성하는 것이 아니라, 문제를 분석하고(Reasoning)하고 그에 따라 필요한 도구를 선택하여 실행하며(Acting), 결과를 관찰하고(Observation) 다음 추론에 반영하는 과정을 반복하면서 문제를 해결하는  Agent 설계 방식이다.\n",
    "\n",
    "### ReAct의 핵심 개념\n",
    "\n",
    "전통적인 프롬프팅 방식은 질문에 대해 즉시 답변을 생성한다. 하지만 **ReAct 패턴**은 다음과 같은 순환 구조를 따른다:\n",
    "\n",
    "```\n",
    "질문 → 생각(Thought) → 행동(Action) → 관찰(Observation) → 생각 → 행동 →  관찰 → ... → 답변\n",
    "```\n",
    "\n",
    "- 예)\n",
    "  - 질문: \"현재 서울의 날씨와 미세먼지 농도를 알려줘\":\n",
    "\n",
    "    - **Thought(생각)**: 날씨 정보를 얻기 위해 날씨 API를 호출해야겠다\n",
    "    - **Action(행동)**: WeatherAPI.get_weather(\"서울\")\n",
    "    - **Observation(관찰)**: 기온 15도, 맑음\n",
    "    - **Thought(생각)**: 이제 미세먼지 정보도 필요하다\n",
    "    - **Action(행동)**: AirQualityAPI.get_pm(\"서울\")\n",
    "    - **Observation(관찰)**: PM10 농도 20㎍/㎥, 좋음\n",
    "    - **Answer(답변)**: 서울의 현재 날씨는 기온 15도로 맑고, 미세먼지 농도는 30㎍/㎥로 좋은 상태이다\n",
    "\n",
    "이처럼 ReAct는 Agent가 **사고 과정을 명시적으로 드러내면서** 외부 도구를 활용하여 복잡한 문제를 해결할 수 있도록 한다.\n",
    "\n",
    "### ReAct의 장점\n",
    "\n",
    "1. **투명성**: Agent의 사고 과정을 추적할 수 있어 디버깅이 용이하다\n",
    "2. **정확성**: 외부 지식과 도구를 활용하여 환각(hallucination)을 줄인다\n",
    "3. **유연성**: 다양한 도구를 조합하여 복잡한 작업을 수행할 수 있다\n",
    "4. **해석 가능성**: 각 단계의 추론 과정을 이해할 수 있다\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 동작 단계\n",
    "ReAct 패턴은 크게 **5단계**의 순환 구조로 동작한다.\n",
    "\n",
    "1. **질문 입력** (Question)\n",
    "     - 사용자로부터 해결해야 할 질문이나 작업을 입력받는다.\n",
    "     - 예시\n",
    "    ```bash\n",
    "     User Input: \"2024년 노벨 물리학상 수상자는 누구이고, 그들의 주요 업적은 무엇인가?\"\n",
    "    ```\n",
    "\n",
    "2. **사고 단계** (Thought)\n",
    "     - 언어 모델이 사용자의 질문(요청)을 분석하고, 문제 해결을 위해 다음에 무엇을 해야 할지 추론한다.(계획을 세운다.) \n",
    "     - 이 단계에서 Agent는:\n",
    "         - 문제를 이해하고 분해한다\n",
    "         - 필요한 정보가 무엇인지 파악한다\n",
    "         - 어떤 도구를 사용해야 할지 결정한다\n",
    "         - 충분한 정보가 모였는지 판단한다\n",
    "\n",
    "       ```bash\n",
    "       Thought: 2024년 노벨 물리학상 정보는 내 학습 데이터에 없을 수 있다. 최신 정보를 검색해야 한다.\n",
    "       ```\n",
    "\n",
    "3. **행동 단계** (Action)\n",
    "     - 사고 단계에서 결정된 계획을 바탕으로 실제 행동을 실행한다. 행동은 일반적으로 외부 도구(Tool) 호출한다.   \n",
    "\n",
    "        ```bash\n",
    "        Action: 검색엔진.검색(\"2024 노벨 물리학상 수상자\")\n",
    "        ```\n",
    "\n",
    "4. **관찰 단계** (Observation)\n",
    "     - 행동(Acttion)의 결과를 관찰하고 얻은 정보를 확인한다.\n",
    "\n",
    "       ```bash\n",
    "       Observation: 2024년 노벨 물리학상은 John Hopfield와 Geoffrey Hinton에게 수여되었다. \n",
    "       ```\n",
    "\n",
    " 5. **반복 또는 종료**\n",
    "       - 관찰한 정보가 사용자 질문에 대한 답변을 하는데 충분하지 않다면 2번의 사고 단계로 돌아가 추가 행동을 계획한다.(사고→행동→관찰 반복) \n",
    "       - 충분한 정보가 모였다면 그 정보를 바탕으로 최종 답변을 생성한다.\n",
    "\n",
    "          ```bash\n",
    "          Thought: 수상자 이름은 알았지만 구체적인 업적 내용이 필요하다.\n",
    "\n",
    "          Action: Search(\"John Hopfield Geoffrey Hinton 노벨상 업적\")\n",
    "\n",
    "          Observation: Hopfield는 연상 메모리를 위한 Hopfield 네트워크를 개발했고, Hinton은 딥러닝의 역전파 알고리즘과 볼츠만 머신을 연구했다.\n",
    "\n",
    "          Thought: 이제 질문에 답할 충분한 정보가 모였다.\n",
    "\n",
    "          Action: Finish(\"2024년 노벨 물리학상은 John Hopfield와 Geoffrey Hinton에게 수여되었다. Hopfield는 연상 메모리를 위한 Hopfield 네트워크를 개발했고, Hinton은 딥러닝의 역전파 알고리즘과 볼츠만 머신 연구로 인공신경망 발전에 기여했다.\")\n",
    "          ```\n",
    "\n",
    "### 동작 흐름도\n",
    "![ReAct](figures/agent-ReAct.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOOL\n",
    "- **Tool은 하나의 기능을 처리하는 함수이다.**\n",
    "    - Tool은 하나의 명확한 기능을 수행하도록 정의된 함수(Function) 형태의 외부 실행 수단이다.\n",
    "    - 대형 언어 모델(LLM)은 본래 텍스트를 생성하는 모델이므로, 실제 계산, 검색, 파일 처리, 데이터베이스 조회와 같은 현실 세계의 작업을 직접 수행할 수는 없다. 이런 실제 작업을 대신 수행하는 단위가 Tool 이다.\n",
    "- **AI Model은 Tool을 이용해 자체 지식의 한계(Knowlege cutoff)를 넘어서는 정보를 제공할 수 있다.**\n",
    "> **Knowledge Cutoff**:\n",
    "> - Knowledge cutoff는 AI 모델이 학습한 데이터가 마지막으로 업데이트된 시점을 의미하며, 그 이후에 발생한 정보나 사건에 대해서는 AI 모델이 학습한 지식으로는 알지 못하는 한계를 가지게 된다.\n",
    "\n",
    "## Tool Calling 개요\n",
    "- **도구 호출**(Tool Calling)은 LLM이 자체적으로 수행할 수 없는 작업을 외부 도구나 API를 활용하여 처리할 수 있게 하는 핵심 기능이다. 이를 통해 **LLM은 자체 지식의 한계를 넘어서는 최신 정보, 정확한 계산, 외부 시스템 제어 등의 능력을 확보**할 수 있다.\n",
    "\n",
    "- **도구 호출(Tool Calling)의 3단계**\n",
    "    1. 도구 바인딩 (Tool Binding): **LLM에 사용가능한 tool들을 등록한다.** \n",
    "        - LLM에게 사용 가능한 도구 목록과 각 도구의 기능(설명) 및 필요한 입력 매개변수를 미리 정의하여 제공한다.\n",
    "            - Tool 함수\n",
    "            - Tool 이름\n",
    "            - Tool이 수행하는 기능 설명\n",
    "            - 입력 파라미터 type과 설명\n",
    "    2. **사용자 질의가 들어오면 LLM이 도구 사용 여부를 판단**한다.\n",
    "        - LLM 자체 추론으로 해결가능한 문제인지 Tool을 호출해야 처리할 수있는 문제 인지를 확인한다.\n",
    "        - **Tool 사용이 필요한 문제** 라고 판단하면 \n",
    "          - 도구를 호출 하는 것이 아니라 어떻게 호출해야 하는지 요청정보를 생성한다.\n",
    "            - 어떤 Tool을 사용해야 하는지, 그 Tool에 어떤 값을 전달해야하는지를 응답으로 생성한다.\n",
    "    3.  **시스템이 Tool 호출 요청정보에 따라 Tool을 실행하고 그 결과를 LLM 에게 전달**한다.\n",
    "\n",
    "     ![toolcalling_concept](figures/toolcalling_concept.png)\n",
    "\n",
    "- **TOOL Calling 예**\n",
    "    - LLM이 수학 계산을 수행해야 할 때, 직접 계산하는 대신 미리 정의된 '계산' 도구를 호출하여 정확한 결과를 얻을 수 있다.\n",
    "  \t- LLM에 최신 정보를 요청하는 질문이 들어왔을 때 '검색' 도구나 'Database 연동' 도구를 사용해 최신 뉴스를 검색하거나, 특정 데이터베이스에서 정보를 조회하는 등의 작업을 수행할 수 있다.\n",
    "  \t- LLM 이 작성한 결과를 google docs와 같은 문서도구나 SNS에 등록한다.\n",
    "\n",
    "## Langchain 과 Tool calling\n",
    "- Tool calling은 대부분의 LLM 서비스가 지원한다.\n",
    "  - [Tool Calling을 지원하는 LLM 모델](https://docs.langchain.com/oss/python/integrations/chat)만 사용할 수 있다.\n",
    "- LangChain은 다양한 모델들의 도구 호출 방식을 표준화하여 일관된 인터페이스로 제공한다. 이를 통해 개발자들은 다양한 모델과 도구들을 쉽게 통합할 수있다.\n",
    "  - [Langchain Tool Calling Concept](https://docs.langchain.com/oss/python/langchain/tools)\n",
    "- Langchain 제공 Built-in tools\n",
    "    -  https://docs.langchain.com/oss/python/integrations/tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Built-in Tools 사용으로 Tool Calling 이해\n",
    "\n",
    "- Langchain은 다양한 도구들을 미리 구현해서 제공하고 있다. 이것들을 builtin tool이라고 한다. \n",
    "  - [Langchain 지원 Built tools](https://docs.langchain.com/oss/python/integrations/tools)\n",
    "- Built-In tool 뿐만 아니라 사용자 정의 Tool들을 직접 구현할 수있는 방법도 제공한다.\n",
    "\n",
    "## Tavily API 검색 Tool\n",
    "> Tavily 웹 검색 도구 사용해 Tool calling을 이해한다.\n",
    "- **Tavily** Service: AI을 위한 웹 검색 API Service.\n",
    "- https://tavily.com/\n",
    "-  LLM과 RAG 시스템에 최적화된 검색 엔진.\n",
    "   -  기존의 일반 검색 엔진들과 달리, Tavily는 AI 애플리케이션의 요구사항에 맞춰 설계되었다.\n",
    "   -  Tavily는 최대 20개 이상의 신뢰도 높은 웹사이트에서 관련정보를 수집한다. \n",
    "   -  수집된 데이터는 AI가 관련성, 신뢰도, 최신성 등을 기준으로 평가해 가장 적합한 정보만 선별해서 요약한다. \n",
    "   -  최종적으로 이 정보는 LLM이 바로 활용할 수있도록 컨텐츠 스티펫, 요약, 출처 등의 구조화된 형태로 반환한다.\n",
    "   -  월 1000회 무료 사용 가능.\n",
    "- **Tavily API Key 받기**\n",
    "  - 회원가입 후 로그인 한다.\n",
    "  - Overview 화면에서 API Key 생성 \n",
    "    - default API key 사용할 수있다.\n",
    "  - 환경변수에 등록한다.\n",
    "      - 변수이름: `TAVILY_API_KEY`\n",
    "\n",
    "### TavilySearch\n",
    "- Langchain에서 제공하는 tool로 Tavily 의 검색 엔진 API를 사용해 검색을 수행한다.\n",
    "- 설치\n",
    "  - `pip install langchain-tavily`\n",
    "- https://python.langchain.com/docs/integrations/tools/tavily_search/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m41 packages\u001b[0m \u001b[2min 304ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 22ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 23ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-tavily\u001b[0m\u001b[2m==0.2.16\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_tavily import TavilySearch # Tavily 검색 tool\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 생성 - 검색 옵션을 파라미터로 설정.\n",
    "tavily_search = TavilySearch(\n",
    "    max_results=3, # 최대 검색 개수.\n",
    "    # include_raw_content=True, # 원본 내용도 포함.\n",
    "    # include_answer=True,    # 검색 결과를 바탕으로 Tavily AI가 종합적 답변을 하도록 한다.\n",
    "    # include_images=True,    # 검색한 문서내의 이미지(경로)들을 반환\n",
    "    # time_range=\"year\",      # day, week, month, year - 현재 시점 기준으로 지정한 기간내의 문서들만 검색결과로 제공.\n",
    "    \n",
    ")\n",
    "# 검색\n",
    "query = \"2025년 한국시리즈 우승팀은?\"\n",
    "# result = tavily_search.invoke(query)\n",
    "result = tavily_search.invoke(\n",
    "    {\n",
    "        \"query\":query,\n",
    "        \"include_images\": True # 옵션들을 key:value 로 설정해서 실행시 동적으로 설정.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': '2025년 한국시리즈 우승팀은?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': ['https://blogthumb.pstatic.net/MjAyNTAzMjNfNjYg/MDAxNzQyNzE4ODAxNzkw.oSUS641rn-u5mmRK9X90k3cOu6mV_S-lXEroFC41xc0g.ifwCdPWPHpTasTUsv1lLbaYgl6z8MXOE4Ezbpu0y2WUg.PNG/������-�Է����ּ���__���纻-_27_-001.png?type=w2',\n",
       "  'https://www.sportschosun.com/article/html/2025/10/22/2025102301001362100180743_w.jpg',\n",
       "  'https://img.etoday.co.kr/pto_db/2024/10/20241029063224_2094589_999_567.jpg',\n",
       "  'https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhIwYdP22bQ2HL4mmF0rsT9O2cpYw8iRkBY4AkpbjujNUkhyphenhyphen-k1BICpkEpj1u1EejbsLIaOld7q40ZSmna-vLCXKj1XNTr8rRHDAB1QhsT-BNRjZkZGPzqPDGc501RlSJyXAx7_HJX2KDCcpZtRWBiUFWbOy6x-MVWIYlHTxsNi6iKnX7ZMjJzvPu6q38jK/s1024/ChatGPT+Image+2025년+10월+11일+오전+11_20_52.png',\n",
       "  'https://blog.kakaocdn.net/dn/boRtrn/btsMgUfWOwB/t7Xx4EoLVFU5OrsilmFCmK/img.jpg'],\n",
       " 'results': [{'url': 'https://ko.wikipedia.org/wiki/2025%EB%85%84_%ED%95%9C%EA%B5%AD%EC%8B%9C%EB%A6%AC%EC%A6%88',\n",
       "   'title': '2025년 한국시리즈',\n",
       "   'content': '| 10월 30일(목) | 4차전 | **LG 트윈스** | **7** - 4 | 한화 이글스 | 16,750명 **(매진)** | 김현수 \"김현수 (1988년생 야구 선수)\") (LG 트윈스) |. | 우승\\xa0: LG 트윈스 (4번째), 한국시리즈 MVP\\xa0: 김현수 \"김현수 (1988년생 야구 선수)\") (LG 트윈스) |. 한화가 6회초 1사 2루 상황에서 노시환의 적시타에 이어서 1사 1, 3루 상황에서 하주석의 희생플라이로 2점 추격을 해봤으나 LG는 6회말 공격 1사 만루 상황에서 신민재 \"신민재 (1996년)\")의 2타점 적시타, 2사 1, 2루에서 김현수 \"김현수 (1988년생 야구 선수)\")와 문보경의 연속 적시타로 4득점을 추가해 상대의 추격을 완전히 뿌리치며 사실상 승부를 결정지었다. 하지만 LG가 이후 폰세를 상대로 3회초 2사 1루 상황에서 터진 신민재 \"신민재 (1996년)\")의 1타점 2루타로 동점, 4회초에는 1아웃에서 앞선 2회말 실책을 만회한 김현수 \"김현수 (야구 선수)\")의 홈런으로 앞서간 가운데 팽팽한 1점 차 승부가 이어졌고 이후 LG는 8회초 1사 1, 3루 오스틴 타석에서 김서현 \"김서현 (야구 선수)\")이 폭투를 범하여 홍창기의 대주자로 들어온 3루 주자 최원영 \"최원영 (야구 선수)\")이 득점하며 3:1로 앞서며 LG의 흐름으로 3차전이 흐르고 있었으나 8회말 한화가 대반격을 시작했다.',\n",
       "   'score': 0.88822687,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.youtube.com/watch?v=MmcDtgJ1zqs',\n",
       "   'title': '[속보] LG 트윈스, 2025 한국시리즈 우승…2년만에 왕좌 탈환 ...',\n",
       "   'content': '프로야구 LG 트윈스가 한화 이글스를 꺾고 2025년 한국시리즈 우승을 차지했습니다. LG는 조금 전 대전에서 열린 한국시리즈 5차전에서 4대1로 승리,',\n",
       "   'score': 0.87706697,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.facebook.com/kbo1982/posts/2025-kbo-%ED%95%9C%EA%B5%AD%EC%8B%9C%EB%A6%AC%EC%A6%88-%EC%9A%B0%EC%8A%B9-lg%ED%8A%B8%EC%9C%88%EC%8A%A4%EC%9E%85%EB%8B%88%EB%8B%A41031-lg%ED%95%9C%ED%99%94%EC%95%BC%EA%B5%AC-baseball-kbo-%ED%8F%AC%EC%8A%A4%ED%8A%B8%EC%8B%9C%EC%A6%8C-%ED%95%9C%EA%B5%AD%EC%8B%9C%EB%A6%AC%EC%A6%88_5%EC%B0%A8%EC%A0%84-lg%ED%8A%B8%EC%9C%88%EC%8A%A4-%EC%9A%B0%EC%8A%B9-kbo2/1315789490588357/',\n",
       "   'title': '2025 KBO 한국시리즈 우승! LG트윈스입니다!(10.31. ...',\n",
       "   'content': '2025 KBO 한국시리즈 우승! LG트윈스입니다!(10.31. LG: 한화) #야구 #baseball #KBO #포스트시즌 #한국시리즈_5차전 #LG트윈스 #우승 #kbo20251031.',\n",
       "   'score': 0.86713725,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.94,\n",
       " 'request_id': '107c0ed4-2dc1-414b-b7d5-a71232102547'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(result))\n",
    "result # 내용의 요약본이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도구이름: tavily_search\n",
      "도구설명:\n",
      "A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.\n"
     ]
    }
   ],
   "source": [
    "#############################################################################################\n",
    "# 도구 - 도구 이름, 도구 설명  ==> llm이 도구 사용 여부를 판단할 때 근거.\n",
    "# Tavily(built-in) 도구 정보 확인\n",
    "#############################################################################################\n",
    "print(\"도구이름:\", tavily_search.name)\n",
    "print(\"도구설명:\")\n",
    "print(tavily_search.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additionalProperties': True,\n",
       " 'description': 'Input for [TavilySearch]',\n",
       " 'properties': {'query': {'description': 'Search query to look up',\n",
       "   'title': 'Query',\n",
       "   'type': 'string'},\n",
       "  'include_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "    {'type': 'null'}],\n",
       "   'default': [],\n",
       "   'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        ',\n",
       "   'title': 'Include Domains'},\n",
       "  'exclude_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "    {'type': 'null'}],\n",
       "   'default': [],\n",
       "   'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        ',\n",
       "   'title': 'Exclude Domains'},\n",
       "  'search_depth': {'anyOf': [{'enum': ['basic',\n",
       "      'advanced',\n",
       "      'fast',\n",
       "      'ultra-fast'],\n",
       "     'type': 'string'},\n",
       "    {'type': 'null'}],\n",
       "   'default': 'basic',\n",
       "   'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        \\n        Use \"fast\" for optimized low latency with high relevance.\\n        \\n        Use \"ultra-fast\" when latency is prioritized above all else.\\n        ',\n",
       "   'title': 'Search Depth'},\n",
       "  'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "   'default': False,\n",
       "   'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        ',\n",
       "   'title': 'Include Images'},\n",
       "  'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'],\n",
       "     'type': 'string'},\n",
       "    {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        ',\n",
       "   'title': 'Time Range'},\n",
       "  'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'],\n",
       "     'type': 'string'},\n",
       "    {'type': 'null'}],\n",
       "   'default': 'general',\n",
       "   'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        ',\n",
       "   'title': 'Topic'},\n",
       "  'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'description': 'Filters search results to include only content published on or after this date.\\n        \\n        Use this parameter when you need to:\\n        - Find recent developments or updates on a topic\\n        - Exclude outdated information from search results\\n        - Focus on content within a specific timeframe\\n        - Combine with end_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-01-15\" for January 15, 2024).\\n        \\n        Examples:\\n        - \"2024-01-01\" - Results from January 1, 2024 onwards\\n        - \"2023-12-25\" - Results from December 25, 2023 onwards\\n        \\n        When combined with end_date, creates a precise date range filter.\\n        \\n        Default is None (no start date restriction).\\n        ',\n",
       "   'title': 'Start Date'},\n",
       "  'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'description': 'Filters search results to include only content published on or before this date.\\n        \\n        Use this parameter when you need to:\\n        - Exclude content published after a certain date\\n        - Study historical information or past events\\n        - Research how topics were covered during specific time periods\\n        - Combine with start_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-03-31\" for March 31, 2024).\\n        \\n        Examples:\\n        - \"2024-03-31\" - Results up to and including March 31, 2024\\n        - \"2023-12-31\" - Results up to and including December 31, 2023\\n        \\n        When combined with start_date, creates a precise date range filter.\\n        For example: start_date=\"2024-01-01\", end_date=\"2024-03-31\" \\n        returns results from Q1 2024 only.\\n        \\n        Default is None (no end date restriction).\\n        ',\n",
       "   'title': 'End Date'}},\n",
       " 'required': ['query'],\n",
       " 'title': 'TavilySearchInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = tavily_search.args_schema.model_json_schema()\n",
    "schema\n",
    "# 도구 스키마(설계 구조)\n",
    "## 도구 호출시 전달 파라미터 정보."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM ToolCalling 흐름\n",
    "\n",
    "### 1. Tool 생성 및 LLM Model에 tool binding\n",
    "- `LLM-Model.bind_tools(tools=[tool_1, tool_2, ...])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableBinding'> <class 'langchain_openai.chat_models.base.ChatOpenAI'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tavily_search = TavilySearch(max_results=5)\n",
    "model = ChatOpenAI(model=\"gpt-5-mini\") # 뇌->성능 좋은 모델을 사용(판단자.)\n",
    "toolkit = [tavily_search] # 툴들 모음\n",
    "# model에 tool들을 binding\n",
    "tool_model = model.bind_tools(tools=toolkit)\n",
    "print(type(tool_model), type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 호출 결과(AIMessage)로 사용자에게 응답을 할지, tool을 호출할지 결정\n",
    "# tool calls - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 따른 응답 차이\n",
    "## tool이 필요없는 질문.\n",
    "## content=\"답변 내용\"\n",
    "## tool_calls=[] # 빈 리스트\n",
    "result = tool_model.invoke(\"안녕하세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 무엇을 도와드릴까요?\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(result.content) # LLM의 응답\n",
    "print(result.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 1284, 'total_tokens': 1468, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CsOlMFeQ2MB7OeJ97v9Z8trLQohEp', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b6e3b-4150-7da1-814e-6c75efc43406-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': '서울 2025년 12월 30일 날씨 예보', 'search_depth': 'fast', 'include_images': False, 'topic': 'general'}, 'id': 'call_Y52415EPEBrTyJMQkxNmHQg7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1284, 'output_tokens': 184, 'total_tokens': 1468, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TOOL이 필요한 질문\n",
    "# 답변 : content=\"\", tool_calls=list[dictionary-호출방식]\n",
    "result2 = tool_model.invoke(\"2025년 12월 30일 서울 날씨는 어때?\")\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 181,\n",
       "   'prompt_tokens': 1284,\n",
       "   'total_tokens': 1465,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 128,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_provider': 'openai',\n",
       "  'model_name': 'gpt-5-mini-2025-08-07',\n",
       "  'system_fingerprint': None,\n",
       "  'id': 'chatcmpl-CsOgQAnlSwtSuR9Uf0Kqt3BJ3VFaB',\n",
       "  'service_tier': 'default',\n",
       "  'finish_reason': 'tool_calls',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'lc_run--019b6e36-9010-7481-bfd7-1cc943a08cab-0',\n",
       " 'tool_calls': [{'name': 'tavily_search',\n",
       "   'args': {'query': '서울 날씨 2025-12-30',\n",
       "    'search_depth': 'advanced',\n",
       "    'include_images': False,\n",
       "    'topic': 'general',\n",
       "    'time_range': 'day'},\n",
       "   'id': 'call_1BVZtgW7DTz0lDY8ZJi9WMfg',\n",
       "   'type': 'tool_call'}],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 1284,\n",
       "  'output_tokens': 181,\n",
       "  'total_tokens': 1465,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 128}}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tool 호출\n",
    "- LLM 모델이 tool 요청을 결정한 경우 **어떤 tool을 어떻게 호출할 지** AIMessage의 `tool_calls` 속성에 넣어 반환한다.\n",
    "- `tool_calls` 의 호출 정보를 넣어 `tool.invoke()` 호출한다.\n",
    "   - `tool.invoke(result.tool_calls[0])`\n",
    "   - **반환타입**: `ToolMessage`\n",
    "     - Tool의 처리결과를 담는 Message Type 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.tool.ToolMessage"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM 응답(AIMessage)에 tool_calls가 있을 경우 Tool을 호출\n",
    "\n",
    "# result2.tool_calls: list[dict]    dict-개별 tool 호출 정보,   list는 묶어주는 역할.\n",
    "search_result = tavily_search.invoke(result2.tool_calls[0])\n",
    "type(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='{\"query\": \"서울 2025년 12월 30일 날씨 예보\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.korea247.kr/south-korea/seoul/weather-songp-ai-dong/weather-hourly?next=4\", \"title\": \"2025년 12월 30일, 화요일 - Songp’ai-dong 시간별 날씨 | 실시간 기온 업데이트\", \"content\": \"대한민국 서울 Songp’ai-dong\\\\n\\\\n# Songp’ai-dong, 서울의 시간별 날씨 2025년 12월 30일, 화요일\\\\n\\\\n월요일  \\\\n29.12\\\\n\\\\n화요일  \\\\n30.12\\\\n\\\\n수요일  \\\\n31.12\\\\n\\\\n## 2025년 12월 30일, 화요일 Songp’ai-dong의 시간별 날씨\\\\n\\\\n시간별 일기 예보\\\\n\\\\n기온\\\\n\\\\n체감 온도\\\\n\\\\n비\\\\n\\\\n습도\\\\n\\\\n기압\\\\n\\\\n풍속\\\\n\\\\n풍향\\\\n\\\\n옅은 안개 확률\\\\n\\\\n이슬점\\\\n\\\\n구름\\\\n\\\\n하층 구름\\\\n\\\\n중층 구름\\\\n\\\\n상층 구름\\\\n\\\\n03:00\\\\n\\\\n09:00\\\\n\\\\n15:00\\\\n\\\\n21:00\\\\n\\\\n맑음\\\\n\\\\n맑음\\\\n\\\\n맑음\\\\n\\\\n맑음\\\\n\\\\n-5°C\\\\n\\\\n-5°C\\\\n\\\\n3°C\\\\n\\\\n-1°C\\\\n\\\\n-5°C\\\\n\\\\n-5°C\\\\n\\\\n0°C\\\\n\\\\n-3°C\\\\n\\\\n0 mm\\\\n\\\\n0 mm\\\\n\\\\n0 mm\\\\n\\\\n0 mm\\\\n\\\\n56 %\\\\n\\\\n45 %\\\\n\\\\n44 %\\\\n\\\\n86 %\\\\n\\\\n1026 hPa\\\\n\\\\n1027 hPa\\\\n\\\\n1024 hPa\\\\n\\\\n1024 hPa\\\\n\\\\n3 km/h\\\\n\\\\n0 km/h\\\\n\\\\n12 km/h\\\\n\\\\n6 km/h\\\\n\\\\n서\\\\n\\\\n북\\\\n\\\\n남서\\\\n\\\\n남서\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n-13°C\\\\n\\\\n-15°C\\\\n\\\\n-9°C [...] -3°C\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n19 %\\\\n\\\\n32 %\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n18 %\\\\n\\\\n28 %\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n3 %\\\\n\\\\n6 %\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n07:45 일출  \\\\n17:22 일몰\\\\n\\\\n12:20 월출  \\\\n01:49 월몰  \\\\n달의 위상:  \\\\n상현달\\\\n\\\\n### 거주 지역의 일기 예보를 확인하세요\\\\n\\\\n확인하시고 무료 선물을 받으세요   \\\\n«다음 여행을 위한 10가지 필수 안전 팁»\\\\n\\\\nSongp’ai-dong, 서울의 시간별 날씨. 업데이트된 정보에는 바람 속도, 바람 방향, 대기압, 기온이 포함됩니다. - 2025년 12월 30일, 화요일\\\\n\\\\n마지막 업데이트: 2025-12-26 07:22\\\\n\\\\n현재 날씨\\\\n\\\\n맑음\\\\n\\\\n근처 기상 관측소\", \"score\": 0.9542783, \"raw_content\": null}, {\"url\": \"https://tallbank123.tistory.com/entry/2025%EB%85%84-12%EC%9B%94-%EC%84%9C%EC%9A%B8%EB%82%A0%EC%94%A8-%EC%98%88%EB%B3%B4%EC%9E%85%EB%8B%88%EB%8B%A4\", \"title\": \"2025년 12월 서울날씨 예보입니다.\", \"content\": \"2025년 12월 서울날씨 예보입니다.\\\\n\\\\n# 키크니 나무\\\\n\\\\n카테고리 없음\\\\n\\\\n# 2025년 12월 서울날씨 예보입니다.\\\\n\\\\nby 꿈꾸는 돌\\\\n2025. 11. 6.\\\\n\\\\n반응형\\\\n\\\\n가을이 끝나고 본격 겨울로 접어들면서 추위에 조심해야 하는 계절입니다. 하지만 크리스마스가 기다리고 있어 설레는 달이기도 합니다. 12월을 좀 더 따뜻하게 보내기 위해 날씨를 확인하고 진행하면 조금 더 수월 할 수 있겠죠.\\\\n\\\\n2025년 12월 서울날씨 예보입니다.\\\\n\\\\n### 2025년 12월 날씨 예보\\\\n\\\\n전체적으로 맑거나 흐린날이 많습니다. 눈 오는 날은 많지 않네요. 화이트 크리스마스는 지금 예측으로 안될 거 같습니다. 어디까지나 예측입니다.\\\\n\\\\n2025년을 마무리하며 바쁜 한달입니다. 각종 송년회나 모임이 있고 마음도 모르게 설레는 달입니다. 한해 돌아보며 마무리 잘하시고 멋진 새해맞이하세요\\\\n\\\\n반응형\\\\n\\\\n반응형\\\\n\\\\n저작자표시 비영리 변경금지\\\\n(새창열림)\\\\n\\\\n## 태그\\\\n\\\\n12월 서울 날씨, 날씨예보, 크리스마스\", \"score\": 0.8687491, \"raw_content\": null}, {\"url\": \"https://dataful.kr/803\", \"title\": \"2025년 12월 24일부터 30일까지 날씨 예보 전망 기온 눈 비 안내\", \"content\": \"본문 바로가기 메뉴 바로가기\\\\n\\\\n 글쓰기\\\\n 관리\\\\n 태그\\\\n 방명록\\\\n RSS\\\\n\\\\n데이터풀\\\\n\\\\n 분류 전체보기 (800) \\\\n  + 날씨 (211)\\\\n  + 배 (40)\\\\n  + 버스 (69)\\\\n  + 보건 복지 (17)\\\\n  + 부동산 금융 (10)\\\\n  + 비행기 (52)\\\\n  + 생활정보 (106)\\\\n  + 스포츠 (34)\\\\n  + 열차 (181)\\\\n  + 자동차 (63)\\\\n  + 기타 (17)\\\\n\\\\n 방명록\\\\n\\\\n티스토리 뷰\\\\n\\\\n날씨\\\\n\\\\n# 2025년 12월 24일부터 30일까지 날씨 예보 전망 기온 눈 비 안내\\\\n\\\\n데이터풀맨 2025. 12. 20.\\\\n\\\\n2025년 12월 24일부터 12월 30일까지 전국 지역별 날씨 예보를 알려드립니다. 눈 비 맑음 흐림 등의 날씨 예보와 최저 기온 최고 기온 정보를 주로 안내합니다. 크리스마스 기간이 포함된 날씨 정보로서 크리스마스 기간 눈이 오는지 여부도 함께 알려드립니다.\\\\n\\\\n일주일 기상 예보를 알려드립니다.\\\\n\\\\n기상청에서 발표하는 자료를 활용하여 알려드립니다. [...] 12월 24일(수) 아침 기온은 0~11℃, 낮 기온은 4~14℃로 평년(최저기온 -9~2℃, 최고기온 1~10℃)보다 높겠고, 그 밖의 날의 아침 기온은 -6~3℃, 낮 기온은 1~11℃로 평년과 비슷하겠습니다.\\\\n\\\\n(해상)\\\\n\\\\n12월 24일(수)~25일(목) 전 해상에 바다의 물결이 1.0~4.0m로 매우 높게 일겠습니다.\\\\n\\\\n## 2025년 12월 24일 ~ 12월 30일 육상 날씨\\\\n\\\\n## 2025년 12월 24일 ~ 12월 30일 최저 최고 기온\\\\n\\\\n2025년 12월 24일부터 30일까지 날씨 예보 전망 기온 눈 비 예보를 알아보았습니다.\\\\n\\\\n이 기간 날씨 정보가 필요하신 분들께 도움을 드렸길 바랍니다.\\\\n\\\\n좀 더 정확한 날씨 예보는 최신 예보입니다.\\\\n\\\\n최신 예보를 확인하시려면 글 상단에 있는 날씨누리 홈페이지 방문해 보시길 바랍니다.\\\\n\\\\n감사합니다.\\\\n\\\\n반응형\\\\n\\\\n저작자표시 비영리 변경금지  (새창열림)\\\\n\\\\n#### \\'날씨\\' 카테고리의 다른 글\", \"score\": 0.84948516, \"raw_content\": null}, {\"url\": \"https://ko.laodong.vn/moi-truong/du-bao-thoi-tiet-10-ngay-toi-tu-29122025-den-712026-o-ca-ba-mien-1632427.ldo\", \"title\": \"2025년 12월 29일부터 2026년 1월 7일까지 3개 지역의 향후 10일간의 날씨 예보\", \"content\": \"북부 및 북중부 지역은 곳곳에 비가 오고, 이른 아침에는 안개가 끼는 곳이 있습니다. 날씨가 춥고, 산악 지역은 매우 추운 곳도 있습니다.\\\\n\\\\n꽝찌에서 다낭시까지의 지역과 꽝응아이에서 닥락까지의 동부 지방에는 곳곳에 소나기가 내립니다. 북쪽은 날씨가 춥습니다.\\\\n\\\\n다른 지역은 저녁과 밤에 소나기와 뇌우가 오는 곳이 있고, 낮에는 맑습니다.\\\\n\\\\n기상 기관은 폭풍우 속에서 회오리바람, 번개 및 강풍이 발생할 가능성이 있다고 경고합니다.\\\\n\\\\n2025년 12월 30일 밤부터 2026년 1월 7일까지의 날씨 추세 예측\\\\n\\\\n국립수문기상예보센터는 2025년 12월 30일 밤부터 2026년 1월 7일까지 일부 지역에서 주목할 만한 기상 추세를 예측했습니다.\", \"score\": 0.82694983, \"raw_content\": null}, {\"url\": \"https://dataful.kr/805\", \"title\": \"2025년 12월 28일부터 ~ 2026년 1월 3일까지 전국 날씨 예보 추위 전망\", \"content\": \"이 글에서는 12월 28일, 12월 29일, 12월 30일, 12월 31일, 2026년 1월 1일, 1월 2일, 1월 3일.\\\\n\\\\n총 7일간의 날씨를 하루 단위로 정리하며, 각 날짜별 예보는 오전·오후로 나누어 전달드립니다.\\\\n\\\\n본 예보는 기상청 날씨누리 중기예보 자료를 참고해 작성되었습니다.\\\\n\\\\n가장 최신의 실시간 기상 정보가 필요하신 경우에는 글 하단에 첨부한 날씨누리 공식 링크를 통해 직접 확인하시는 것을 권장드립니다.\\\\n\\\\n우선 이 글의 전체 구성과 차례를 살펴보며, 이번 글에서 어떤 내용을 다루는지 미리 확인해 보시기 바랍니다.\\\\n\\\\n<차례>\\\\n\\\\n 2025년 12월 28일 ~ 2026년 1월 3일 날씨 예보 요약\\\\n 2025년 12월 28일 ~ 2026년 1월 3일 전국 날씨 예보\\\\n 2025년 12월 28일 ~ 2026년 1월 3일 전국 기온 예보\\\\n\\\\n## 2025년 12월 28일 ~ 2026년 1월 3일 날씨 예보 요약\\\\n\\\\n(강수)\", \"score\": 0.7978881, \"raw_content\": null}], \"response_time\": 0.0, \"request_id\": \"19c27bb8-7560-4e43-b52c-1f3e26270f07\"}', name='tavily_search', tool_call_id='call_Y52415EPEBrTyJMQkxNmHQg7')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"query\": \"서울 2025년 12월 30일 날씨 예보\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.korea247.kr/south-korea/seoul/weather-songp-ai-dong/weather-hourly?next=4\", \"title\": \"2025년 12월 30일, 화요일 - Songp’ai-dong 시간별 날씨 | 실시간 기온 업데이트\", \"content\": \"대한민국 서울 Songp’ai-dong\\\\n\\\\n# Songp’ai-dong, 서울의 시간별 날씨 2025년 12월 30일, 화요일\\\\n\\\\n월요일  \\\\n29.12\\\\n\\\\n화요일  \\\\n30.12\\\\n\\\\n수요일  \\\\n31.12\\\\n\\\\n## 2025년 12월 30일, 화요일 Songp’ai-dong의 시간별 날씨\\\\n\\\\n시간별 일기 예보\\\\n\\\\n기온\\\\n\\\\n체감 온도\\\\n\\\\n비\\\\n\\\\n습도\\\\n\\\\n기압\\\\n\\\\n풍속\\\\n\\\\n풍향\\\\n\\\\n옅은 안개 확률\\\\n\\\\n이슬점\\\\n\\\\n구름\\\\n\\\\n하층 구름\\\\n\\\\n중층 구름\\\\n\\\\n상층 구름\\\\n\\\\n03:00\\\\n\\\\n09:00\\\\n\\\\n15:00\\\\n\\\\n21:00\\\\n\\\\n맑음\\\\n\\\\n맑음\\\\n\\\\n맑음\\\\n\\\\n맑음\\\\n\\\\n-5°C\\\\n\\\\n-5°C\\\\n\\\\n3°C\\\\n\\\\n-1°C\\\\n\\\\n-5°C\\\\n\\\\n-5°C\\\\n\\\\n0°C\\\\n\\\\n-3°C\\\\n\\\\n0 mm\\\\n\\\\n0 mm\\\\n\\\\n0 mm\\\\n\\\\n0 mm\\\\n\\\\n56 %\\\\n\\\\n45 %\\\\n\\\\n44 %\\\\n\\\\n86 %\\\\n\\\\n1026 hPa\\\\n\\\\n1027 hPa\\\\n\\\\n1024 hPa\\\\n\\\\n1024 hPa\\\\n\\\\n3 km/h\\\\n\\\\n0 km/h\\\\n\\\\n12 km/h\\\\n\\\\n6 km/h\\\\n\\\\n서\\\\n\\\\n북\\\\n\\\\n남서\\\\n\\\\n남서\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n-13°C\\\\n\\\\n-15°C\\\\n\\\\n-9°C [...] -3°C\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n19 %\\\\n\\\\n32 %\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n18 %\\\\n\\\\n28 %\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n3 %\\\\n\\\\n6 %\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n0 %\\\\n\\\\n07:45 일출  \\\\n17:22 일몰\\\\n\\\\n12:20 월출  \\\\n01:49 월몰  \\\\n달의 위상:  \\\\n상현달\\\\n\\\\n### 거주 지역의 일기 예보를 확인하세요\\\\n\\\\n확인하시고 무료 선물을 받으세요   \\\\n«다음 여행을 위한 10가지 필수 안전 팁»\\\\n\\\\nSongp’ai-dong, 서울의 시간별 날씨. 업데이트된 정보에는 바람 속도, 바람 방향, 대기압, 기온이 포함됩니다. - 2025년 12월 30일, 화요일\\\\n\\\\n마지막 업데이트: 2025-12-26 07:22\\\\n\\\\n현재 날씨\\\\n\\\\n맑음\\\\n\\\\n근처 기상 관측소\", \"score\": 0.9542783, \"raw_content\": null}, {\"url\": \"https://tallbank123.tistory.com/entry/2025%EB%85%84-12%EC%9B%94-%EC%84%9C%EC%9A%B8%EB%82%A0%EC%94%A8-%EC%98%88%EB%B3%B4%EC%9E%85%EB%8B%88%EB%8B%A4\", \"title\": \"2025년 12월 서울날씨 예보입니다.\", \"content\": \"2025년 12월 서울날씨 예보입니다.\\\\n\\\\n# 키크니 나무\\\\n\\\\n카테고리 없음\\\\n\\\\n# 2025년 12월 서울날씨 예보입니다.\\\\n\\\\nby 꿈꾸는 돌\\\\n2025. 11. 6.\\\\n\\\\n반응형\\\\n\\\\n가을이 끝나고 본격 겨울로 접어들면서 추위에 조심해야 하는 계절입니다. 하지만 크리스마스가 기다리고 있어 설레는 달이기도 합니다. 12월을 좀 더 따뜻하게 보내기 위해 날씨를 확인하고 진행하면 조금 더 수월 할 수 있겠죠.\\\\n\\\\n2025년 12월 서울날씨 예보입니다.\\\\n\\\\n### 2025년 12월 날씨 예보\\\\n\\\\n전체적으로 맑거나 흐린날이 많습니다. 눈 오는 날은 많지 않네요. 화이트 크리스마스는 지금 예측으로 안될 거 같습니다. 어디까지나 예측입니다.\\\\n\\\\n2025년을 마무리하며 바쁜 한달입니다. 각종 송년회나 모임이 있고 마음도 모르게 설레는 달입니다. 한해 돌아보며 마무리 잘하시고 멋진 새해맞이하세요\\\\n\\\\n반응형\\\\n\\\\n반응형\\\\n\\\\n저작자표시 비영리 변경금지\\\\n(새창열림)\\\\n\\\\n## 태그\\\\n\\\\n12월 서울 날씨, 날씨예보, 크리스마스\", \"score\": 0.8687491, \"raw_content\": null}, {\"url\": \"https://dataful.kr/803\", \"title\": \"2025년 12월 24일부터 30일까지 날씨 예보 전망 기온 눈 비 안내\", \"content\": \"본문 바로가기 메뉴 바로가기\\\\n\\\\n 글쓰기\\\\n 관리\\\\n 태그\\\\n 방명록\\\\n RSS\\\\n\\\\n데이터풀\\\\n\\\\n 분류 전체보기 (800) \\\\n  + 날씨 (211)\\\\n  + 배 (40)\\\\n  + 버스 (69)\\\\n  + 보건 복지 (17)\\\\n  + 부동산 금융 (10)\\\\n  + 비행기 (52)\\\\n  + 생활정보 (106)\\\\n  + 스포츠 (34)\\\\n  + 열차 (181)\\\\n  + 자동차 (63)\\\\n  + 기타 (17)\\\\n\\\\n 방명록\\\\n\\\\n티스토리 뷰\\\\n\\\\n날씨\\\\n\\\\n# 2025년 12월 24일부터 30일까지 날씨 예보 전망 기온 눈 비 안내\\\\n\\\\n데이터풀맨 2025. 12. 20.\\\\n\\\\n2025년 12월 24일부터 12월 30일까지 전국 지역별 날씨 예보를 알려드립니다. 눈 비 맑음 흐림 등의 날씨 예보와 최저 기온 최고 기온 정보를 주로 안내합니다. 크리스마스 기간이 포함된 날씨 정보로서 크리스마스 기간 눈이 오는지 여부도 함께 알려드립니다.\\\\n\\\\n일주일 기상 예보를 알려드립니다.\\\\n\\\\n기상청에서 발표하는 자료를 활용하여 알려드립니다. [...] 12월 24일(수) 아침 기온은 0~11℃, 낮 기온은 4~14℃로 평년(최저기온 -9~2℃, 최고기온 1~10℃)보다 높겠고, 그 밖의 날의 아침 기온은 -6~3℃, 낮 기온은 1~11℃로 평년과 비슷하겠습니다.\\\\n\\\\n(해상)\\\\n\\\\n12월 24일(수)~25일(목) 전 해상에 바다의 물결이 1.0~4.0m로 매우 높게 일겠습니다.\\\\n\\\\n## 2025년 12월 24일 ~ 12월 30일 육상 날씨\\\\n\\\\n## 2025년 12월 24일 ~ 12월 30일 최저 최고 기온\\\\n\\\\n2025년 12월 24일부터 30일까지 날씨 예보 전망 기온 눈 비 예보를 알아보았습니다.\\\\n\\\\n이 기간 날씨 정보가 필요하신 분들께 도움을 드렸길 바랍니다.\\\\n\\\\n좀 더 정확한 날씨 예보는 최신 예보입니다.\\\\n\\\\n최신 예보를 확인하시려면 글 상단에 있는 날씨누리 홈페이지 방문해 보시길 바랍니다.\\\\n\\\\n감사합니다.\\\\n\\\\n반응형\\\\n\\\\n저작자표시 비영리 변경금지  (새창열림)\\\\n\\\\n#### \\'날씨\\' 카테고리의 다른 글\", \"score\": 0.84948516, \"raw_content\": null}, {\"url\": \"https://ko.laodong.vn/moi-truong/du-bao-thoi-tiet-10-ngay-toi-tu-29122025-den-712026-o-ca-ba-mien-1632427.ldo\", \"title\": \"2025년 12월 29일부터 2026년 1월 7일까지 3개 지역의 향후 10일간의 날씨 예보\", \"content\": \"북부 및 북중부 지역은 곳곳에 비가 오고, 이른 아침에는 안개가 끼는 곳이 있습니다. 날씨가 춥고, 산악 지역은 매우 추운 곳도 있습니다.\\\\n\\\\n꽝찌에서 다낭시까지의 지역과 꽝응아이에서 닥락까지의 동부 지방에는 곳곳에 소나기가 내립니다. 북쪽은 날씨가 춥습니다.\\\\n\\\\n다른 지역은 저녁과 밤에 소나기와 뇌우가 오는 곳이 있고, 낮에는 맑습니다.\\\\n\\\\n기상 기관은 폭풍우 속에서 회오리바람, 번개 및 강풍이 발생할 가능성이 있다고 경고합니다.\\\\n\\\\n2025년 12월 30일 밤부터 2026년 1월 7일까지의 날씨 추세 예측\\\\n\\\\n국립수문기상예보센터는 2025년 12월 30일 밤부터 2026년 1월 7일까지 일부 지역에서 주목할 만한 기상 추세를 예측했습니다.\", \"score\": 0.82694983, \"raw_content\": null}, {\"url\": \"https://dataful.kr/805\", \"title\": \"2025년 12월 28일부터 ~ 2026년 1월 3일까지 전국 날씨 예보 추위 전망\", \"content\": \"이 글에서는 12월 28일, 12월 29일, 12월 30일, 12월 31일, 2026년 1월 1일, 1월 2일, 1월 3일.\\\\n\\\\n총 7일간의 날씨를 하루 단위로 정리하며, 각 날짜별 예보는 오전·오후로 나누어 전달드립니다.\\\\n\\\\n본 예보는 기상청 날씨누리 중기예보 자료를 참고해 작성되었습니다.\\\\n\\\\n가장 최신의 실시간 기상 정보가 필요하신 경우에는 글 하단에 첨부한 날씨누리 공식 링크를 통해 직접 확인하시는 것을 권장드립니다.\\\\n\\\\n우선 이 글의 전체 구성과 차례를 살펴보며, 이번 글에서 어떤 내용을 다루는지 미리 확인해 보시기 바랍니다.\\\\n\\\\n<차례>\\\\n\\\\n 2025년 12월 28일 ~ 2026년 1월 3일 날씨 예보 요약\\\\n 2025년 12월 28일 ~ 2026년 1월 3일 전국 날씨 예보\\\\n 2025년 12월 28일 ~ 2026년 1월 3일 전국 기온 예보\\\\n\\\\n## 2025년 12월 28일 ~ 2026년 1월 3일 날씨 예보 요약\\\\n\\\\n(강수)\", \"score\": 0.7978881, \"raw_content\": null}], \"response_time\": 0.0, \"request_id\": \"19c27bb8-7560-4e43-b52c-1f3e26270f07\"}'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tool call 이 여러 개인 경우.\n",
    "query = \"2025년 KBO, MLB, NPB 리그의 우승팀을 알려줘.\"\n",
    "result = tool_model.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search',\n",
       "  'args': {'query': '2025 KBO 우승팀',\n",
       "   'search_depth': 'advanced',\n",
       "   'topic': 'news',\n",
       "   'include_images': False},\n",
       "  'id': 'call_pownOzId1h1cgrdIRUuD9MV8',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'tavily_search',\n",
       "  'args': {'query': '2025 MLB World Series champion',\n",
       "   'search_depth': 'advanced',\n",
       "   'topic': 'news',\n",
       "   'include_images': False},\n",
       "  'id': 'call_8Iccvz2bfHUQIeSv3SsxfLyV',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'tavily_search',\n",
       "  'args': {'query': '2025 NPB 우승팀',\n",
       "   'search_depth': 'advanced',\n",
       "   'topic': 'news',\n",
       "   'include_images': False},\n",
       "  'id': 'call_H7lYocyJ1Y6G3RJWOskatfG4',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls\n",
    "# 각각 툴이 다를 경우에는 반복문 돌려야됨. 지금은 같은 툴이라서 batch를 씀."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tool_call 이 여러개일 경우 \n",
    "- 질의에 대해 tool을 여러번 호출 해야 하는 경우 tool_calling 정보를 여러개 반환할 수 있다.\n",
    "    - 예) 검색할 키워드가 여러개인 경우. \n",
    "- `tool.batch([tool_call1, tool_call2, ..])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tool_call in result.tool_calls:   # LLM이 여러개의 툴을 가지고 있을 경우 반복문을 실행해야 한다.\n",
    "#   tool_call.name => 호출할 툴 이름 조회.\n",
    "#   tool_model.invoke(tool_call)\n",
    "\n",
    "# Runnable: invoke()/stream() - 개별 요청. batch(): 한번에 여러개 요청\n",
    "search_result_list = tavily_search.batch(result.tool_calls) # [toolcall, toolcall, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolMessage(content='{\"query\": \"2025 KBO 우승팀\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.mlb.com/news/mlb-teams-seeking-turnaround-2026\", \"title\": \"6 teams whose fortunes are looking up for ’26 - MLB.com\", \"score\": 0.31069437, \"published_date\": \"Mon, 29 Dec 2025 01:08:55 GMT\", \"content\": \"Nats fans have been waiting for all that youth -- on the field, and now in dugout and the front office -- to translate into on-field success. This may well be that year.\\\\n\\\\nOrioles  \\\\n2025: 75-87 (5th in AL East)\\\\n\\\\nNo team has been more aggressive than the Orioles this offseason, and for good reason: After a pair of disappointing postseasons and a truly miserable 2025, that Team Of The Future label everybody put on the Orioles was starting to gather a little mold. [...] # 6 teams whose fortunes are looking up for ’26\\\\n\\\\n1:05 AM UTC\\\\n\\\\nWill Leitch\\\\n\\\\n@williamfleitch\\\\n\\\\nAs we close the book on 2025 and celebrate the teams that enjoyed a great year, the teams that didn’t should keep this in mind: One year can make a huge difference. [...] Just ask the Blue Jays. In 2025, they reached a World Series that they came this close to winning (several times). But in 2024? They finished the year in last place after enduring months of speculation that they might just trade Vladimir Guerrero Jr. and start over.\\\\n\\\\n Get gear for the new year\\\\n\\\\nIt can turn around for you fast. In both directions.\", \"raw_content\": null}, {\"url\": \"https://bleacherreport.com/articles/25337485-grading-every-mlb-teams-2019-draft-haul-6-years-later\", \"title\": \"Grading Every MLB Team\\'s 2019 Draft Haul 6 Years Later - Bleacher Report\", \"score\": 0.032344334, \"published_date\": \"Thu, 25 Dec 2025 13:12:33 GMT\", \"content\": \"Ryan Zeferjahn and Matthew Lugo ended up being part of the same trade package at the 2024 deadline to acquire rental reliever Luis García from the Angels, and Zeferjahn logged a 4.74 ERA and 11.5 K/9 in 62 appearances as a rookie in 2025.\\\\n\\\\nGrade:D\\\\n\\\\n## Chicago Cubs\\\\n\\\\n6 of 30\\\\n\\\\nMatt Dirksen/Chicago Cubs/Getty Images\\\\n\\\\nPorter Hodge\\\\n\\\\nFirst-Round Pick:RHP Ryan Jensen (1-27)\\\\n\\\\nMLB Players:LHP DJ Herz (8-252), RHP Hunter Bigge (12-372), RHP Porter Hodge (13-402), RHP Bryan King (30-912) [...] Bleacher Report22h### Justin Verlander and 8 MLB Free Agents With Huge Buy-Low Upside\\\\n\\\\nBleacher Report2d\\\\n\\\\n## Baltimore Orioles\\\\n\\\\n4 of 30\\\\n\\\\nTim Warner/Getty Images\\\\n\\\\nAdley Rutschman and Gunnar Henderson\\\\n\\\\nFirst-Round Pick:C Adley Rutschman (1-1)\\\\n\\\\nMLB Players:SS Gunnar Henderson (2-42), OF Kyle Stowers (2-71), SS Joey Ortiz (4-108), IF Darell Hernaiz (5-138), C Maverick Handley (6-168), RHP Connor Gillispie (9-258), RHP Kade Strowd (12-348) [...] The fact that they also landed Vinnie Pasquantino, Michael Massey and Alec Marsh in this draft class makes it arguably the best draft haul in franchise history, and one that has truly reshaped the organization.\\\\n\\\\nGrade:A\\\\n\\\\n## Los Angeles Angels\\\\n\\\\n14 of 30\\\\n\\\\nSam Hodde/Getty Images\\\\n\\\\nJack Kochanowicz\\\\n\\\\nFirst-Round Pick:SS Will Wilson (1-15)\\\\n\\\\nMLB Players:2B Kyren Paris (2-55), RHP Jack Kochanowicz (3-92), RHP Davis Daniel (7-211), RHP Zac Kristofak (14-421)\", \"raw_content\": null}, {\"url\": \"https://www.foxsports.com/articles/nfl/lionsvikings-matchup-has-lost-some-luster-but-the-playoffs-are-still-possible-for-ailing-detroit\", \"title\": \"Lions-Vikings matchup has lost some luster, but the playoffs are still possible for ailing Detroit - FOX Sports\", \"score\": 0.021948254, \"published_date\": \"Wed, 24 Dec 2025 15:59:19 GMT\", \"content\": \"After reaching the NFC championship game for the 2023 season and logging a franchise-record 15 wins last season, the Lions (8-7) are in trouble after losing at home to Pittsburgh last week for their first two-game losing streak in more than three years.\\\\n\\\\n“We haven’t had that feeling. It’s creeping in on us now,” quarterback Jared Goff said. “We\\'ve got to find a way.”\\\\n\\\\n## Vikings turn to Brosmer again [...] Item 1 of 3\\\\n\\\\nin this topic\\\\n\\\\nNational Football League\\\\n\\\\nDetroit Lions\\\\n\\\\nMinnesota Vikings\\\\n\\\\nJared Goff\\\\n\\\\nMax Brosmer\\\\n\\\\nJ.J. McCarthy\\\\n\\\\nBrian Branch\\\\n\\\\nKerby Joseph\\\\n\\\\nJahmyr Gibbs\\\\n\\\\nDavid Montgomery\\\\n\\\\nCarson Wentz\\\\n\\\\nSeattle Seahawks\\\\n\\\\nNEXT STORY\\\\n\\\\n### 2025 NFL Week 17 Buzz: Chargers LB Denzel Perryman\\'s Suspension Upheld\\\\n\\\\nrecommended [...] 2. ### 2025 NFL Playoff Picture, Bracket, Schedule: 8 Teams Clinch Spots in Week 16### QB Stock Market Week 17: Caleb Williams Defying Logic; Aaron Rodgers Reforming### Ravens, Broncos, 49ers, Seahawks Lead Way With 6 Players at NFL Pro Bowl Games\\\\n3. ### Let\\'s Debate: Jared Goff, Tee Higgins & the Other Top Pro Bowl Snubs### Herd Hierarchy Week 17: Who Replaced Rams at No. 1? Are The Jaguars for Real?### 2025 NFL Division Winner Odds: Clinching Scenarios Will Define Week 17\", \"raw_content\": null}, {\"url\": \"https://www.foxsports.com/articles/nfl/2025-nfl-week-17-predictions-betting-odds-tv-schedule\", \"title\": \"2025 NFL Week 17 Predictions, Betting Odds & TV Schedule - FOX Sports\", \"score\": 0.01784874, \"published_date\": \"Tue, 23 Dec 2025 21:07:22 GMT\", \"content\": \"Game Date: Thursday, Dec. 25\\\\n Game Time: 1 p.m. ET\\\\n TV Channel: Netflix\\\\n Box Score\\\\n Location: Landover, Maryland\\\\n\\\\n## Minnesota Vikings vs. Detroit Lions\\\\n\\\\n## Odds & Prediction\\\\n\\\\n Spread: Lions (-6)\\\\n Moneyline: Lions -344, Vikings +276\\\\n Total: 44.5 points\\\\n Prediction: Lions 25, Vikings 24\\\\n\\\\n## How to Watch\\\\n\\\\n Game Date: Thursday, Dec. 25\\\\n Game Time: 4:30 p.m. ET\\\\n TV Channel: Netflix\\\\n Box Score\\\\n Location: Minneapolis, Minnesota\\\\n\\\\n## Kansas City Chiefs vs. Denver Broncos\\\\n\\\\n## Odds & Prediction [...] Check out the full NFL schedule on FOX Sports!\\\\n\\\\nThis page may contain affiliate links to legal sports betting partners. If you sign up or place a wager, FOX Sports may be compensated. Read more about Sports Betting on FOX Sports.\\\\n\\\\n## Week 17 Betting Lines & Game Info\\\\n\\\\n## Washington Commanders vs. Dallas Cowboys\\\\n\\\\n## Odds & Prediction\\\\n\\\\n Spread: Cowboys (-7)\\\\n Moneyline: Cowboys -325, Commanders +261\\\\n Total: 50.5 points\\\\n Prediction: Cowboys 27, Commanders 26\\\\n\\\\n## How to Watch [...] Item 1 of 3\\\\n\\\\nin this topic\\\\n\\\\nNational Football League\\\\n\\\\nBetting\\\\n\\\\nGambling\\\\n\\\\nNEXT STORY\\\\n\\\\n### 2025 NFL Week 17 Buzz: Browns Make QB Decision on Deshaun Watson\\\\n\\\\nrecommended\", \"raw_content\": null}, {\"url\": \"https://www.mlb.com/news/rangers-expect-bounceback-season-from-josh-jung\", \"title\": \"Rangers hopeful Jung can reach new heights after shaky \\'25 - MLB.com\", \"score\": 0.013121271, \"published_date\": \"Mon, 29 Dec 2025 15:04:11 GMT\", \"content\": \"In this new era of the Rangers, Schumaker and his staff are going to be trying to get the club back to the postseason. A major part of that will include the offense, where Jung was just one of many underperformers in 2025. [...] Skubal will go for his third in a row in 2026 and, ERA fluctuations aside, essentially had the same season in 2025 as he did in 2024. If he does it again, he’ll win that third Cy. That is … if he’s still in American League. Yep, one of the major questions about Skubal remains: Is he going to be a Tiger on Opening Day? After the Trade Deadline? This time next year?\", \"raw_content\": null}], \"response_time\": 0.0, \"request_id\": \"95b1e221-da90-4dcf-8300-200afa335ac2\"}', name='tavily_search', tool_call_id='call_pownOzId1h1cgrdIRUuD9MV8'),\n",
       " ToolMessage(content='{\"query\": \"2025 MLB World Series champion\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.foxnews.com/sports/sports-teams-were-crowned-champions-2025.amp\", \"title\": \"Sports teams that were crowned champions in 2025 - Fox News\", \"score\": 0.99776566, \"published_date\": \"Sat, 27 Dec 2025 11:00:06 GMT\", \"content\": \"The Dodgers became Major League Baseball’s first back-to-back champions since the 1998-2000 New York Yankees, who won three consecutive titles, in 2025. The Dodgers beat the Toronto Blue Jays in seven games, defeating the Blue Jays in extra innings of Game 7 in one of the most thrilling World Series games ever. The Blue Jays had a 3-2 series lead heading back to Canada, but the Dodgers won two games on the road while facing elimination to win their second consecutive title. [...] Los Angeles Dodgers pitcher Yoshinobu Yamamoto, top center, celebrates with teammates after the team defeated the Toronto Blue Jays after the 11th inning in Game 7 of baseball\\'s World Series in Toronto on Sunday, Nov. 2, 2025. (Chris Young/The Canadian Press via AP) [...] The Dodgers weren’t as dominant in the regular season in 2025 as they were in 2024 (93 wins compared to 98 in 2024) but still ended up at the top. The Dodgers\\' bullpen faltered down the stretch, so manager Dave Roberts got creative and used multiple starters in relief. Roberts turned young starter Roki Sasaki into the team’s closer in October. Yoshinobu Yamamoto won World Series MVP after pitching 37.1 innings in the postseason, going 5-1 with a 1.85 ERA. The Dodgers swept the Cincinnati Reds\", \"raw_content\": null}, {\"url\": \"https://www.nytimes.com/athletic/6912583/2025/12/25/baseball-trivia-quiz-2025/\", \"title\": \"It’s the most wonderful quiz of the year: The Athletic’s annual MLB trivia extravaganza! - The New York Times\", \"score\": 0.99589807, \"published_date\": \"Thu, 25 Dec 2025 11:00:00 GMT\", \"content\": \"The Los Angeles Dodgers outlasted the Toronto Blue Jays in a thrilling seven-game World Series, becoming the first repeat champion in a quarter century. Five of the major award winners from 2024 – Aaron Judge, Shohei Ohtani, Tarik Skubal, Pat Murphy and Stephen Vogt – earned the same trophies for 2025, while Paul Skenes graduated from Rookie of the Year to Cy Young. [...] # It’s the most wonderful quiz of the year: The Athletic’s annual MLB trivia extravaganza!\\\\n\\\\nShohei Ohtani and the Dodgers both ran it back in 2025, winning the NL MVP and World Series again.Kyle Cooper/Colorado Rockies/Getty Images\\\\n\\\\nBy Tyler Kepner\\\\n\\\\nIn Major League Baseball, 2025 was the year to run it all back.\", \"raw_content\": null}, {\"url\": \"https://www.mlb.com/news/mlb-teams-seeking-turnaround-2026\", \"title\": \"6 teams whose fortunes are looking up for ’26 - MLB.com\", \"score\": 0.9693242, \"published_date\": \"Mon, 29 Dec 2025 01:08:55 GMT\", \"content\": \"Just ask the Blue Jays. In 2025, they reached a World Series that they came this close to winning (several times). But in 2024? They finished the year in last place after enduring months of speculation that they might just trade Vladimir Guerrero Jr. and start over.\\\\n\\\\n Get gear for the new year\\\\n\\\\nIt can turn around for you fast. In both directions. [...] Nationals  \\\\n2025: 66-96 (5th in NL East)\\\\n\\\\nWhen you haven’t had a winning season since before the pandemic -- even if that 2019 season ended in a World Series title -- it’s probably a sign that you need some fresh eyes leading your organization. The Nationals certainly have that, with a 33-year-old manager, a 35-year-old president of baseball operations and a 31-year-old general manager. Crusty old salts, they’re not. [...] After a 2024 that felt mostly snakebit, thanks to a seemingly endless number of injuries, the Braves were hopeful that ’25 would be a return to normal, the comeback of a team that won the World Series in ’21 and won 101-plus games each of the two years afterward. It did not turn out that way.\", \"raw_content\": null}, {\"url\": \"https://www.mlb.com/news/rangers-expect-bounceback-season-from-josh-jung\", \"title\": \"Rangers hopeful Jung can reach new heights after shaky \\'25 - MLB.com\", \"score\": 0.87578696, \"published_date\": \"Mon, 29 Dec 2025 15:04:11 GMT\", \"content\": \"Vladimir Guerrero Jr., 1B, Blue Jays  \\\\nThe 2025 season essentially began in the best possible way, with Guerrero signing a contract extension that kicked off the Blue Jays’ best season in more than 30 years, one that culminated in a World Series that might just have been the best one this century. Unfortunately, that historic Series ended in historic heartbreak for Toronto. [...] The 27-year-old has shown who he can be at his best. During Jung’s rookie season in 2023, he was named an All-Star starter at third base en route to the club’s first World Series championship. Now he’s got to find a way to do that again. [...] Skubal will go for his third in a row in 2026 and, ERA fluctuations aside, essentially had the same season in 2025 as he did in 2024. If he does it again, he’ll win that third Cy. That is … if he’s still in American League. Yep, one of the major questions about Skubal remains: Is he going to be a Tiger on Opening Day? After the Trade Deadline? This time next year?\", \"raw_content\": null}, {\"url\": \"https://www.mlb.com/news/impact-players-2026\", \"title\": \"10 players who will define the 2026 season - MLB.com\", \"score\": 0.8624676, \"published_date\": \"Mon, 29 Dec 2025 01:07:30 GMT\", \"content\": \"Vladimir Guerrero Jr., 1B, Blue Jays  \\\\nThe 2025 season essentially began in the best possible way, with Guerrero signing a contract extension that kicked off the Blue Jays’ best season in more than 30 years, one that culminated in a World Series that might just have been the best one this century. Unfortunately, that historic Series ended in historic heartbreak for Toronto. [...] Skubal will go for his third in a row in 2026 and, ERA fluctuations aside, essentially had the same season in 2025 as he did in 2024. If he does it again, he’ll win that third Cy. That is … if he’s still in American League. Yep, one of the major questions about Skubal remains: Is he going to be a Tiger on Opening Day? After the Trade Deadline? This time next year? [...] Julio Rodríguez, CF, Mariners  \\\\nRodríguez had an outstanding year in 2025, an improvement on his disappointing 2024 and, of course, one that ended with a division title and a trip to the ALCS. But the signature star of the Mariners’ resurgence since he won the AL Rookie of the Year Award in 2022 was, in fact, not the signature star of the Mariners this year: That would be Cal Raleigh, the Big Dumper.\", \"raw_content\": null}], \"response_time\": 0.9, \"request_id\": \"29230dc6-1244-476d-a327-ab433332ba96\"}', name='tavily_search', tool_call_id='call_8Iccvz2bfHUQIeSv3SsxfLyV'),\n",
       " ToolMessage(content='{\"query\": \"2025 NPB 우승팀\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.mlb.com/video/stats-oddities-of-2025-cal-raleigh\", \"title\": \"Stats & Oddities of 2025: Cal Raleigh - MLB.com\", \"score\": 0.4286405, \"published_date\": \"Sun, 28 Dec 2025 01:19:59 GMT\", \"content\": \"NL Central\\\\n       Image 22: Chicago Cubs Team LogoChicago Cubs Chi Cubs\\\\n       Image 23: Cincinnati Reds Team LogoCincinnati Reds Cincinnati\\\\n       Image 24: Milwaukee Brewers Team LogoMilwaukee Brewers Milwaukee\\\\n       Image 25: Pittsburgh Pirates Team LogoPittsburgh Pirates Pittsburgh\\\\n       Image 26: St. Louis Cardinals Team LogoSt. Louis Cardinals St. Louis [...] AL Central\\\\n       Image 7: Chicago White Sox Team LogoChicago White Sox Chi White Sox\\\\n       Image 8: Cleveland Guardians Team LogoCleveland Guardians Cleveland\\\\n       Image 9: Detroit Tigers Team LogoDetroit Tigers Detroit\\\\n       Image 10: Kansas City Royals Team LogoKansas City Royals Kansas City\\\\n       Image 11: Minnesota Twins Team LogoMinnesota Twins Minnesota [...] AL West\\\\n       Image 12: Athletics Team LogoAthletics Athletics\\\\n       Image 13: Houston Astros Team LogoHouston Astros Houston\\\\n       Image 14: Los Angeles Angels Team LogoLos Angeles Angels LA Angels\\\\n       Image 15: Seattle Mariners Team LogoSeattle Mariners Seattle\\\\n       Image 16: Texas Rangers Team LogoTexas Rangers Texas\", \"raw_content\": null}, {\"url\": \"https://www.mlb.com/news/mlb-teams-seeking-turnaround-2026\", \"title\": \"6 teams whose fortunes are looking up for ’26 - MLB.com\", \"score\": 0.35240287, \"published_date\": \"Mon, 29 Dec 2025 01:08:55 GMT\", \"content\": \"Nats fans have been waiting for all that youth -- on the field, and now in dugout and the front office -- to translate into on-field success. This may well be that year.\\\\n\\\\nOrioles  \\\\n2025: 75-87 (5th in AL East)\\\\n\\\\nNo team has been more aggressive than the Orioles this offseason, and for good reason: After a pair of disappointing postseasons and a truly miserable 2025, that Team Of The Future label everybody put on the Orioles was starting to gather a little mold. [...] So with 2026 just days away, we look today at six teams that aren’t exactly doing backflips about how 2025 turned out but have all sorts of reasons to be optimistic about the new year. Even after a season in which things didn’t go too well, the seeds may have been planted for a better tomorrow.\\\\n\\\\nAthletics  \\\\n2025: 76-86 (4th in AL West) [...] If another big-time starting pitcher ends up signing in Baltimore, there’s every reason to believe the Orioles’ consolidation season, the one when it all comes together, could be 2026.\\\\n\\\\nSignings & Trades  \\\\n• Latest free-agent and trade rumors  \\\\n• Top 30 free agents | Every free agent, by position  \\\\n• Tracking every team\\'s offseason moves  \\\\n• Offseason dates, rules & terms explained\\\\n\\\\nPirates  \\\\n2025: 71-91 (5th in NL Central)\", \"raw_content\": null}, {\"url\": \"https://www.foxsports.com/articles/nfl/lionsvikings-matchup-has-lost-some-luster-but-the-playoffs-are-still-possible-for-ailing-detroit\", \"title\": \"Lions-Vikings matchup has lost some luster, but the playoffs are still possible for ailing Detroit - FOX Sports\", \"score\": 0.3135884, \"published_date\": \"Wed, 24 Dec 2025 15:59:19 GMT\", \"content\": \"The Lions, at least, have a chance to return to the postseason even if they need help.\\\\n\\\\nThe roadmap is simple: Beat Minnesota on Thursday and Chicago next week and have Green Bay lose its last two games, against Baltimore on Saturday and at Minnesota in Week 18. [...] The Lions had won 15 straight times after a loss to match the league’s longest such streak with Denver (1984 to 1988) and Baltimore (2009 to 2012), according to Sportradar data, until their late rally fell short in the wild finish last week against Pittsburgh.\\\\n\\\\nThis is the first time Detroit has dropped consecutive games since starting 1-6 in 2022 during Campbell’s second season.\\\\n\\\\n## The stars go dark for the Vikings [...] my favs\\\\n\\\\nAccess and manage your favorites here\\\\n\\\\n FOX Super 6 💰\\\\n Tom Brady\\\\n\\\\n SPORTS & TEAMS\\\\n PLAYERS\\\\n SHOWS\\\\n PERSONALITIES\\\\n TOPICS\\\\n\\\\n# Lions-Vikings matchup has lost some luster, but the playoffs are still possible for ailing Detroit\\\\n\\\\nUpdated Dec. 24, 2025 10:59 a.m. ET\\\\n\\\\nshare\\\\n\\\\nfacebookxredditlink\\\\n\\\\nAssociated Press\", \"raw_content\": null}, {\"url\": \"https://biz.chosun.com/en/en-sports/2025/12/30/FPKVGQ2RQJAM7NE64IQSXJTGDA/\", \"title\": \"Okamoto Kazuma heads to US to seek MLB deal - CHOSUNBIZ - Chosunbiz\", \"score\": 0.20315401, \"published_date\": \"Tue, 30 Dec 2025 01:49:33 GMT\", \"content\": \"EnglishSports\\\\n\\\\n# Okamoto Kazuma heads to US to seek MLB deal\\\\n\\\\nBy \\\\n\\\\nOSEN\\\\n\\\\nPublished 2025.12.30. 10:49\\\\n\\\\nYomiuri Giants\\' Okamoto Kazuma (29) of Nippon Professional Baseball (NPB) has headed to the United States to pursue a move to the major leagues.\\\\n\\\\nMLB.com, the official major league outlet, reported on the 30th (Korean time) that NPB star Okamoto Kazuma crossed over to the United States to meet with major league teams ahead of the posting deadline. [...] This year\\'s major league winter meetings feature many Asian position players challenging the big leagues. Kiwoom Heroes\\' Song Seong-mun of the KBO League signed a four-year, $15 million aggregate contract with the San Diego Padres (about 21.5 billion won), and Yakult Swallows\\' Murakami Munetaka of NPB signed a two-year, $34 million contract with the Chicago White Sox (about 48.7 billion won).\", \"raw_content\": null}, {\"url\": \"https://www.si.com/mlb/giants/onsi/san-francisco-giants-news/how-giants-pitching-prospect-poised-breakout-season-2026\", \"title\": \"How New Giants Pitching Prospect is Poised for Breakout Season in 2026 - Sports Illustrated\", \"score\": 0.17418572, \"published_date\": \"Tue, 30 Dec 2025 01:00:00 GMT\", \"content\": \"The opportunity will be there for the right-hander. Logan Webb and Robbie Ray are at the top of the rotation. Adrian Houser will likely be an innings-eating No. 3 starter. The rest of the rotation is up for grabs. Landen Roupp has the inside track to a job but not a lock. Carson Whisenhut, Trevor McDonald and Carson Seymour are also part of the equation. Webb’s commitment to the World Baseball Classic should provide opportunities for Tidwell and the rest of the contenders to impress first-year\", \"raw_content\": null}], \"response_time\": 0.0, \"request_id\": \"5f2a08f3-aa43-4faa-8b3b-aa131e2b0def\"}', name='tavily_search', tool_call_id='call_H7lYocyJ1Y6G3RJWOskatfG4')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tool의 처리(응답) 결과를 LLM 요청시 사용\n",
    "- ToolMessage를 prompt 에 추가하여 LLM에 요청한다.\n",
    "- ToolMessage 는 Tool Calling 정보를 가진 AIMessage 다음에 들어와야 한다.\n",
    "- Prompt 순서\n",
    "    1. 일반 prompt (system, 대화 history, .., human)\n",
    "    2. AIMessage: tool calling 정보를 가진 AIMessage. (tool_model에 질의 받은 tool calling 정보가 있는 응답)\n",
    "    3. ToolMessage:  Tool의 처리 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search',\n",
       "  'args': {'query': '2025 KBO 챔피언 우승팀 2025 KBO 한국시리즈 우승',\n",
       "   'search_depth': 'advanced',\n",
       "   'topic': 'news',\n",
       "   'include_images': False},\n",
       "  'id': 'call_LlpQbREbqAZR3Y543lbbxY1H',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"당신은 AI Assistant 입니다. 제공된 정보를 바탕으로 답변을 해주세요.\"),\n",
    "        (\"human\", \"{query}\"),\n",
    "        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | tool_model\n",
    "final_result = chain.invoke(\n",
    "    {\n",
    "        \"query\": query,\n",
    "        \"tool_messages\":[result, *search_result_list] \n",
    "        # result는 toolcall 정보가 있는 AIMessage. 어떤 콜을 했는지에 대한 정보.\n",
    "        # *search_result_list : ToolMessage이고 Tool의 처리결과이다.\n",
    "    }\n",
    ")\n",
    "final_result.tool_calls # -> tool 호출 -> llm 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(final_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_tavily\\tavily_research.py:97: UserWarning: Field name \"output_schema\" in \"TavilyResearch\" shadows an attribute in parent \"BaseTool\"\n",
      "  class TavilyResearch(BaseTool):  # type: ignore[override, override]\n",
      "c:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_tavily\\tavily_research.py:97: UserWarning: Field name \"stream\" in \"TavilyResearch\" shadows an attribute in parent \"BaseTool\"\n",
      "  class TavilyResearch(BaseTool):  # type: ignore[override, override]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################\n",
    "# Agent chain을 구성\n",
    "############################\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_tavily import TavilySearch\n",
    "from dotenv import load_dotenv\n",
    "from datetime import date\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_search = TavilySearch()\n",
    "model = ChatOpenAI(model=\"gpt-5-mini\")\n",
    "\n",
    "tool_model = model.bind_tools(tools=[tavily_search]) # 모델에 TOOL을 Binding\n",
    "\n",
    "system_message = \"\"\"# Instruction\n",
    "당신은 다양한 질문에 답을 하는 AI assistant 입니다.\n",
    "사용자 질문에 대해 최신 정보를 바탕으로 답변해주세요.\n",
    "오늘 날짜는 {today} 입니다.\n",
    "필요하다면 tool을 이용해 답변에 필요한 정보를 수집합니다.\n",
    "당신이 사용할 수 있는 TOOL은 다음과 같습니다.\n",
    "- tavily_search: 웹 검색 툴\"\"\"\n",
    "today = date.today().strftime(\"%Y년 %m월 %d일\") # %H시간, %M: 분, %S: 초.\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", \"{query}\"),\n",
    "        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\n",
    "    ],\n",
    "    partial_variables={\"today\":today}\n",
    ")\n",
    "\n",
    "tool_model_chain = prompt | tool_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def websearch_agent(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Agent 전체 흐름을 처리하는 Runnable\n",
    "    사용자 질문(query)을 받아서 tool_model과 tool을 이용해서 최종 응답을 반환한다.\n",
    "    ReAct 구조로 구성. (ReAct Loop)\n",
    "    \"\"\"\n",
    "    ai_message = tool_model_chain({\"query\":query}) # 반환:1, 슬제응답 또는 \n",
    "    messages = []\n",
    "    # 만약 툴콜이 값이 있다면\n",
    "    while ai_message.tool_calls:\n",
    "        # tool_messages = tavily_search.batch()(ai_message.tool_calls)\n",
    "        tool_messages = []\n",
    "        for tool_call in ai_message.tool_calls:\n",
    "            # name = tool_call.name\n",
    "            # if name == \"search_wiki\":\n",
    "            #     tool_msg = search_wiki.invoke(tool_call)\n",
    "            # elif name == \"search_menu\":\n",
    "            #     tool_msg = search_menu.invoke(tool_call)\n",
    "            # elif name == \"tavily_search\":\n",
    "            #     tool_msg = tavily_search.invoke(tool_call)\n",
    "            tool_msg = globals()[tool_call[\"name\"]].invoke(tool_call)\n",
    "            tool_messages.append(tool_msg)\n",
    "\n",
    "        # tavily_search.batch()(ai_message.tool_calls)\n",
    "        messages.extend([ai_message, *tool_messages])\n",
    "        ai_message = tool_model_chain.invoke({\"query\": query,\"tool_messages\" :messages})\n",
    "\n",
    "    messages.append(ai_message)\n",
    "    return ai_message.content, messages # AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RunnableSequence' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res = \u001b[43mwebsearch_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m파스타 메뉴를 추천해줘. 그리고 파스타의 유래에 대해 설명해줘.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4871\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4856\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this `Runnable` synchronously.\u001b[39;00m\n\u001b[32m   4857\u001b[39m \n\u001b[32m   4858\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4868\u001b[39m \n\u001b[32m   4869\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4870\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4872\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4873\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4875\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4876\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4877\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4878\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2058\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2054\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   2055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2056\u001b[39m         output = cast(\n\u001b[32m   2057\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2058\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2059\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2060\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2061\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2062\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2066\u001b[39m         )\n\u001b[32m   2067\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2068\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:433\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    432\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4728\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input_, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4726\u001b[39m                 output = chunk\n\u001b[32m   4727\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4728\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4729\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4730\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4731\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:433\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    432\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mwebsearch_agent\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;129m@chain\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwebsearch_agent\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      3\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    Agent 전체 흐름을 처리하는 Runnable\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    사용자 질문(query)을 받아서 tool_model과 tool을 이용해서 최종 응답을 반환한다.\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m    ReAct 구조로 구성. (ReAct Loop)\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     ai_message = \u001b[43mtool_model_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 반환:1, 슬제응답 또는 \u001b[39;00m\n\u001b[32m      9\u001b[39m     messages = []\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# 만약 툴콜이 값이 있다면\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'RunnableSequence' object is not callable"
     ]
    }
   ],
   "source": [
    "res = websearch_agent.invoke(\"파스타 메뉴를 추천해줘. 그리고 파스타의 유래에 대해 설명해줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': '__main__',\n",
       " '__doc__': 'Automatically created module for IPython interactive environment',\n",
       " '__package__': None,\n",
       " '__loader__': None,\n",
       " '__spec__': None,\n",
       " '__builtin__': <module 'builtins' (built-in)>,\n",
       " '__builtins__': <module 'builtins' (built-in)>,\n",
       " '_ih': ['',\n",
       "  '# 문서 Load\\nimport os\\n# 메뉴읽어 오기\\nmenu_file_path = \"data/restaurant_menu.txt\"\\nwith open(menu_file_path, \"r\", encoding=\"utf-8\") as f:\\n    menu = f.read()',\n",
       "  '# Split - 메뉴별로 분리하기 위해 직접 처리\\nfrom langchain_core.documents import Document\\nimport re\\nfrom pprint import pprint\\n\\ndef create_documents(menu_all: str, file_name) -> list[Document]:\\n    \"\"\"메뉴별로 분리 한뒤 Document로 변환. 변환된 Document들을 리스트로 반환\\n    metadata: 메뉴이름, 주요 재료, 가격, source(파일이름)\\n    \"\"\"\\n    menu_list = menu_all.split(\"\\\\n\\\\n\")\\n    menu_documents = [] # 개별 메뉴로 Document를 생성. 그것들을 저장할 list를 만듬.\\n    for menu_item in menu_list:\\n\\n        # 메뉴 이름 추출\\n        menu_name_pattern = r\"(^\\\\d+.\\\\s)([가-힣a-zA-Z\\\\d ]+)\" \\n        # (^\\\\d+.\\\\s) : 숫자로 시작. 그다음 . 그러고 공백.\\n        # 숫자가 있어서 후방 검색이 안됨.\\n        menu_name_result = re.search(menu_name_pattern, menu_item)\\n        menu_name = menu_name_result.group(2).strip()  # 메뉴 이름 추출 # 1은 번호\\n\\n        # 주요재료 추출 - text로 indexing.\\n        menu_ingredient_pattern = r\"(?<=주요 재료: ).+\" # ?<= 검색할 때 쓰지만, 값은 주지마.\\n        ingredients = re.search(menu_ingredient_pattern, menu_item).group().strip()\\n\\n        # 가격추출\\n        price_pattern = r\"(?<=가격: )[\\\\d,]+(?=원)\"\\n        # 전방 후방탐색 동시에. 가격과 원을 검색할때 쓰지만, 값은 필요 없음.\\n        price_result = re.search(price_pattern, menu_item)\\n        price = int(price_result.group().replace(\",\", \"\")) # 숫자에서 쉼표 지워버림.\\n\\n\\n        # 메뉴 이름을 제외한 나머지는 메뉴 설명으로 간주\\n        menu_doc = Document(\\n            page_content=menu_item,     # 메뉴 설명을 page_content에 넣는다. metadata는 나중에 따로 따로 payload filtering 할 수있기 때문에 \\n            metadata={\\n                \"menu_name\": menu_name, # 메뉴 이름\\n                \"price\": price,         # 가격\\n                \"ingredients\": ingredients, # 재료 리스트\\n                \"source\": file_name     # 메뉴가 저장된 파일 이름\\n            }\\n        )\\n        menu_documents.append(menu_doc)\\n    return menu_documents\\n\\n\\nmenu_documents = create_documents(menu, menu_file_path)\\nprint(len(menu_documents))\\nmenu_documents[0]',\n",
       "  '# VectorDB 저장 및 VectorStore 생성\\nfrom langchain_qdrant import QdrantVectorStore\\nfrom langchain_openai import OpenAIEmbeddings\\nfrom qdrant_client import QdrantClient\\nfrom qdrant_client.http.models import Distance, VectorParams\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\nCOLLECTION_NAME = \"restaurant_menu\"\\nVECTOR_SIZE = 1536  # OpenAIEmbeddings의 벡터 크기\\n\\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\\n\\nclient = QdrantClient(host=\"localhost\", port=6333)\\nif client.collection_exists(COLLECTION_NAME):\\n    client.delete_collection(COLLECTION_NAME)\\n\\n# Collection 생성\\nclient.create_collection(\\n    collection_name=COLLECTION_NAME,\\n    # 벡터 저장소에 대한 설정. - vector_config는 default이므로 이름을 안줘도 됨(default 로 잡힘) 이름을 줄 거면 {\"이름\":VectorParams()} 설정\\n    vectors_config=VectorParams(\\n        size=VECTOR_SIZE, \\n        distance=Distance.COSINE\\n    )\\n)\\n\\nvectorstore = QdrantVectorStore(\\n    client=client, # QdrantClient\\n    embedding=embeddings, # Embedding Model\\n    collection_name=COLLECTION_NAME # 연결할 Collection 지정.\\n)\\nids = vectorstore.add_documents(menu_documents)\\nprint(f\"저장된 문서 개수: {len(ids)}\")\\n##################################################\\n# Retriever 생성\\n##################################################\\nmenu_retriever = vectorstore.as_retriever(\\n    search_kwargs={\"k\": 3}  # 검색할 결과 개수\\n)\\n\\nfrom langchain_core.runnables import ConfigurableField\\nretriever = menu_retriever.configurable_fields(\\n    search_type=ConfigurableField(\\n        id=\"search_type\"\\n    ),\\n    search_kwargs=ConfigurableField(\\n        id=\"search_kwargs\"\\n    ),\\n)',\n",
       "  '# VectorDB 저장 및 VectorStore 생성\\nfrom langchain_qdrant import QdrantVectorStore\\nfrom langchain_openai import OpenAIEmbeddings\\nfrom qdrant_client import QdrantClient\\nfrom qdrant_client.http.models import Distance, VectorParams\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\nCOLLECTION_NAME = \"restaurant_menu\"\\nVECTOR_SIZE = 1536  # OpenAIEmbeddings의 벡터 크기\\n\\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\\n\\nclient = QdrantClient(host=\"localhost\", port=6333)\\nif client.collection_exists(COLLECTION_NAME):\\n    client.delete_collection(COLLECTION_NAME)\\n\\n# Collection 생성\\nclient.create_collection(\\n    collection_name=COLLECTION_NAME,\\n    # 벡터 저장소에 대한 설정. - vector_config는 default이므로 이름을 안줘도 됨(default 로 잡힘) 이름을 줄 거면 {\"이름\":VectorParams()} 설정\\n    vectors_config=VectorParams(\\n        size=VECTOR_SIZE, \\n        distance=Distance.COSINE\\n    )\\n)\\n\\nvectorstore = QdrantVectorStore(\\n    client=client, # QdrantClient\\n    embedding=embeddings, # Embedding Model\\n    collection_name=COLLECTION_NAME # 연결할 Collection 지정.\\n)\\nids = vectorstore.add_documents(menu_documents)\\nprint(f\"저장된 문서 개수: {len(ids)}\")\\n##################################################\\n# Retriever 생성\\n##################################################\\nmenu_retriever = vectorstore.as_retriever(\\n    search_kwargs={\"k\": 3}  # 검색할 결과 개수\\n)\\n\\nfrom langchain_core.runnables import ConfigurableField\\nretriever = menu_retriever.configurable_fields(\\n    search_type=ConfigurableField(\\n        id=\"search_type\"\\n    ),\\n    search_kwargs=ConfigurableField(\\n        id=\"search_kwargs\"\\n    ),\\n)',\n",
       "  '# Split - 메뉴별로 분리하기 위해 직접 처리\\nfrom langchain_core.documents import Document\\nimport re\\nfrom pprint import pprint\\n\\ndef create_documents(menu_all: str, file_name) -> list[Document]:\\n    \"\"\"메뉴별로 분리 한뒤 Document로 변환. 변환된 Document들을 리스트로 반환\\n    metadata: 메뉴이름, 주요 재료, 가격, source(파일이름)\\n    \"\"\"\\n    menu_list = menu_all.split(\"\\\\n\\\\n\")\\n    menu_documents = [] # 개별 메뉴로 Document를 생성. 그것들을 저장할 list를 만듬.\\n    for menu_item in menu_list:\\n\\n        # 메뉴 이름 추출\\n        menu_name_pattern = r\"(^\\\\d+.\\\\s)([가-힣a-zA-Z\\\\d ]+)\" \\n        # (^\\\\d+.\\\\s) : 숫자로 시작. 그다음 . 그러고 공백.\\n        # 숫자가 있어서 후방 검색이 안됨.\\n        menu_name_result = re.search(menu_name_pattern, menu_item)\\n        menu_name = menu_name_result.group(2).strip()  # 메뉴 이름 추출 # 1은 번호\\n\\n        # 주요재료 추출 - text로 indexing.\\n        menu_ingredient_pattern = r\"(?<=주요 재료: ).+\" # ?<= 검색할 때 쓰지만, 값은 주지마.\\n        ingredients = re.search(menu_ingredient_pattern, menu_item).group().strip()\\n\\n        # 가격추출\\n        price_pattern = r\"(?<=가격: )[\\\\d,]+(?=원)\"\\n        # 전방 후방탐색 동시에. 가격과 원을 검색할때 쓰지만, 값은 필요 없음.\\n        price_result = re.search(price_pattern, menu_item)\\n        price = int(price_result.group().replace(\",\", \"\")) # 숫자에서 쉼표 지워버림.\\n\\n\\n        # 메뉴 이름을 제외한 나머지는 메뉴 설명으로 간주\\n        menu_doc = Document(\\n            page_content=menu_item,     # 메뉴 설명을 page_content에 넣는다. metadata는 나중에 따로 따로 payload filtering 할 수있기 때문에 \\n            metadata={\\n                \"menu_name\": menu_name, # 메뉴 이름\\n                \"price\": price,         # 가격\\n                \"ingredients\": ingredients, # 재료 리스트\\n                \"source\": file_name     # 메뉴가 저장된 파일 이름\\n            }\\n        )\\n        menu_documents.append(menu_doc)\\n    return menu_documents\\n\\n\\nmenu_documents = create_documents(menu, menu_file_path)\\nprint(len(menu_documents))\\nmenu_documents[0]',\n",
       "  '# 문서 Load\\nimport os\\n# 메뉴읽어 오기\\nmenu_file_path = \"data/restaurant_menu.txt\"\\nwith open(menu_file_path, \"r\", encoding=\"utf-8\") as f:\\n    menu = f.read()',\n",
       "  '# Split - 메뉴별로 분리하기 위해 직접 처리\\nfrom langchain_core.documents import Document\\nimport re\\nfrom pprint import pprint\\n\\ndef create_documents(menu_all: str, file_name) -> list[Document]:\\n    \"\"\"메뉴별로 분리 한뒤 Document로 변환. 변환된 Document들을 리스트로 반환\\n    metadata: 메뉴이름, 주요 재료, 가격, source(파일이름)\\n    \"\"\"\\n    menu_list = menu_all.split(\"\\\\n\\\\n\")\\n    menu_documents = [] # 개별 메뉴로 Document를 생성. 그것들을 저장할 list를 만듬.\\n    for menu_item in menu_list:\\n\\n        # 메뉴 이름 추출\\n        menu_name_pattern = r\"(^\\\\d+.\\\\s)([가-힣a-zA-Z\\\\d ]+)\" \\n        # (^\\\\d+.\\\\s) : 숫자로 시작. 그다음 . 그러고 공백.\\n        # 숫자가 있어서 후방 검색이 안됨.\\n        menu_name_result = re.search(menu_name_pattern, menu_item)\\n        menu_name = menu_name_result.group(2).strip()  # 메뉴 이름 추출 # 1은 번호\\n\\n        # 주요재료 추출 - text로 indexing.\\n        menu_ingredient_pattern = r\"(?<=주요 재료: ).+\" # ?<= 검색할 때 쓰지만, 값은 주지마.\\n        ingredients = re.search(menu_ingredient_pattern, menu_item).group().strip()\\n\\n        # 가격추출\\n        price_pattern = r\"(?<=가격: )[\\\\d,]+(?=원)\"\\n        # 전방 후방탐색 동시에. 가격과 원을 검색할때 쓰지만, 값은 필요 없음.\\n        price_result = re.search(price_pattern, menu_item)\\n        price = int(price_result.group().replace(\",\", \"\")) # 숫자에서 쉼표 지워버림.\\n\\n\\n        # 메뉴 이름을 제외한 나머지는 메뉴 설명으로 간주\\n        menu_doc = Document(\\n            page_content=menu_item,     # 메뉴 설명을 page_content에 넣는다. metadata는 나중에 따로 따로 payload filtering 할 수있기 때문에 \\n            metadata={\\n                \"menu_name\": menu_name, # 메뉴 이름\\n                \"price\": price,         # 가격\\n                \"ingredients\": ingredients, # 재료 리스트\\n                \"source\": file_name     # 메뉴가 저장된 파일 이름\\n            }\\n        )\\n        menu_documents.append(menu_doc)\\n    return menu_documents\\n\\n\\nmenu_documents = create_documents(menu, menu_file_path)\\nprint(len(menu_documents))\\nmenu_documents[0]',\n",
       "  '# VectorDB 저장 및 VectorStore 생성\\nfrom langchain_qdrant import QdrantVectorStore\\nfrom langchain_openai import OpenAIEmbeddings\\nfrom qdrant_client import QdrantClient\\nfrom qdrant_client.http.models import Distance, VectorParams\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\nCOLLECTION_NAME = \"restaurant_menu\"\\nVECTOR_SIZE = 1536  # OpenAIEmbeddings의 벡터 크기\\n\\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\\n\\nclient = QdrantClient(host=\"localhost\", port=6333)\\nif client.collection_exists(COLLECTION_NAME):\\n    client.delete_collection(COLLECTION_NAME)\\n\\n# Collection 생성\\nclient.create_collection(\\n    collection_name=COLLECTION_NAME,\\n    # 벡터 저장소에 대한 설정. - vector_config는 default이므로 이름을 안줘도 됨(default 로 잡힘) 이름을 줄 거면 {\"이름\":VectorParams()} 설정\\n    vectors_config=VectorParams(\\n        size=VECTOR_SIZE, \\n        distance=Distance.COSINE\\n    )\\n)\\n\\nvectorstore = QdrantVectorStore(\\n    client=client, # QdrantClient\\n    embedding=embeddings, # Embedding Model\\n    collection_name=COLLECTION_NAME # 연결할 Collection 지정.\\n)\\nids = vectorstore.add_documents(menu_documents)\\nprint(f\"저장된 문서 개수: {len(ids)}\")\\n##################################################\\n# Retriever 생성\\n##################################################\\nmenu_retriever = vectorstore.as_retriever(\\n    search_kwargs={\"k\": 3}  # 검색할 결과 개수\\n)\\n\\nfrom langchain_core.runnables import ConfigurableField\\nretriever = menu_retriever.configurable_fields(\\n    search_type=ConfigurableField(\\n        id=\"search_type\"\\n    ),\\n    search_kwargs=ConfigurableField(\\n        id=\"search_kwargs\"\\n    ),\\n)',\n",
       "  'query=\"쇠고기를 재료로 하는 음식은 뭐가 있어?\"\\nresult = retriever.invoke(query)\\n\\nfor doc in result:\\n    print(doc.metadata)',\n",
       "  '# Retriever를 tool로 사용\\n# 쿼리를 입력 받아서 retriever로 검색해서 그 결과를 반환하는 tool을 직접 구현\\n@tool\\ndef search_menu(query:str) -> str:\\n    \"\"\"VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\\n    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\\n\\n    Args:\\n        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\\n    Return:\\n        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.\\n    \"\"\"\\n    result_list = []\\n    docs = retriever.invoke(query)\\n    for doc in docs:\\n        result_list.append({\"content\":doc.page_content, \\n                            \"title\":doc.metadata[\\'menu_name\\'],\\n                            \"url\":doc.metadata[\\'source\\']\\n                            })\\n    if result_list:\\n        result = {\"result\": result_list}\\n    else:\\n        result = {\"result\":\"검색된 메뉴가 없습니다.\"}\\n\\n    return json.dumps(result, ensure_ascii=False)',\n",
       "  'from langchain_core.tools import tool\\n# Retriever를 tool로 사용\\n# 쿼리를 입력 받아서 retriever로 검색해서 그 결과를 반환하는 tool을 직접 구현\\n@tool\\ndef search_menu(query:str) -> str:\\n    \"\"\"VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\\n    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\\n\\n    Args:\\n        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\\n    Return:\\n        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.\\n    \"\"\"\\n    result_list = []\\n    docs = retriever.invoke(query)\\n    for doc in docs:\\n        result_list.append({\"content\":doc.page_content, \\n                            \"title\":doc.metadata[\\'menu_name\\'],\\n                            \"url\":doc.metadata[\\'source\\']\\n                            })\\n    if result_list:\\n        result = {\"result\": result_list}\\n    else:\\n        result = {\"result\":\"검색된 메뉴가 없습니다.\"}\\n\\n    return json.dumps(result, ensure_ascii=False)',\n",
       "  'print(search_menu.name)\\nprint(search_menu.description)\\nprint(search_menu.schema',\n",
       "  'print(search_menu.name)\\nprint(search_menu.description)\\nprint(search_menu.schema)',\n",
       "  'tool_model = ChatOpenAI(\"gpt-5-mini\").bind_tools(tools=[search_menu])\\nres = tool_model.invoke(\"식당 메뉴 중\")',\n",
       "  'tool_model = ChatOpenAI(model=\"gpt-5-mini\").bind_tools(tools=[search_menu])\\nres = tool_model.invoke(\"식당 메뉴 중 면요리를 추천해줘.\")',\n",
       "  '############################\\n# Agent chain을 구성\\n############################\\nfrom langchain_openai import ChatOpenAI\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_core.runnables import chain\\nfrom langchain_tavily import TavilySearch\\nfrom dotenv import load_dotenv\\nfrom datetime import date\\n\\nload_dotenv()',\n",
       "  'tool_model = ChatOpenAI(model=\"gpt-5-mini\").bind_tools(tools=[search_menu])\\nres = tool_model.invoke(\"식당 메뉴 중 면요리를 추천해줘.\")',\n",
       "  'res.tool_calls',\n",
       "  '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()',\n",
       "  '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(\"gpt-5.2\").bind_tools(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       "  '# Runnable을 tool로 변환 -> as_tools\\n## args_schema 설정\\nclass WikiSearchParameterSchema(BaseModel):\\n    query: str = Field(..., description=\"Wikipedia 에서 검색할 keyword\")\\n    max_results: int = Field(description=\"검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.\")\\n\\nsearch_wiki = wikipedia_search.as_tool(\\n    args_schema=WikiSearchParameterSchema,\\n    name=\"search_wiki\",\\n    description=\"\"\"이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다. \\n\"\"\"\\n)',\n",
       "  '# Runnable을 tool로 변환 -> as_tools\\n## args_schema 설정\\nclass WikiSearchParameterSchema(BaseModel):\\n    query: str = Field(..., description=\"Wikipedia 에서 검색할 keyword\")\\n    max_results: int = Field(description=\"검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.\")\\n\\nsearch_wiki = wikipedia_search.as_tool(\\n    args_schema=WikiSearchParameterSchema,\\n    name=\"search_wiki\",\\n    description=\"\"\"이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다. \\n\"\"\"\\n)',\n",
       "  'from langchain_core.tools import tool\\n\\n@tool\\ndef plus(num1:int|float, num2:int|float) -> int|float:\\n    \"\"\"두개 수를 받아서 덧셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\\n    return num1 + num2\\n\\n@tool\\ndef minus(num1:int|float, num2:int|float) -> int|float:\\n    \"\"\"두개 수를 받아서 뺄셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\\n    return num1 - num2\\n\\n@tool\\ndef multiply(num1:int|float, num2:int|float) -> int|float:\\n    \"\"\"두개 수를 받아서 곱셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\\n    return num1 * num2\\n\\n# 파라미터에 대한 자세한 설명이 들어가야 하는 경우 -> Pydantic\\nfrom pydantic import BaseModel, Field\\nclass DivideParameterSchema(BaseModel):\\n    num1: int|float = Field(..., description=\"나눌떄 사용할 첫번째 값\")\\n    num2: int|float = Field(..., description=\"나눌때 사용할 두번째 값\")\\n\\n@tool(\"divide_tool\", args_schema=DivideParameterSchema)\\ndef divide(num1:int|float, num2:int|float) -> int|float:\\n    \"\"\"두개 수를 받아서 나눗셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\\n    return num1 / num2',\n",
       "  '# Runnable을 tool로 변환 -> as_tools\\n## args_schema 설정\\nclass WikiSearchParameterSchema(BaseModel):\\n    query: str = Field(..., description=\"Wikipedia 에서 검색할 keyword\")\\n    max_results: int = Field(description=\"검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.\")\\n\\nsearch_wiki = wikipedia_search.as_tool(\\n    args_schema=WikiSearchParameterSchema,\\n    name=\"search_wiki\",\\n    description=\"\"\"이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다. \\n\"\"\"\\n)',\n",
       "  'from langchain_community.document_loaders import WikipediaLoader # 위키백과 사전 내용을 크롤링해서 문서로 반환.\\nfrom pydantic import BaseModel, Field\\nfrom langchain_core.runnables import chain\\nimport json\\n\\n@chain\\ndef wikipedia_search(inputs:dict) -> str:\\n    \"\"\"사용자 query를 위키백과사전에서 검색하고 검색 결과 중 k개 문서를 반환한다.\\n    Args:\\n        inputs(dict): query-검색할 키워드, max_results(int): 반환할 검색 결과수 를 받는다.\\n    Returns:\\n        str - 검색 결과를 json 으로 반환.\\n              형식: {\"result\":[{검색문서1}, {검색문서2}, ...]}. 검색 문서(dict) - content, url, title로 구성\\n              검색결과가 없을 경우 : {\"result\": \"결과없음\"} 반환.\\n    \"\"\"\\n    query = inputs[\"query\"]\\n    max_results = inputs.get(\"max_results\", 5)\\n    loader = WikipediaLoader(query=query, load_max_docs=max_results, lang=\"ko\")\\n    docs = loader.load() #list[Document]\\n\\n    result_list = []\\n    for doc in docs:\\n        result_list.append({\"content\":doc.page_content, \\n                            \"title\":doc.metadata.get(\\'title\\'),\\n                            \"url\":doc.metadata.get(\"source\")\\n                            })\\n    if result_list:\\n        result = {\"result\": result_list}\\n    else:\\n        result = {\"result\": \"검색 결과가 없습니다.\"}\\n\\n    # JSON 문자열로 변환해서 반환. #json.load() : json문자열을 파이썬 자료구조(dict나 list)로 변환.\\n    return json.dumps(result, ensure_ascii=False) #json.dumps() : 파이썬 자료구조(dict나 list)->json문자열.\\n    # escape_ascii=False: 한글 문자가 나오도록 처리. True: 한글이 유니코드 escape 문자로 나옴(\\\\uxxxx)',\n",
       "  '# Runnable을 tool로 변환 -> as_tools\\n## args_schema 설정\\nclass WikiSearchParameterSchema(BaseModel):\\n    query: str = Field(..., description=\"Wikipedia 에서 검색할 keyword\")\\n    max_results: int = Field(description=\"검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.\")\\n\\nsearch_wiki = wikipedia_search.as_tool(\\n    args_schema=WikiSearchParameterSchema,\\n    name=\"search_wiki\",\\n    description=\"\"\"이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다. \\n\"\"\"\\n)',\n",
       "  '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(\"gpt-5.2\").bind_tools(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       "  '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(\"gpt-5.2\").bind_tools(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       "  '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(\"gpt-5.2\").bind_tool(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       "  '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(model=\"gpt-5.2\").bind_tools(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       "  'res = tool_model_chain.invoke({\"query\":\"파스타 메뉴를 추천해주고 파스타 유래나 역사를 알려줘.\"})',\n",
       "  'from langchain_core.tools import tool\\n# Retriever를 tool로 사용\\n# 쿼리를 입력 받아서 retriever로 검색해서 그 결과를 반환하는 tool을 직접 구현\\n@tool\\ndef search_menu(query:str) -> str:\\n    \"\"\"VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\\n    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\\n\\n    Args:\\n        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\\n    Return:\\n        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.\\n    \"\"\"\\n    result_list = []\\n    docs = retriever.invoke(query)\\n    for doc in docs:\\n        result_list.append({\"content\":doc.page_content, \\n                            \"title\":doc.metadata[\\'menu_name\\'],\\n                            \"url\":doc.metadata[\\'source\\']\\n                            })\\n    if result_list:\\n        result = {\"result\": result_list}\\n    else:\\n        result = {\"result\":\"검색된 메뉴가 없습니다.\"}\\n\\n    return json.dumps(result, ensure_ascii=False)',\n",
       "  'res = tool_model_chain.invoke({\"query\":\"파스타 메뉴를 추천해주고 파스타 유래나 역사를 알려줘.\"})',\n",
       "  'res = tool_model_chain.invoke({\"query\":\"파스타 메뉴를 추천해주고 파스타 유래나 역사를 알려줘.\"})',\n",
       "  'globals() # 전역변수로 등록된 모든 변수, 함수들을 dictionary 제공. key: \"이름\", value: 변수/함수/클래스'],\n",
       " '_oh': {2: Document(metadata={'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt'}, page_content='1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.'),\n",
       "  5: Document(metadata={'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt'}, page_content='1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.'),\n",
       "  7: Document(metadata={'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt'}, page_content='1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.'),\n",
       "  16: True,\n",
       "  18: [{'name': 'search_menu',\n",
       "    'args': {'query': '면요리'},\n",
       "    'id': 'call_3icxEAYHczcNopeViNioXr24',\n",
       "    'type': 'tool_call'}],\n",
       "  19: True},\n",
       " '_dh': [WindowsPath('c:/Users/Playdata/Documents/SKN21_2/SKN21/10_langchain')],\n",
       " 'In': ['',\n",
       "  '# 문서 Load\\nimport os\\n# 메뉴읽어 오기\\nmenu_file_path = \"data/restaurant_menu.txt\"\\nwith open(menu_file_path, \"r\", encoding=\"utf-8\") as f:\\n    menu = f.read()',\n",
       "  '# Split - 메뉴별로 분리하기 위해 직접 처리\\nfrom langchain_core.documents import Document\\nimport re\\nfrom pprint import pprint\\n\\ndef create_documents(menu_all: str, file_name) -> list[Document]:\\n    \"\"\"메뉴별로 분리 한뒤 Document로 변환. 변환된 Document들을 리스트로 반환\\n    metadata: 메뉴이름, 주요 재료, 가격, source(파일이름)\\n    \"\"\"\\n    menu_list = menu_all.split(\"\\\\n\\\\n\")\\n    menu_documents = [] # 개별 메뉴로 Document를 생성. 그것들을 저장할 list를 만듬.\\n    for menu_item in menu_list:\\n\\n        # 메뉴 이름 추출\\n        menu_name_pattern = r\"(^\\\\d+.\\\\s)([가-힣a-zA-Z\\\\d ]+)\" \\n        # (^\\\\d+.\\\\s) : 숫자로 시작. 그다음 . 그러고 공백.\\n        # 숫자가 있어서 후방 검색이 안됨.\\n        menu_name_result = re.search(menu_name_pattern, menu_item)\\n        menu_name = menu_name_result.group(2).strip()  # 메뉴 이름 추출 # 1은 번호\\n\\n        # 주요재료 추출 - text로 indexing.\\n        menu_ingredient_pattern = r\"(?<=주요 재료: ).+\" # ?<= 검색할 때 쓰지만, 값은 주지마.\\n        ingredients = re.search(menu_ingredient_pattern, menu_item).group().strip()\\n\\n        # 가격추출\\n        price_pattern = r\"(?<=가격: )[\\\\d,]+(?=원)\"\\n        # 전방 후방탐색 동시에. 가격과 원을 검색할때 쓰지만, 값은 필요 없음.\\n        price_result = re.search(price_pattern, menu_item)\\n        price = int(price_result.group().replace(\",\", \"\")) # 숫자에서 쉼표 지워버림.\\n\\n\\n        # 메뉴 이름을 제외한 나머지는 메뉴 설명으로 간주\\n        menu_doc = Document(\\n            page_content=menu_item,     # 메뉴 설명을 page_content에 넣는다. metadata는 나중에 따로 따로 payload filtering 할 수있기 때문에 \\n            metadata={\\n                \"menu_name\": menu_name, # 메뉴 이름\\n                \"price\": price,         # 가격\\n                \"ingredients\": ingredients, # 재료 리스트\\n                \"source\": file_name     # 메뉴가 저장된 파일 이름\\n            }\\n        )\\n        menu_documents.append(menu_doc)\\n    return menu_documents\\n\\n\\nmenu_documents = create_documents(menu, menu_file_path)\\nprint(len(menu_documents))\\nmenu_documents[0]',\n",
       "  '# VectorDB 저장 및 VectorStore 생성\\nfrom langchain_qdrant import QdrantVectorStore\\nfrom langchain_openai import OpenAIEmbeddings\\nfrom qdrant_client import QdrantClient\\nfrom qdrant_client.http.models import Distance, VectorParams\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\nCOLLECTION_NAME = \"restaurant_menu\"\\nVECTOR_SIZE = 1536  # OpenAIEmbeddings의 벡터 크기\\n\\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\\n\\nclient = QdrantClient(host=\"localhost\", port=6333)\\nif client.collection_exists(COLLECTION_NAME):\\n    client.delete_collection(COLLECTION_NAME)\\n\\n# Collection 생성\\nclient.create_collection(\\n    collection_name=COLLECTION_NAME,\\n    # 벡터 저장소에 대한 설정. - vector_config는 default이므로 이름을 안줘도 됨(default 로 잡힘) 이름을 줄 거면 {\"이름\":VectorParams()} 설정\\n    vectors_config=VectorParams(\\n        size=VECTOR_SIZE, \\n        distance=Distance.COSINE\\n    )\\n)\\n\\nvectorstore = QdrantVectorStore(\\n    client=client, # QdrantClient\\n    embedding=embeddings, # Embedding Model\\n    collection_name=COLLECTION_NAME # 연결할 Collection 지정.\\n)\\nids = vectorstore.add_documents(menu_documents)\\nprint(f\"저장된 문서 개수: {len(ids)}\")\\n##################################################\\n# Retriever 생성\\n##################################################\\nmenu_retriever = vectorstore.as_retriever(\\n    search_kwargs={\"k\": 3}  # 검색할 결과 개수\\n)\\n\\nfrom langchain_core.runnables import ConfigurableField\\nretriever = menu_retriever.configurable_fields(\\n    search_type=ConfigurableField(\\n        id=\"search_type\"\\n    ),\\n    search_kwargs=ConfigurableField(\\n        id=\"search_kwargs\"\\n    ),\\n)',\n",
       "  '# VectorDB 저장 및 VectorStore 생성\\nfrom langchain_qdrant import QdrantVectorStore\\nfrom langchain_openai import OpenAIEmbeddings\\nfrom qdrant_client import QdrantClient\\nfrom qdrant_client.http.models import Distance, VectorParams\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\nCOLLECTION_NAME = \"restaurant_menu\"\\nVECTOR_SIZE = 1536  # OpenAIEmbeddings의 벡터 크기\\n\\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\\n\\nclient = QdrantClient(host=\"localhost\", port=6333)\\nif client.collection_exists(COLLECTION_NAME):\\n    client.delete_collection(COLLECTION_NAME)\\n\\n# Collection 생성\\nclient.create_collection(\\n    collection_name=COLLECTION_NAME,\\n    # 벡터 저장소에 대한 설정. - vector_config는 default이므로 이름을 안줘도 됨(default 로 잡힘) 이름을 줄 거면 {\"이름\":VectorParams()} 설정\\n    vectors_config=VectorParams(\\n        size=VECTOR_SIZE, \\n        distance=Distance.COSINE\\n    )\\n)\\n\\nvectorstore = QdrantVectorStore(\\n    client=client, # QdrantClient\\n    embedding=embeddings, # Embedding Model\\n    collection_name=COLLECTION_NAME # 연결할 Collection 지정.\\n)\\nids = vectorstore.add_documents(menu_documents)\\nprint(f\"저장된 문서 개수: {len(ids)}\")\\n##################################################\\n# Retriever 생성\\n##################################################\\nmenu_retriever = vectorstore.as_retriever(\\n    search_kwargs={\"k\": 3}  # 검색할 결과 개수\\n)\\n\\nfrom langchain_core.runnables import ConfigurableField\\nretriever = menu_retriever.configurable_fields(\\n    search_type=ConfigurableField(\\n        id=\"search_type\"\\n    ),\\n    search_kwargs=ConfigurableField(\\n        id=\"search_kwargs\"\\n    ),\\n)',\n",
       "  '# Split - 메뉴별로 분리하기 위해 직접 처리\\nfrom langchain_core.documents import Document\\nimport re\\nfrom pprint import pprint\\n\\ndef create_documents(menu_all: str, file_name) -> list[Document]:\\n    \"\"\"메뉴별로 분리 한뒤 Document로 변환. 변환된 Document들을 리스트로 반환\\n    metadata: 메뉴이름, 주요 재료, 가격, source(파일이름)\\n    \"\"\"\\n    menu_list = menu_all.split(\"\\\\n\\\\n\")\\n    menu_documents = [] # 개별 메뉴로 Document를 생성. 그것들을 저장할 list를 만듬.\\n    for menu_item in menu_list:\\n\\n        # 메뉴 이름 추출\\n        menu_name_pattern = r\"(^\\\\d+.\\\\s)([가-힣a-zA-Z\\\\d ]+)\" \\n        # (^\\\\d+.\\\\s) : 숫자로 시작. 그다음 . 그러고 공백.\\n        # 숫자가 있어서 후방 검색이 안됨.\\n        menu_name_result = re.search(menu_name_pattern, menu_item)\\n        menu_name = menu_name_result.group(2).strip()  # 메뉴 이름 추출 # 1은 번호\\n\\n        # 주요재료 추출 - text로 indexing.\\n        menu_ingredient_pattern = r\"(?<=주요 재료: ).+\" # ?<= 검색할 때 쓰지만, 값은 주지마.\\n        ingredients = re.search(menu_ingredient_pattern, menu_item).group().strip()\\n\\n        # 가격추출\\n        price_pattern = r\"(?<=가격: )[\\\\d,]+(?=원)\"\\n        # 전방 후방탐색 동시에. 가격과 원을 검색할때 쓰지만, 값은 필요 없음.\\n        price_result = re.search(price_pattern, menu_item)\\n        price = int(price_result.group().replace(\",\", \"\")) # 숫자에서 쉼표 지워버림.\\n\\n\\n        # 메뉴 이름을 제외한 나머지는 메뉴 설명으로 간주\\n        menu_doc = Document(\\n            page_content=menu_item,     # 메뉴 설명을 page_content에 넣는다. metadata는 나중에 따로 따로 payload filtering 할 수있기 때문에 \\n            metadata={\\n                \"menu_name\": menu_name, # 메뉴 이름\\n                \"price\": price,         # 가격\\n                \"ingredients\": ingredients, # 재료 리스트\\n                \"source\": file_name     # 메뉴가 저장된 파일 이름\\n            }\\n        )\\n        menu_documents.append(menu_doc)\\n    return menu_documents\\n\\n\\nmenu_documents = create_documents(menu, menu_file_path)\\nprint(len(menu_documents))\\nmenu_documents[0]',\n",
       "  '# 문서 Load\\nimport os\\n# 메뉴읽어 오기\\nmenu_file_path = \"data/restaurant_menu.txt\"\\nwith open(menu_file_path, \"r\", encoding=\"utf-8\") as f:\\n    menu = f.read()',\n",
       "  '# Split - 메뉴별로 분리하기 위해 직접 처리\\nfrom langchain_core.documents import Document\\nimport re\\nfrom pprint import pprint\\n\\ndef create_documents(menu_all: str, file_name) -> list[Document]:\\n    \"\"\"메뉴별로 분리 한뒤 Document로 변환. 변환된 Document들을 리스트로 반환\\n    metadata: 메뉴이름, 주요 재료, 가격, source(파일이름)\\n    \"\"\"\\n    menu_list = menu_all.split(\"\\\\n\\\\n\")\\n    menu_documents = [] # 개별 메뉴로 Document를 생성. 그것들을 저장할 list를 만듬.\\n    for menu_item in menu_list:\\n\\n        # 메뉴 이름 추출\\n        menu_name_pattern = r\"(^\\\\d+.\\\\s)([가-힣a-zA-Z\\\\d ]+)\" \\n        # (^\\\\d+.\\\\s) : 숫자로 시작. 그다음 . 그러고 공백.\\n        # 숫자가 있어서 후방 검색이 안됨.\\n        menu_name_result = re.search(menu_name_pattern, menu_item)\\n        menu_name = menu_name_result.group(2).strip()  # 메뉴 이름 추출 # 1은 번호\\n\\n        # 주요재료 추출 - text로 indexing.\\n        menu_ingredient_pattern = r\"(?<=주요 재료: ).+\" # ?<= 검색할 때 쓰지만, 값은 주지마.\\n        ingredients = re.search(menu_ingredient_pattern, menu_item).group().strip()\\n\\n        # 가격추출\\n        price_pattern = r\"(?<=가격: )[\\\\d,]+(?=원)\"\\n        # 전방 후방탐색 동시에. 가격과 원을 검색할때 쓰지만, 값은 필요 없음.\\n        price_result = re.search(price_pattern, menu_item)\\n        price = int(price_result.group().replace(\",\", \"\")) # 숫자에서 쉼표 지워버림.\\n\\n\\n        # 메뉴 이름을 제외한 나머지는 메뉴 설명으로 간주\\n        menu_doc = Document(\\n            page_content=menu_item,     # 메뉴 설명을 page_content에 넣는다. metadata는 나중에 따로 따로 payload filtering 할 수있기 때문에 \\n            metadata={\\n                \"menu_name\": menu_name, # 메뉴 이름\\n                \"price\": price,         # 가격\\n                \"ingredients\": ingredients, # 재료 리스트\\n                \"source\": file_name     # 메뉴가 저장된 파일 이름\\n            }\\n        )\\n        menu_documents.append(menu_doc)\\n    return menu_documents\\n\\n\\nmenu_documents = create_documents(menu, menu_file_path)\\nprint(len(menu_documents))\\nmenu_documents[0]',\n",
       "  '# VectorDB 저장 및 VectorStore 생성\\nfrom langchain_qdrant import QdrantVectorStore\\nfrom langchain_openai import OpenAIEmbeddings\\nfrom qdrant_client import QdrantClient\\nfrom qdrant_client.http.models import Distance, VectorParams\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\nCOLLECTION_NAME = \"restaurant_menu\"\\nVECTOR_SIZE = 1536  # OpenAIEmbeddings의 벡터 크기\\n\\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\\n\\nclient = QdrantClient(host=\"localhost\", port=6333)\\nif client.collection_exists(COLLECTION_NAME):\\n    client.delete_collection(COLLECTION_NAME)\\n\\n# Collection 생성\\nclient.create_collection(\\n    collection_name=COLLECTION_NAME,\\n    # 벡터 저장소에 대한 설정. - vector_config는 default이므로 이름을 안줘도 됨(default 로 잡힘) 이름을 줄 거면 {\"이름\":VectorParams()} 설정\\n    vectors_config=VectorParams(\\n        size=VECTOR_SIZE, \\n        distance=Distance.COSINE\\n    )\\n)\\n\\nvectorstore = QdrantVectorStore(\\n    client=client, # QdrantClient\\n    embedding=embeddings, # Embedding Model\\n    collection_name=COLLECTION_NAME # 연결할 Collection 지정.\\n)\\nids = vectorstore.add_documents(menu_documents)\\nprint(f\"저장된 문서 개수: {len(ids)}\")\\n##################################################\\n# Retriever 생성\\n##################################################\\nmenu_retriever = vectorstore.as_retriever(\\n    search_kwargs={\"k\": 3}  # 검색할 결과 개수\\n)\\n\\nfrom langchain_core.runnables import ConfigurableField\\nretriever = menu_retriever.configurable_fields(\\n    search_type=ConfigurableField(\\n        id=\"search_type\"\\n    ),\\n    search_kwargs=ConfigurableField(\\n        id=\"search_kwargs\"\\n    ),\\n)',\n",
       "  'query=\"쇠고기를 재료로 하는 음식은 뭐가 있어?\"\\nresult = retriever.invoke(query)\\n\\nfor doc in result:\\n    print(doc.metadata)',\n",
       "  '# Retriever를 tool로 사용\\n# 쿼리를 입력 받아서 retriever로 검색해서 그 결과를 반환하는 tool을 직접 구현\\n@tool\\ndef search_menu(query:str) -> str:\\n    \"\"\"VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\\n    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\\n\\n    Args:\\n        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\\n    Return:\\n        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.\\n    \"\"\"\\n    result_list = []\\n    docs = retriever.invoke(query)\\n    for doc in docs:\\n        result_list.append({\"content\":doc.page_content, \\n                            \"title\":doc.metadata[\\'menu_name\\'],\\n                            \"url\":doc.metadata[\\'source\\']\\n                            })\\n    if result_list:\\n        result = {\"result\": result_list}\\n    else:\\n        result = {\"result\":\"검색된 메뉴가 없습니다.\"}\\n\\n    return json.dumps(result, ensure_ascii=False)',\n",
       "  'from langchain_core.tools import tool\\n# Retriever를 tool로 사용\\n# 쿼리를 입력 받아서 retriever로 검색해서 그 결과를 반환하는 tool을 직접 구현\\n@tool\\ndef search_menu(query:str) -> str:\\n    \"\"\"VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\\n    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\\n\\n    Args:\\n        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\\n    Return:\\n        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.\\n    \"\"\"\\n    result_list = []\\n    docs = retriever.invoke(query)\\n    for doc in docs:\\n        result_list.append({\"content\":doc.page_content, \\n                            \"title\":doc.metadata[\\'menu_name\\'],\\n                            \"url\":doc.metadata[\\'source\\']\\n                            })\\n    if result_list:\\n        result = {\"result\": result_list}\\n    else:\\n        result = {\"result\":\"검색된 메뉴가 없습니다.\"}\\n\\n    return json.dumps(result, ensure_ascii=False)',\n",
       "  'print(search_menu.name)\\nprint(search_menu.description)\\nprint(search_menu.schema',\n",
       "  'print(search_menu.name)\\nprint(search_menu.description)\\nprint(search_menu.schema)',\n",
       "  'tool_model = ChatOpenAI(\"gpt-5-mini\").bind_tools(tools=[search_menu])\\nres = tool_model.invoke(\"식당 메뉴 중\")',\n",
       "  'tool_model = ChatOpenAI(model=\"gpt-5-mini\").bind_tools(tools=[search_menu])\\nres = tool_model.invoke(\"식당 메뉴 중 면요리를 추천해줘.\")',\n",
       "  '############################\\n# Agent chain을 구성\\n############################\\nfrom langchain_openai import ChatOpenAI\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_core.runnables import chain\\nfrom langchain_tavily import TavilySearch\\nfrom dotenv import load_dotenv\\nfrom datetime import date\\n\\nload_dotenv()',\n",
       "  'tool_model = ChatOpenAI(model=\"gpt-5-mini\").bind_tools(tools=[search_menu])\\nres = tool_model.invoke(\"식당 메뉴 중 면요리를 추천해줘.\")',\n",
       "  'res.tool_calls',\n",
       "  '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()',\n",
       "  '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(\"gpt-5.2\").bind_tools(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       "  '# Runnable을 tool로 변환 -> as_tools\\n## args_schema 설정\\nclass WikiSearchParameterSchema(BaseModel):\\n    query: str = Field(..., description=\"Wikipedia 에서 검색할 keyword\")\\n    max_results: int = Field(description=\"검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.\")\\n\\nsearch_wiki = wikipedia_search.as_tool(\\n    args_schema=WikiSearchParameterSchema,\\n    name=\"search_wiki\",\\n    description=\"\"\"이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다. \\n\"\"\"\\n)',\n",
       "  '# Runnable을 tool로 변환 -> as_tools\\n## args_schema 설정\\nclass WikiSearchParameterSchema(BaseModel):\\n    query: str = Field(..., description=\"Wikipedia 에서 검색할 keyword\")\\n    max_results: int = Field(description=\"검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.\")\\n\\nsearch_wiki = wikipedia_search.as_tool(\\n    args_schema=WikiSearchParameterSchema,\\n    name=\"search_wiki\",\\n    description=\"\"\"이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다. \\n\"\"\"\\n)',\n",
       "  'from langchain_core.tools import tool\\n\\n@tool\\ndef plus(num1:int|float, num2:int|float) -> int|float:\\n    \"\"\"두개 수를 받아서 덧셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\\n    return num1 + num2\\n\\n@tool\\ndef minus(num1:int|float, num2:int|float) -> int|float:\\n    \"\"\"두개 수를 받아서 뺄셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\\n    return num1 - num2\\n\\n@tool\\ndef multiply(num1:int|float, num2:int|float) -> int|float:\\n    \"\"\"두개 수를 받아서 곱셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\\n    return num1 * num2\\n\\n# 파라미터에 대한 자세한 설명이 들어가야 하는 경우 -> Pydantic\\nfrom pydantic import BaseModel, Field\\nclass DivideParameterSchema(BaseModel):\\n    num1: int|float = Field(..., description=\"나눌떄 사용할 첫번째 값\")\\n    num2: int|float = Field(..., description=\"나눌때 사용할 두번째 값\")\\n\\n@tool(\"divide_tool\", args_schema=DivideParameterSchema)\\ndef divide(num1:int|float, num2:int|float) -> int|float:\\n    \"\"\"두개 수를 받아서 나눗셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\\n    return num1 / num2',\n",
       "  '# Runnable을 tool로 변환 -> as_tools\\n## args_schema 설정\\nclass WikiSearchParameterSchema(BaseModel):\\n    query: str = Field(..., description=\"Wikipedia 에서 검색할 keyword\")\\n    max_results: int = Field(description=\"검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.\")\\n\\nsearch_wiki = wikipedia_search.as_tool(\\n    args_schema=WikiSearchParameterSchema,\\n    name=\"search_wiki\",\\n    description=\"\"\"이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다. \\n\"\"\"\\n)',\n",
       "  'from langchain_community.document_loaders import WikipediaLoader # 위키백과 사전 내용을 크롤링해서 문서로 반환.\\nfrom pydantic import BaseModel, Field\\nfrom langchain_core.runnables import chain\\nimport json\\n\\n@chain\\ndef wikipedia_search(inputs:dict) -> str:\\n    \"\"\"사용자 query를 위키백과사전에서 검색하고 검색 결과 중 k개 문서를 반환한다.\\n    Args:\\n        inputs(dict): query-검색할 키워드, max_results(int): 반환할 검색 결과수 를 받는다.\\n    Returns:\\n        str - 검색 결과를 json 으로 반환.\\n              형식: {\"result\":[{검색문서1}, {검색문서2}, ...]}. 검색 문서(dict) - content, url, title로 구성\\n              검색결과가 없을 경우 : {\"result\": \"결과없음\"} 반환.\\n    \"\"\"\\n    query = inputs[\"query\"]\\n    max_results = inputs.get(\"max_results\", 5)\\n    loader = WikipediaLoader(query=query, load_max_docs=max_results, lang=\"ko\")\\n    docs = loader.load() #list[Document]\\n\\n    result_list = []\\n    for doc in docs:\\n        result_list.append({\"content\":doc.page_content, \\n                            \"title\":doc.metadata.get(\\'title\\'),\\n                            \"url\":doc.metadata.get(\"source\")\\n                            })\\n    if result_list:\\n        result = {\"result\": result_list}\\n    else:\\n        result = {\"result\": \"검색 결과가 없습니다.\"}\\n\\n    # JSON 문자열로 변환해서 반환. #json.load() : json문자열을 파이썬 자료구조(dict나 list)로 변환.\\n    return json.dumps(result, ensure_ascii=False) #json.dumps() : 파이썬 자료구조(dict나 list)->json문자열.\\n    # escape_ascii=False: 한글 문자가 나오도록 처리. True: 한글이 유니코드 escape 문자로 나옴(\\\\uxxxx)',\n",
       "  '# Runnable을 tool로 변환 -> as_tools\\n## args_schema 설정\\nclass WikiSearchParameterSchema(BaseModel):\\n    query: str = Field(..., description=\"Wikipedia 에서 검색할 keyword\")\\n    max_results: int = Field(description=\"검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.\")\\n\\nsearch_wiki = wikipedia_search.as_tool(\\n    args_schema=WikiSearchParameterSchema,\\n    name=\"search_wiki\",\\n    description=\"\"\"이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다. \\n\"\"\"\\n)',\n",
       "  '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(\"gpt-5.2\").bind_tools(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       "  '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(\"gpt-5.2\").bind_tools(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       "  '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(\"gpt-5.2\").bind_tool(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       "  '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(model=\"gpt-5.2\").bind_tools(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       "  'res = tool_model_chain.invoke({\"query\":\"파스타 메뉴를 추천해주고 파스타 유래나 역사를 알려줘.\"})',\n",
       "  'from langchain_core.tools import tool\\n# Retriever를 tool로 사용\\n# 쿼리를 입력 받아서 retriever로 검색해서 그 결과를 반환하는 tool을 직접 구현\\n@tool\\ndef search_menu(query:str) -> str:\\n    \"\"\"VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\\n    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\\n\\n    Args:\\n        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\\n    Return:\\n        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.\\n    \"\"\"\\n    result_list = []\\n    docs = retriever.invoke(query)\\n    for doc in docs:\\n        result_list.append({\"content\":doc.page_content, \\n                            \"title\":doc.metadata[\\'menu_name\\'],\\n                            \"url\":doc.metadata[\\'source\\']\\n                            })\\n    if result_list:\\n        result = {\"result\": result_list}\\n    else:\\n        result = {\"result\":\"검색된 메뉴가 없습니다.\"}\\n\\n    return json.dumps(result, ensure_ascii=False)',\n",
       "  'res = tool_model_chain.invoke({\"query\":\"파스타 메뉴를 추천해주고 파스타 유래나 역사를 알려줘.\"})',\n",
       "  'res = tool_model_chain.invoke({\"query\":\"파스타 메뉴를 추천해주고 파스타 유래나 역사를 알려줘.\"})',\n",
       "  'globals() # 전역변수로 등록된 모든 변수, 함수들을 dictionary 제공. key: \"이름\", value: 변수/함수/클래스'],\n",
       " 'Out': {2: Document(metadata={'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt'}, page_content='1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.'),\n",
       "  5: Document(metadata={'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt'}, page_content='1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.'),\n",
       "  7: Document(metadata={'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt'}, page_content='1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.'),\n",
       "  16: True,\n",
       "  18: [{'name': 'search_menu',\n",
       "    'args': {'query': '면요리'},\n",
       "    'id': 'call_3icxEAYHczcNopeViNioXr24',\n",
       "    'type': 'tool_call'}],\n",
       "  19: True},\n",
       " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x000002A2E7CFA8A0>>,\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x2a2e7d5a510>,\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x2a2e7d5a510>,\n",
       " 'open': <function _io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
       " '_': True,\n",
       " '__': [{'name': 'search_menu',\n",
       "   'args': {'query': '면요리'},\n",
       "   'id': 'call_3icxEAYHczcNopeViNioXr24',\n",
       "   'type': 'tool_call'}],\n",
       " '___': True,\n",
       " '__vsc_ipynb_file__': 'c:\\\\Users\\\\Playdata\\\\Documents\\\\SKN21_2\\\\SKN21\\\\10_langchain\\\\12_Agent_ToolCalling.ipynb',\n",
       " '_i': 'res = tool_model_chain.invoke({\"query\":\"파스타 메뉴를 추천해주고 파스타 유래나 역사를 알려줘.\"})',\n",
       " '_ii': 'res = tool_model_chain.invoke({\"query\":\"파스타 메뉴를 추천해주고 파스타 유래나 역사를 알려줘.\"})',\n",
       " '_iii': 'from langchain_core.tools import tool\\n# Retriever를 tool로 사용\\n# 쿼리를 입력 받아서 retriever로 검색해서 그 결과를 반환하는 tool을 직접 구현\\n@tool\\ndef search_menu(query:str) -> str:\\n    \"\"\"VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\\n    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\\n    \\n    Args:\\n        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\\n    Return:\\n        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.\\n    \"\"\"\\n    result_list = []\\n    docs = retriever.invoke(query)\\n    for doc in docs:\\n        result_list.append({\"content\":doc.page_content, \\n                            \"title\":doc.metadata[\\'menu_name\\'],\\n                            \"url\":doc.metadata[\\'source\\']\\n                            })\\n    if result_list:\\n        result = {\"result\": result_list}\\n    else:\\n        result = {\"result\":\"검색된 메뉴가 없습니다.\"}\\n    \\n    return json.dumps(result, ensure_ascii=False)',\n",
       " '_i1': '# 문서 Load\\nimport os\\n# 메뉴읽어 오기\\nmenu_file_path = \"data/restaurant_menu.txt\"\\nwith open(menu_file_path, \"r\", encoding=\"utf-8\") as f:\\n    menu = f.read()',\n",
       " 'os': <module 'os' (frozen)>,\n",
       " 'menu_file_path': 'data/restaurant_menu.txt',\n",
       " 'f': <_io.TextIOWrapper name='data/restaurant_menu.txt' mode='r' encoding='utf-8'>,\n",
       " 'menu': '1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.\\n\\n2. 카르보나라\\n   - 가격: 20,000원\\n   - 주요 재료: 스파게티 면, 판체타, 달걀 노른자, 파르미지아노 치즈\\n   - 메뉴 설명: 이탈리아 전통 방식으로 만든 크리미한 파스타입니다. 판체타의 풍미와 달걀 노른자가 어우러져 고소하고 깊은 맛을 자랑합니다. 신선한 파르미지아노 치즈가 풍미를 더하며, 후추를 뿌려 맛을 완성합니다.\\n\\n3. 부르기뇽 스튜\\n   - 가격: 28,000원\\n   - 주요 재료: 쇠고기, 적포도주, 양파, 당근, 베이컨\\n   - 메뉴 설명: 프랑스 부르고뉴 지방에서 유래된 스튜 요리로, 고기를 적포도주와 함께 오랜 시간 푹 끓여 부드럽고 진한 풍미를 자랑합니다. 신선한 허브와 채소가 맛을 풍부하게 하고, 바게트와 함께 제공됩니다.\\n\\n4. 니스 샐러드\\n   - 가격: 18,000원\\n   - 주요 재료: 참치, 방울토마토, 올리브, 삶은 달걀, 그린빈\\n   - 메뉴 설명: 프랑스 니스 지방의 상큼한 샐러드로, 다양한 채소와 참치를 사용해 풍성한 맛과 식감을 제공합니다. 발사믹 비네거 드레싱이 가미되어 가볍게 즐기기 좋은 요리입니다. 신선함과 영양을 동시에 잡은 메뉴입니다.\\n\\n5. 프렌치 어니언 수프\\n   - 가격: 12,000원\\n   - 주요 재료: 양파, 비프 스톡, 화이트 와인, 그뤼에르 치즈\\n   - 메뉴 설명: 달콤하게 캐러멜라이즈된 양파와 진한 비프 스톡으로 만든 프랑스 전통 수프입니다. 바삭한 바게트 위에 그뤼에르 치즈를 녹여 깊은 풍미를 더했습니다. 추운 날씨에 특히 잘 어울리는 따뜻한 메뉴입니다.\\n\\n6. 트러플 피자\\n   - 가격: 26,000원\\n   - 주요 재료: 트러플 오일, 모짜렐라 치즈, 얇은 피자 도우, 루꼴라\\n   - 메뉴 설명: 얇고 바삭한 도우 위에 고급 트러플 오일과 모짜렐라 치즈를 얹어 구워낸 피자입니다. 루꼴라를 더해 신선하고 고소한 맛이 특징입니다. 고급스러운 한 끼를 즐기기에 완벽한 선택입니다.\\n\\n7. 밀라노풍 송아지 커틀렛\\n   - 가격: 30,000원\\n   - 주요 재료: 송아지 고기, 빵가루, 파르미지아노 치즈, 루꼴라 샐러드\\n   - 메뉴 설명: 얇게 저민 송아지 고기를 바삭하게 튀겨 낸 이탈리아 전통 요리입니다. 레몬을 곁들여 고기의 풍미를 돋우며, 상큼한 루꼴라 샐러드가 함께 제공됩니다. 바삭한 식감과 부드러운 고기의 조화가 일품입니다.\\n\\n8. 프로방스 치킨\\n   - 가격: 22,000원\\n   - 주요 재료: 닭고기, 타임, 로즈마리, 올리브, 토마토\\n   - 메뉴 설명: 프랑스 프로방스 지방의 허브와 토마토 소스로 조리한 닭고기 요리입니다. 부드럽고 촉촉한 닭고기와 향긋한 허브가 입맛을 돋웁니다. 라이스나 바게트와 함께 즐기기 좋습니다.\\n\\n9. 해산물 링귀니\\n   - 가격: 24,000원\\n   - 주요 재료: 링귀니 면, 홍합, 새우, 오징어, 화이트 와인\\n   - 메뉴 설명: 신선한 해산물과 화이트 와인을 곁들여 만든 이탈리아 대표 파스타입니다. 면과 해산물이 풍부하게 어우러져 깊고 풍성한 맛을 자랑합니다. 바다의 풍미를 그대로 담은 특별한 메뉴입니다.\\n\\n10. 토마토 브루스케타\\n    - 가격: 12,000원\\n    - 주요 재료: 토마토, 바질, 올리브 오일, 바게트\\n    - 메뉴 설명: 바삭하게 구운 바게트 위에 신선한 토마토와 바질을 얹고 올리브 오일로 마무리한 간단한 요리입니다. 입맛을 돋우는 상큼한 맛이 특징입니다. 가벼운 전채로 적합합니다.\\n\\n11. 크림 스피나치 라자냐\\n    - 가격: 23,000원\\n    - 주요 재료: 라자냐 면, 크림 소스, 시금치, 리코타 치즈\\n    - 메뉴 설명: 부드럽고 크리미한 소스와 신선한 시금치가 조화를 이루는 라자냐입니다. 리코타 치즈를 풍부하게 사용해 깊은 맛을 더했습니다. 따뜻하고 풍성한 한 끼로 제격입니다.\\n\\n12. 바질 페스토 뇨끼\\n    - 가격: 19,000원\\n    - 주요 재료: 감자 뇨끼, 바질 페스토, 파르미지아노 치즈\\n    - 메뉴 설명: 부드럽고 쫀득한 감자 뇨끼에 향긋한 바질 페스토를 곁들인 이탈리아 대표 요리입니다. 신선한 치즈와 허브가 요리의 맛을 풍부하게 만듭니다. 가벼운 식사로 적합합니다.\\n\\n13. 티라미수\\n    - 가격: 10,000원\\n    - 주요 재료: 마스카르포네 치즈, 에스프레소, 코코아 파우더, 사보이아르디\\n    - 메뉴 설명: 이탈리아를 대표하는 디저트로, 부드러운 마스카르포네 치즈 크림과 촉촉한 에스프레소 시트가 어우러집니다. 코코아 파우더가 위에 뿌려져 달콤쌉쌀한 맛이 특징입니다. 커피와 함께 즐기기에 완벽한 디저트입니다.\\n\\n14. 크렘 브륄레\\n    - 가격: 11,000원\\n    - 주요 재료: 크림, 설탕, 바닐라 빈, 달걀 노른자\\n    - 메뉴 설명: 부드러운 크림 베이스 위에 바삭한 캐러멜 층이 올라간 프랑스 디저트입니다. 숟가락으로 캐러멜을 부수며 즐기는 식감이 매력적입니다. 부드럽고 달콤한 맛이 입안을 가득 채웁니다.\\n\\n15. 레몬 타르트\\n    - 가격: 9,000원\\n    - 주요 재료: 레몬 커드, 타르트 크러스트, 슈거 파우더\\n    - 메뉴 설명: 상큼한 레몬 커드와 바삭한 타르트 크러스트가 완벽한 조화를 이루는 디저트입니다. 달콤한 맛과 상큼한 맛이 균형을 이루며, 가볍게 즐기기 좋은 메뉴입니다. 애프터눈 티와 잘 어울립니다.',\n",
       " '_i2': '# Split - 메뉴별로 분리하기 위해 직접 처리\\nfrom langchain_core.documents import Document\\nimport re\\nfrom pprint import pprint\\n\\ndef create_documents(menu_all: str, file_name) -> list[Document]:\\n    \"\"\"메뉴별로 분리 한뒤 Document로 변환. 변환된 Document들을 리스트로 반환\\n    metadata: 메뉴이름, 주요 재료, 가격, source(파일이름)\\n    \"\"\"\\n    menu_list = menu_all.split(\"\\\\n\\\\n\")\\n    menu_documents = [] # 개별 메뉴로 Document를 생성. 그것들을 저장할 list를 만듬.\\n    for menu_item in menu_list:\\n\\n        # 메뉴 이름 추출\\n        menu_name_pattern = r\"(^\\\\d+.\\\\s)([가-힣a-zA-Z\\\\d ]+)\" \\n        # (^\\\\d+.\\\\s) : 숫자로 시작. 그다음 . 그러고 공백.\\n        # 숫자가 있어서 후방 검색이 안됨.\\n        menu_name_result = re.search(menu_name_pattern, menu_item)\\n        menu_name = menu_name_result.group(2).strip()  # 메뉴 이름 추출 # 1은 번호\\n\\n        # 주요재료 추출 - text로 indexing.\\n        menu_ingredient_pattern = r\"(?<=주요 재료: ).+\" # ?<= 검색할 때 쓰지만, 값은 주지마.\\n        ingredients = re.search(menu_ingredient_pattern, menu_item).group().strip()\\n    \\n        # 가격추출\\n        price_pattern = r\"(?<=가격: )[\\\\d,]+(?=원)\"\\n        # 전방 후방탐색 동시에. 가격과 원을 검색할때 쓰지만, 값은 필요 없음.\\n        price_result = re.search(price_pattern, menu_item)\\n        price = int(price_result.group().replace(\",\", \"\")) # 숫자에서 쉼표 지워버림.\\n\\n        \\n        # 메뉴 이름을 제외한 나머지는 메뉴 설명으로 간주\\n        menu_doc = Document(\\n            page_content=menu_item,     # 메뉴 설명을 page_content에 넣는다. metadata는 나중에 따로 따로 payload filtering 할 수있기 때문에 \\n            metadata={\\n                \"menu_name\": menu_name, # 메뉴 이름\\n                \"price\": price,         # 가격\\n                \"ingredients\": ingredients, # 재료 리스트\\n                \"source\": file_name     # 메뉴가 저장된 파일 이름\\n            }\\n        )\\n        menu_documents.append(menu_doc)\\n    return menu_documents\\n\\n\\nmenu_documents = create_documents(menu, menu_file_path)\\nprint(len(menu_documents))\\nmenu_documents[0]',\n",
       " 'Document': langchain_core.documents.base.Document,\n",
       " 're': <module 're' from 'C:\\\\Users\\\\Playdata\\\\AppData\\\\Roaming\\\\uv\\\\python\\\\cpython-3.12.12-windows-x86_64-none\\\\Lib\\\\re\\\\__init__.py'>,\n",
       " 'pprint': <function pprint.pprint(object, stream=None, indent=1, width=80, depth=None, *, compact=False, sort_dicts=True, underscore_numbers=False)>,\n",
       " 'create_documents': <function __main__.create_documents(menu_all: str, file_name) -> list[langchain_core.documents.base.Document]>,\n",
       " 'menu_documents': [Document(metadata={'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt'}, page_content='1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.'),\n",
       "  Document(metadata={'menu_name': '카르보나라', 'price': 20000, 'ingredients': '스파게티 면, 판체타, 달걀 노른자, 파르미지아노 치즈', 'source': 'data/restaurant_menu.txt'}, page_content='2. 카르보나라\\n   - 가격: 20,000원\\n   - 주요 재료: 스파게티 면, 판체타, 달걀 노른자, 파르미지아노 치즈\\n   - 메뉴 설명: 이탈리아 전통 방식으로 만든 크리미한 파스타입니다. 판체타의 풍미와 달걀 노른자가 어우러져 고소하고 깊은 맛을 자랑합니다. 신선한 파르미지아노 치즈가 풍미를 더하며, 후추를 뿌려 맛을 완성합니다.'),\n",
       "  Document(metadata={'menu_name': '부르기뇽 스튜', 'price': 28000, 'ingredients': '쇠고기, 적포도주, 양파, 당근, 베이컨', 'source': 'data/restaurant_menu.txt'}, page_content='3. 부르기뇽 스튜\\n   - 가격: 28,000원\\n   - 주요 재료: 쇠고기, 적포도주, 양파, 당근, 베이컨\\n   - 메뉴 설명: 프랑스 부르고뉴 지방에서 유래된 스튜 요리로, 고기를 적포도주와 함께 오랜 시간 푹 끓여 부드럽고 진한 풍미를 자랑합니다. 신선한 허브와 채소가 맛을 풍부하게 하고, 바게트와 함께 제공됩니다.'),\n",
       "  Document(metadata={'menu_name': '니스 샐러드', 'price': 18000, 'ingredients': '참치, 방울토마토, 올리브, 삶은 달걀, 그린빈', 'source': 'data/restaurant_menu.txt'}, page_content='4. 니스 샐러드\\n   - 가격: 18,000원\\n   - 주요 재료: 참치, 방울토마토, 올리브, 삶은 달걀, 그린빈\\n   - 메뉴 설명: 프랑스 니스 지방의 상큼한 샐러드로, 다양한 채소와 참치를 사용해 풍성한 맛과 식감을 제공합니다. 발사믹 비네거 드레싱이 가미되어 가볍게 즐기기 좋은 요리입니다. 신선함과 영양을 동시에 잡은 메뉴입니다.'),\n",
       "  Document(metadata={'menu_name': '프렌치 어니언 수프', 'price': 12000, 'ingredients': '양파, 비프 스톡, 화이트 와인, 그뤼에르 치즈', 'source': 'data/restaurant_menu.txt'}, page_content='5. 프렌치 어니언 수프\\n   - 가격: 12,000원\\n   - 주요 재료: 양파, 비프 스톡, 화이트 와인, 그뤼에르 치즈\\n   - 메뉴 설명: 달콤하게 캐러멜라이즈된 양파와 진한 비프 스톡으로 만든 프랑스 전통 수프입니다. 바삭한 바게트 위에 그뤼에르 치즈를 녹여 깊은 풍미를 더했습니다. 추운 날씨에 특히 잘 어울리는 따뜻한 메뉴입니다.'),\n",
       "  Document(metadata={'menu_name': '트러플 피자', 'price': 26000, 'ingredients': '트러플 오일, 모짜렐라 치즈, 얇은 피자 도우, 루꼴라', 'source': 'data/restaurant_menu.txt'}, page_content='6. 트러플 피자\\n   - 가격: 26,000원\\n   - 주요 재료: 트러플 오일, 모짜렐라 치즈, 얇은 피자 도우, 루꼴라\\n   - 메뉴 설명: 얇고 바삭한 도우 위에 고급 트러플 오일과 모짜렐라 치즈를 얹어 구워낸 피자입니다. 루꼴라를 더해 신선하고 고소한 맛이 특징입니다. 고급스러운 한 끼를 즐기기에 완벽한 선택입니다.'),\n",
       "  Document(metadata={'menu_name': '밀라노풍 송아지 커틀렛', 'price': 30000, 'ingredients': '송아지 고기, 빵가루, 파르미지아노 치즈, 루꼴라 샐러드', 'source': 'data/restaurant_menu.txt'}, page_content='7. 밀라노풍 송아지 커틀렛\\n   - 가격: 30,000원\\n   - 주요 재료: 송아지 고기, 빵가루, 파르미지아노 치즈, 루꼴라 샐러드\\n   - 메뉴 설명: 얇게 저민 송아지 고기를 바삭하게 튀겨 낸 이탈리아 전통 요리입니다. 레몬을 곁들여 고기의 풍미를 돋우며, 상큼한 루꼴라 샐러드가 함께 제공됩니다. 바삭한 식감과 부드러운 고기의 조화가 일품입니다.'),\n",
       "  Document(metadata={'menu_name': '프로방스 치킨', 'price': 22000, 'ingredients': '닭고기, 타임, 로즈마리, 올리브, 토마토', 'source': 'data/restaurant_menu.txt'}, page_content='8. 프로방스 치킨\\n   - 가격: 22,000원\\n   - 주요 재료: 닭고기, 타임, 로즈마리, 올리브, 토마토\\n   - 메뉴 설명: 프랑스 프로방스 지방의 허브와 토마토 소스로 조리한 닭고기 요리입니다. 부드럽고 촉촉한 닭고기와 향긋한 허브가 입맛을 돋웁니다. 라이스나 바게트와 함께 즐기기 좋습니다.'),\n",
       "  Document(metadata={'menu_name': '해산물 링귀니', 'price': 24000, 'ingredients': '링귀니 면, 홍합, 새우, 오징어, 화이트 와인', 'source': 'data/restaurant_menu.txt'}, page_content='9. 해산물 링귀니\\n   - 가격: 24,000원\\n   - 주요 재료: 링귀니 면, 홍합, 새우, 오징어, 화이트 와인\\n   - 메뉴 설명: 신선한 해산물과 화이트 와인을 곁들여 만든 이탈리아 대표 파스타입니다. 면과 해산물이 풍부하게 어우러져 깊고 풍성한 맛을 자랑합니다. 바다의 풍미를 그대로 담은 특별한 메뉴입니다.'),\n",
       "  Document(metadata={'menu_name': '토마토 브루스케타', 'price': 12000, 'ingredients': '토마토, 바질, 올리브 오일, 바게트', 'source': 'data/restaurant_menu.txt'}, page_content='10. 토마토 브루스케타\\n    - 가격: 12,000원\\n    - 주요 재료: 토마토, 바질, 올리브 오일, 바게트\\n    - 메뉴 설명: 바삭하게 구운 바게트 위에 신선한 토마토와 바질을 얹고 올리브 오일로 마무리한 간단한 요리입니다. 입맛을 돋우는 상큼한 맛이 특징입니다. 가벼운 전채로 적합합니다.'),\n",
       "  Document(metadata={'menu_name': '크림 스피나치 라자냐', 'price': 23000, 'ingredients': '라자냐 면, 크림 소스, 시금치, 리코타 치즈', 'source': 'data/restaurant_menu.txt'}, page_content='11. 크림 스피나치 라자냐\\n    - 가격: 23,000원\\n    - 주요 재료: 라자냐 면, 크림 소스, 시금치, 리코타 치즈\\n    - 메뉴 설명: 부드럽고 크리미한 소스와 신선한 시금치가 조화를 이루는 라자냐입니다. 리코타 치즈를 풍부하게 사용해 깊은 맛을 더했습니다. 따뜻하고 풍성한 한 끼로 제격입니다.'),\n",
       "  Document(metadata={'menu_name': '바질 페스토 뇨끼', 'price': 19000, 'ingredients': '감자 뇨끼, 바질 페스토, 파르미지아노 치즈', 'source': 'data/restaurant_menu.txt'}, page_content='12. 바질 페스토 뇨끼\\n    - 가격: 19,000원\\n    - 주요 재료: 감자 뇨끼, 바질 페스토, 파르미지아노 치즈\\n    - 메뉴 설명: 부드럽고 쫀득한 감자 뇨끼에 향긋한 바질 페스토를 곁들인 이탈리아 대표 요리입니다. 신선한 치즈와 허브가 요리의 맛을 풍부하게 만듭니다. 가벼운 식사로 적합합니다.'),\n",
       "  Document(metadata={'menu_name': '티라미수', 'price': 10000, 'ingredients': '마스카르포네 치즈, 에스프레소, 코코아 파우더, 사보이아르디', 'source': 'data/restaurant_menu.txt'}, page_content='13. 티라미수\\n    - 가격: 10,000원\\n    - 주요 재료: 마스카르포네 치즈, 에스프레소, 코코아 파우더, 사보이아르디\\n    - 메뉴 설명: 이탈리아를 대표하는 디저트로, 부드러운 마스카르포네 치즈 크림과 촉촉한 에스프레소 시트가 어우러집니다. 코코아 파우더가 위에 뿌려져 달콤쌉쌀한 맛이 특징입니다. 커피와 함께 즐기기에 완벽한 디저트입니다.'),\n",
       "  Document(metadata={'menu_name': '크렘 브륄레', 'price': 11000, 'ingredients': '크림, 설탕, 바닐라 빈, 달걀 노른자', 'source': 'data/restaurant_menu.txt'}, page_content='14. 크렘 브륄레\\n    - 가격: 11,000원\\n    - 주요 재료: 크림, 설탕, 바닐라 빈, 달걀 노른자\\n    - 메뉴 설명: 부드러운 크림 베이스 위에 바삭한 캐러멜 층이 올라간 프랑스 디저트입니다. 숟가락으로 캐러멜을 부수며 즐기는 식감이 매력적입니다. 부드럽고 달콤한 맛이 입안을 가득 채웁니다.'),\n",
       "  Document(metadata={'menu_name': '레몬 타르트', 'price': 9000, 'ingredients': '레몬 커드, 타르트 크러스트, 슈거 파우더', 'source': 'data/restaurant_menu.txt'}, page_content='15. 레몬 타르트\\n    - 가격: 9,000원\\n    - 주요 재료: 레몬 커드, 타르트 크러스트, 슈거 파우더\\n    - 메뉴 설명: 상큼한 레몬 커드와 바삭한 타르트 크러스트가 완벽한 조화를 이루는 디저트입니다. 달콤한 맛과 상큼한 맛이 균형을 이루며, 가볍게 즐기기 좋은 메뉴입니다. 애프터눈 티와 잘 어울립니다.')],\n",
       " '_2': Document(metadata={'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt'}, page_content='1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.'),\n",
       " '_i3': '# VectorDB 저장 및 VectorStore 생성\\nfrom langchain_qdrant import QdrantVectorStore\\nfrom langchain_openai import OpenAIEmbeddings\\nfrom qdrant_client import QdrantClient\\nfrom qdrant_client.http.models import Distance, VectorParams\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\nCOLLECTION_NAME = \"restaurant_menu\"\\nVECTOR_SIZE = 1536  # OpenAIEmbeddings의 벡터 크기\\n\\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\\n\\nclient = QdrantClient(host=\"localhost\", port=6333)\\nif client.collection_exists(COLLECTION_NAME):\\n    client.delete_collection(COLLECTION_NAME)\\n\\n# Collection 생성\\nclient.create_collection(\\n    collection_name=COLLECTION_NAME,\\n    # 벡터 저장소에 대한 설정. - vector_config는 default이므로 이름을 안줘도 됨(default 로 잡힘) 이름을 줄 거면 {\"이름\":VectorParams()} 설정\\n    vectors_config=VectorParams(\\n        size=VECTOR_SIZE, \\n        distance=Distance.COSINE\\n    )\\n)\\n\\nvectorstore = QdrantVectorStore(\\n    client=client, # QdrantClient\\n    embedding=embeddings, # Embedding Model\\n    collection_name=COLLECTION_NAME # 연결할 Collection 지정.\\n)\\nids = vectorstore.add_documents(menu_documents)\\nprint(f\"저장된 문서 개수: {len(ids)}\")\\n##################################################\\n# Retriever 생성\\n##################################################\\nmenu_retriever = vectorstore.as_retriever(\\n    search_kwargs={\"k\": 3}  # 검색할 결과 개수\\n)\\n\\nfrom langchain_core.runnables import ConfigurableField\\nretriever = menu_retriever.configurable_fields(\\n    search_type=ConfigurableField(\\n        id=\"search_type\"\\n    ),\\n    search_kwargs=ConfigurableField(\\n        id=\"search_kwargs\"\\n    ),\\n)',\n",
       " 'QdrantVectorStore': langchain_qdrant.qdrant.QdrantVectorStore,\n",
       " 'OpenAIEmbeddings': langchain_openai.embeddings.base.OpenAIEmbeddings,\n",
       " 'QdrantClient': qdrant_client.qdrant_client.QdrantClient,\n",
       " 'Distance': <enum 'Distance'>,\n",
       " 'VectorParams': qdrant_client.http.models.models.VectorParams,\n",
       " 'load_dotenv': <function dotenv.main.load_dotenv(dotenv_path: Union[str, ForwardRef('os.PathLike[str]'), NoneType] = None, stream: Optional[IO[str]] = None, verbose: bool = False, override: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> bool>,\n",
       " 'COLLECTION_NAME': 'restaurant_menu',\n",
       " 'VECTOR_SIZE': 1536,\n",
       " 'embeddings': OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x000002A297A784A0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x000002A298F78A40>, model='text-embedding-3-small', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True),\n",
       " 'client': <qdrant_client.qdrant_client.QdrantClient at 0x2a297a6a150>,\n",
       " '_i4': '# VectorDB 저장 및 VectorStore 생성\\nfrom langchain_qdrant import QdrantVectorStore\\nfrom langchain_openai import OpenAIEmbeddings\\nfrom qdrant_client import QdrantClient\\nfrom qdrant_client.http.models import Distance, VectorParams\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\nCOLLECTION_NAME = \"restaurant_menu\"\\nVECTOR_SIZE = 1536  # OpenAIEmbeddings의 벡터 크기\\n\\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\\n\\nclient = QdrantClient(host=\"localhost\", port=6333)\\nif client.collection_exists(COLLECTION_NAME):\\n    client.delete_collection(COLLECTION_NAME)\\n\\n# Collection 생성\\nclient.create_collection(\\n    collection_name=COLLECTION_NAME,\\n    # 벡터 저장소에 대한 설정. - vector_config는 default이므로 이름을 안줘도 됨(default 로 잡힘) 이름을 줄 거면 {\"이름\":VectorParams()} 설정\\n    vectors_config=VectorParams(\\n        size=VECTOR_SIZE, \\n        distance=Distance.COSINE\\n    )\\n)\\n\\nvectorstore = QdrantVectorStore(\\n    client=client, # QdrantClient\\n    embedding=embeddings, # Embedding Model\\n    collection_name=COLLECTION_NAME # 연결할 Collection 지정.\\n)\\nids = vectorstore.add_documents(menu_documents)\\nprint(f\"저장된 문서 개수: {len(ids)}\")\\n##################################################\\n# Retriever 생성\\n##################################################\\nmenu_retriever = vectorstore.as_retriever(\\n    search_kwargs={\"k\": 3}  # 검색할 결과 개수\\n)\\n\\nfrom langchain_core.runnables import ConfigurableField\\nretriever = menu_retriever.configurable_fields(\\n    search_type=ConfigurableField(\\n        id=\"search_type\"\\n    ),\\n    search_kwargs=ConfigurableField(\\n        id=\"search_kwargs\"\\n    ),\\n)',\n",
       " '_i5': '# Split - 메뉴별로 분리하기 위해 직접 처리\\nfrom langchain_core.documents import Document\\nimport re\\nfrom pprint import pprint\\n\\ndef create_documents(menu_all: str, file_name) -> list[Document]:\\n    \"\"\"메뉴별로 분리 한뒤 Document로 변환. 변환된 Document들을 리스트로 반환\\n    metadata: 메뉴이름, 주요 재료, 가격, source(파일이름)\\n    \"\"\"\\n    menu_list = menu_all.split(\"\\\\n\\\\n\")\\n    menu_documents = [] # 개별 메뉴로 Document를 생성. 그것들을 저장할 list를 만듬.\\n    for menu_item in menu_list:\\n\\n        # 메뉴 이름 추출\\n        menu_name_pattern = r\"(^\\\\d+.\\\\s)([가-힣a-zA-Z\\\\d ]+)\" \\n        # (^\\\\d+.\\\\s) : 숫자로 시작. 그다음 . 그러고 공백.\\n        # 숫자가 있어서 후방 검색이 안됨.\\n        menu_name_result = re.search(menu_name_pattern, menu_item)\\n        menu_name = menu_name_result.group(2).strip()  # 메뉴 이름 추출 # 1은 번호\\n\\n        # 주요재료 추출 - text로 indexing.\\n        menu_ingredient_pattern = r\"(?<=주요 재료: ).+\" # ?<= 검색할 때 쓰지만, 값은 주지마.\\n        ingredients = re.search(menu_ingredient_pattern, menu_item).group().strip()\\n    \\n        # 가격추출\\n        price_pattern = r\"(?<=가격: )[\\\\d,]+(?=원)\"\\n        # 전방 후방탐색 동시에. 가격과 원을 검색할때 쓰지만, 값은 필요 없음.\\n        price_result = re.search(price_pattern, menu_item)\\n        price = int(price_result.group().replace(\",\", \"\")) # 숫자에서 쉼표 지워버림.\\n\\n        \\n        # 메뉴 이름을 제외한 나머지는 메뉴 설명으로 간주\\n        menu_doc = Document(\\n            page_content=menu_item,     # 메뉴 설명을 page_content에 넣는다. metadata는 나중에 따로 따로 payload filtering 할 수있기 때문에 \\n            metadata={\\n                \"menu_name\": menu_name, # 메뉴 이름\\n                \"price\": price,         # 가격\\n                \"ingredients\": ingredients, # 재료 리스트\\n                \"source\": file_name     # 메뉴가 저장된 파일 이름\\n            }\\n        )\\n        menu_documents.append(menu_doc)\\n    return menu_documents\\n\\n\\nmenu_documents = create_documents(menu, menu_file_path)\\nprint(len(menu_documents))\\nmenu_documents[0]',\n",
       " '_5': Document(metadata={'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt'}, page_content='1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.'),\n",
       " '_i6': '# 문서 Load\\nimport os\\n# 메뉴읽어 오기\\nmenu_file_path = \"data/restaurant_menu.txt\"\\nwith open(menu_file_path, \"r\", encoding=\"utf-8\") as f:\\n    menu = f.read()',\n",
       " '_i7': '# Split - 메뉴별로 분리하기 위해 직접 처리\\nfrom langchain_core.documents import Document\\nimport re\\nfrom pprint import pprint\\n\\ndef create_documents(menu_all: str, file_name) -> list[Document]:\\n    \"\"\"메뉴별로 분리 한뒤 Document로 변환. 변환된 Document들을 리스트로 반환\\n    metadata: 메뉴이름, 주요 재료, 가격, source(파일이름)\\n    \"\"\"\\n    menu_list = menu_all.split(\"\\\\n\\\\n\")\\n    menu_documents = [] # 개별 메뉴로 Document를 생성. 그것들을 저장할 list를 만듬.\\n    for menu_item in menu_list:\\n\\n        # 메뉴 이름 추출\\n        menu_name_pattern = r\"(^\\\\d+.\\\\s)([가-힣a-zA-Z\\\\d ]+)\" \\n        # (^\\\\d+.\\\\s) : 숫자로 시작. 그다음 . 그러고 공백.\\n        # 숫자가 있어서 후방 검색이 안됨.\\n        menu_name_result = re.search(menu_name_pattern, menu_item)\\n        menu_name = menu_name_result.group(2).strip()  # 메뉴 이름 추출 # 1은 번호\\n\\n        # 주요재료 추출 - text로 indexing.\\n        menu_ingredient_pattern = r\"(?<=주요 재료: ).+\" # ?<= 검색할 때 쓰지만, 값은 주지마.\\n        ingredients = re.search(menu_ingredient_pattern, menu_item).group().strip()\\n    \\n        # 가격추출\\n        price_pattern = r\"(?<=가격: )[\\\\d,]+(?=원)\"\\n        # 전방 후방탐색 동시에. 가격과 원을 검색할때 쓰지만, 값은 필요 없음.\\n        price_result = re.search(price_pattern, menu_item)\\n        price = int(price_result.group().replace(\",\", \"\")) # 숫자에서 쉼표 지워버림.\\n\\n        \\n        # 메뉴 이름을 제외한 나머지는 메뉴 설명으로 간주\\n        menu_doc = Document(\\n            page_content=menu_item,     # 메뉴 설명을 page_content에 넣는다. metadata는 나중에 따로 따로 payload filtering 할 수있기 때문에 \\n            metadata={\\n                \"menu_name\": menu_name, # 메뉴 이름\\n                \"price\": price,         # 가격\\n                \"ingredients\": ingredients, # 재료 리스트\\n                \"source\": file_name     # 메뉴가 저장된 파일 이름\\n            }\\n        )\\n        menu_documents.append(menu_doc)\\n    return menu_documents\\n\\n\\nmenu_documents = create_documents(menu, menu_file_path)\\nprint(len(menu_documents))\\nmenu_documents[0]',\n",
       " '_7': Document(metadata={'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt'}, page_content='1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.'),\n",
       " '_i8': '# VectorDB 저장 및 VectorStore 생성\\nfrom langchain_qdrant import QdrantVectorStore\\nfrom langchain_openai import OpenAIEmbeddings\\nfrom qdrant_client import QdrantClient\\nfrom qdrant_client.http.models import Distance, VectorParams\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\nCOLLECTION_NAME = \"restaurant_menu\"\\nVECTOR_SIZE = 1536  # OpenAIEmbeddings의 벡터 크기\\n\\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\\n\\nclient = QdrantClient(host=\"localhost\", port=6333)\\nif client.collection_exists(COLLECTION_NAME):\\n    client.delete_collection(COLLECTION_NAME)\\n\\n# Collection 생성\\nclient.create_collection(\\n    collection_name=COLLECTION_NAME,\\n    # 벡터 저장소에 대한 설정. - vector_config는 default이므로 이름을 안줘도 됨(default 로 잡힘) 이름을 줄 거면 {\"이름\":VectorParams()} 설정\\n    vectors_config=VectorParams(\\n        size=VECTOR_SIZE, \\n        distance=Distance.COSINE\\n    )\\n)\\n\\nvectorstore = QdrantVectorStore(\\n    client=client, # QdrantClient\\n    embedding=embeddings, # Embedding Model\\n    collection_name=COLLECTION_NAME # 연결할 Collection 지정.\\n)\\nids = vectorstore.add_documents(menu_documents)\\nprint(f\"저장된 문서 개수: {len(ids)}\")\\n##################################################\\n# Retriever 생성\\n##################################################\\nmenu_retriever = vectorstore.as_retriever(\\n    search_kwargs={\"k\": 3}  # 검색할 결과 개수\\n)\\n\\nfrom langchain_core.runnables import ConfigurableField\\nretriever = menu_retriever.configurable_fields(\\n    search_type=ConfigurableField(\\n        id=\"search_type\"\\n    ),\\n    search_kwargs=ConfigurableField(\\n        id=\"search_kwargs\"\\n    ),\\n)',\n",
       " 'vectorstore': <langchain_qdrant.qdrant.QdrantVectorStore at 0x2a297a783b0>,\n",
       " 'ids': ['00d3b8579d2441368a406e881018b2a4',\n",
       "  'f083c89cdc554997bf1f1911c8cded00',\n",
       "  '3144041dcf604be6b2b8b4de76d74ed4',\n",
       "  '891bdb9b5bc4429dafee5af6e9f6857d',\n",
       "  '1d77ae0b3d0b48e3b3b0aef307e5f095',\n",
       "  'acf79481869a4101bb1018e8c19e9113',\n",
       "  '515faaa09fb344cdb6a33e319d3dffe1',\n",
       "  '07b4323c5b784953a882480cd592a25f',\n",
       "  'a8b318e961d24b62b049a2513cfdc1d9',\n",
       "  '9fc456ca40884dc6be41abc0913420e2',\n",
       "  'a11f4e6d3eec4d03a5f23e20eb2a7f65',\n",
       "  '40c03136fa4c488eac68b5d15a678b5f',\n",
       "  'a0e843eed1264b0eb7bc4fc4344b504f',\n",
       "  'febb6c395a2a441dbb0486d5e00c0815',\n",
       "  '796bcf94dae4406694869cc7fbb3f45d'],\n",
       " 'menu_retriever': VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x000002A297A783B0>, search_kwargs={'k': 3}),\n",
       " 'ConfigurableField': langchain_core.runnables.utils.ConfigurableField,\n",
       " 'retriever': RunnableConfigurableFields(default=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x000002A297A783B0>, search_kwargs={'k': 3}), fields={'search_type': ConfigurableField(id='search_type', name=None, description=None, annotation=None, is_shared=False), 'search_kwargs': ConfigurableField(id='search_kwargs', name=None, description=None, annotation=None, is_shared=False)}),\n",
       " '_i9': 'query=\"쇠고기를 재료로 하는 음식은 뭐가 있어?\"\\nresult = retriever.invoke(query)\\n\\nfor doc in result:\\n    print(doc.metadata)',\n",
       " 'query': '쇠고기를 재료로 하는 음식은 뭐가 있어?',\n",
       " 'result': [Document(metadata={'menu_name': '부르기뇽 스튜', 'price': 28000, 'ingredients': '쇠고기, 적포도주, 양파, 당근, 베이컨', 'source': 'data/restaurant_menu.txt', '_id': '3144041d-cf60-4be6-b2b8-b4de76d74ed4', '_collection_name': 'restaurant_menu'}, page_content='3. 부르기뇽 스튜\\n   - 가격: 28,000원\\n   - 주요 재료: 쇠고기, 적포도주, 양파, 당근, 베이컨\\n   - 메뉴 설명: 프랑스 부르고뉴 지방에서 유래된 스튜 요리로, 고기를 적포도주와 함께 오랜 시간 푹 끓여 부드럽고 진한 풍미를 자랑합니다. 신선한 허브와 채소가 맛을 풍부하게 하고, 바게트와 함께 제공됩니다.'),\n",
       "  Document(metadata={'menu_name': '트러플 피자', 'price': 26000, 'ingredients': '트러플 오일, 모짜렐라 치즈, 얇은 피자 도우, 루꼴라', 'source': 'data/restaurant_menu.txt', '_id': 'acf79481-869a-4101-bb10-18e8c19e9113', '_collection_name': 'restaurant_menu'}, page_content='6. 트러플 피자\\n   - 가격: 26,000원\\n   - 주요 재료: 트러플 오일, 모짜렐라 치즈, 얇은 피자 도우, 루꼴라\\n   - 메뉴 설명: 얇고 바삭한 도우 위에 고급 트러플 오일과 모짜렐라 치즈를 얹어 구워낸 피자입니다. 루꼴라를 더해 신선하고 고소한 맛이 특징입니다. 고급스러운 한 끼를 즐기기에 완벽한 선택입니다.'),\n",
       "  Document(metadata={'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt', '_id': '00d3b857-9d24-4136-8a40-6e881018b2a4', '_collection_name': 'restaurant_menu'}, page_content='1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.')],\n",
       " 'doc': Document(metadata={'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt', '_id': '00d3b857-9d24-4136-8a40-6e881018b2a4', '_collection_name': 'restaurant_menu'}, page_content='1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.'),\n",
       " '_i10': '# Retriever를 tool로 사용\\n# 쿼리를 입력 받아서 retriever로 검색해서 그 결과를 반환하는 tool을 직접 구현\\n@tool\\ndef search_menu(query:str) -> str:\\n    \"\"\"VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\\n    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\\n    \\n    Args:\\n        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\\n    Return:\\n        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.\\n    \"\"\"\\n    result_list = []\\n    docs = retriever.invoke(query)\\n    for doc in docs:\\n        result_list.append({\"content\":doc.page_content, \\n                            \"title\":doc.metadata[\\'menu_name\\'],\\n                            \"url\":doc.metadata[\\'source\\']\\n                            })\\n    if result_list:\\n        result = {\"result\": result_list}\\n    else:\\n        result = {\"result\":\"검색된 메뉴가 없습니다.\"}\\n    \\n    return json.dumps(result, ensure_ascii=False)',\n",
       " '_i11': 'from langchain_core.tools import tool\\n# Retriever를 tool로 사용\\n# 쿼리를 입력 받아서 retriever로 검색해서 그 결과를 반환하는 tool을 직접 구현\\n@tool\\ndef search_menu(query:str) -> str:\\n    \"\"\"VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\\n    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\\n    \\n    Args:\\n        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\\n    Return:\\n        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.\\n    \"\"\"\\n    result_list = []\\n    docs = retriever.invoke(query)\\n    for doc in docs:\\n        result_list.append({\"content\":doc.page_content, \\n                            \"title\":doc.metadata[\\'menu_name\\'],\\n                            \"url\":doc.metadata[\\'source\\']\\n                            })\\n    if result_list:\\n        result = {\"result\": result_list}\\n    else:\\n        result = {\"result\":\"검색된 메뉴가 없습니다.\"}\\n    \\n    return json.dumps(result, ensure_ascii=False)',\n",
       " 'tool': <function langchain_core.tools.convert.tool(name_or_callable: str | collections.abc.Callable | None = None, runnable: langchain_core.runnables.base.Runnable | None = None, *args: Any, description: str | None = None, return_direct: bool = False, args_schema: type[pydantic.main.BaseModel] | dict[str, typing.Any] | None = None, infer_schema: bool = True, response_format: Literal['content', 'content_and_artifact'] = 'content', parse_docstring: bool = False, error_on_invalid_docstring: bool = True, extras: dict[str, typing.Any] | None = None) -> langchain_core.tools.base.BaseTool | collections.abc.Callable[[collections.abc.Callable | langchain_core.runnables.base.Runnable], langchain_core.tools.base.BaseTool]>,\n",
       " 'search_menu': StructuredTool(name='search_menu', description='VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\\n    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\\n\\n    Args:\\n        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\\n    Return:\\n        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.', args_schema=<class 'langchain_core.utils.pydantic.search_menu'>, func=<function search_menu at 0x000002A2C5729B20>),\n",
       " '_i12': 'print(search_menu.name)\\nprint(search_menu.description)\\nprint(search_menu.schema',\n",
       " '_i13': 'print(search_menu.name)\\nprint(search_menu.description)\\nprint(search_menu.schema)',\n",
       " '_i14': 'tool_model = ChatOpenAI(\"gpt-5-mini\").bind_tools(tools=[search_menu])\\nres = tool_model.invoke(\"식당 메뉴 중\")',\n",
       " '_i15': 'tool_model = ChatOpenAI(model=\"gpt-5-mini\").bind_tools(tools=[search_menu])\\nres = tool_model.invoke(\"식당 메뉴 중 면요리를 추천해줘.\")',\n",
       " '_i16': '############################\\n# Agent chain을 구성\\n############################\\nfrom langchain_openai import ChatOpenAI\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_core.runnables import chain\\nfrom langchain_tavily import TavilySearch\\nfrom dotenv import load_dotenv\\nfrom datetime import date\\n\\nload_dotenv()',\n",
       " 'ChatOpenAI': langchain_openai.chat_models.base.ChatOpenAI,\n",
       " 'ChatPromptTemplate': langchain_core.prompts.chat.ChatPromptTemplate,\n",
       " 'MessagesPlaceholder': langchain_core.prompts.chat.MessagesPlaceholder,\n",
       " 'chain': <function langchain_core.runnables.base.chain(func: 'Callable[[Input], Output] | Callable[[Input], Iterator[Output]] | Callable[[Input], Coroutine[Any, Any, Output]] | Callable[[Input], AsyncIterator[Output]]') -> 'Runnable[Input, Output]'>,\n",
       " 'TavilySearch': langchain_tavily.tavily_search.TavilySearch,\n",
       " 'date': datetime.date,\n",
       " '_16': True,\n",
       " '_i17': 'tool_model = ChatOpenAI(model=\"gpt-5-mini\").bind_tools(tools=[search_menu])\\nres = tool_model.invoke(\"식당 메뉴 중 면요리를 추천해줘.\")',\n",
       " 'tool_model': RunnableBinding(bound=ChatOpenAI(profile={}, client=<openai.resources.chat.completions.completions.Completions object at 0x000002A2C57EA330>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002A2C57E9D90>, root_client=<openai.OpenAI object at 0x000002A2C57E8590>, root_async_client=<openai.AsyncOpenAI object at 0x000002A2C57EA210>, model_name='gpt-5.2', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True), kwargs={'tools': [{'type': 'function', 'function': {'name': 'search_wiki', 'description': '이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다.', 'parameters': {'properties': {'query': {'description': 'Wikipedia 에서 검색할 keyword', 'type': 'string'}, 'max_results': {'description': '검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.', 'type': 'integer'}}, 'required': ['query', 'max_results'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'search_menu', 'description': 'VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\\n    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\\n\\n    Args:\\n        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\\n    Return:\\n        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.', 'parameters': {'properties': {'query': {'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'tavily_search', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'Search query to look up', 'type': 'string'}, 'include_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        '}, 'exclude_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        '}, 'search_depth': {'anyOf': [{'enum': ['basic', 'advanced', 'fast', 'ultra-fast'], 'type': 'string'}, {'type': 'null'}], 'default': 'basic', 'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        \\n        Use \"fast\" for optimized low latency with high relevance.\\n        \\n        Use \"ultra-fast\" when latency is prioritized above all else.\\n        '}, 'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        '}, 'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'], 'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        '}, 'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'], 'type': 'string'}, {'type': 'null'}], 'default': 'general', 'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        '}, 'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or after this date.\\n        \\n        Use this parameter when you need to:\\n        - Find recent developments or updates on a topic\\n        - Exclude outdated information from search results\\n        - Focus on content within a specific timeframe\\n        - Combine with end_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-01-15\" for January 15, 2024).\\n        \\n        Examples:\\n        - \"2024-01-01\" - Results from January 1, 2024 onwards\\n        - \"2023-12-25\" - Results from December 25, 2023 onwards\\n        \\n        When combined with end_date, creates a precise date range filter.\\n        \\n        Default is None (no start date restriction).\\n        '}, 'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or before this date.\\n        \\n        Use this parameter when you need to:\\n        - Exclude content published after a certain date\\n        - Study historical information or past events\\n        - Research how topics were covered during specific time periods\\n        - Combine with start_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-03-31\" for March 31, 2024).\\n        \\n        Examples:\\n        - \"2024-03-31\" - Results up to and including March 31, 2024\\n        - \"2023-12-31\" - Results up to and including December 31, 2023\\n        \\n        When combined with start_date, creates a precise date range filter.\\n        For example: start_date=\"2024-01-01\", end_date=\"2024-03-31\" \\n        returns results from Q1 2024 only.\\n        \\n        Default is None (no end date restriction).\\n        '}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[]),\n",
       " 'res': AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 153, 'prompt_tokens': 196, 'total_tokens': 349, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Csj0xhOk3zw5bfJVXUct3BzM2q5FX', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b72df-14f3-7663-897c-83ce6347ae1a-0', tool_calls=[{'name': 'search_menu', 'args': {'query': '면요리'}, 'id': 'call_3icxEAYHczcNopeViNioXr24', 'type': 'tool_call'}], usage_metadata={'input_tokens': 196, 'output_tokens': 153, 'total_tokens': 349, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}}),\n",
       " '_i18': 'res.tool_calls',\n",
       " '_18': [{'name': 'search_menu',\n",
       "   'args': {'query': '면요리'},\n",
       "   'id': 'call_3icxEAYHczcNopeViNioXr24',\n",
       "   'type': 'tool_call'}],\n",
       " '_i19': '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()',\n",
       " '_19': True,\n",
       " '_i20': '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(\"gpt-5.2\").bind_tools(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       " 'tavily_search': TavilySearch(max_results=5, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'), api_base_url=None)),\n",
       " '_i21': '# Runnable을 tool로 변환 -> as_tools\\n## args_schema 설정\\nclass WikiSearchParameterSchema(BaseModel):\\n    query: str = Field(..., description=\"Wikipedia 에서 검색할 keyword\")\\n    max_results: int = Field(description=\"검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.\")\\n\\nsearch_wiki = wikipedia_search.as_tool(\\n    args_schema=WikiSearchParameterSchema,\\n    name=\"search_wiki\",\\n    description=\"\"\"이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다. \\n\"\"\"\\n)',\n",
       " '_i22': '# Runnable을 tool로 변환 -> as_tools\\n## args_schema 설정\\nclass WikiSearchParameterSchema(BaseModel):\\n    query: str = Field(..., description=\"Wikipedia 에서 검색할 keyword\")\\n    max_results: int = Field(description=\"검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.\")\\n\\nsearch_wiki = wikipedia_search.as_tool(\\n    args_schema=WikiSearchParameterSchema,\\n    name=\"search_wiki\",\\n    description=\"\"\"이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다. \\n\"\"\"\\n)',\n",
       " '_i23': 'from langchain_core.tools import tool\\n\\n@tool\\ndef plus(num1:int|float, num2:int|float) -> int|float:\\n    \"\"\"두개 수를 받아서 덧셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\\n    return num1 + num2\\n\\n@tool\\ndef minus(num1:int|float, num2:int|float) -> int|float:\\n    \"\"\"두개 수를 받아서 뺄셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\\n    return num1 - num2\\n\\n@tool\\ndef multiply(num1:int|float, num2:int|float) -> int|float:\\n    \"\"\"두개 수를 받아서 곱셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\\n    return num1 * num2\\n\\n# 파라미터에 대한 자세한 설명이 들어가야 하는 경우 -> Pydantic\\nfrom pydantic import BaseModel, Field\\nclass DivideParameterSchema(BaseModel):\\n    num1: int|float = Field(..., description=\"나눌떄 사용할 첫번째 값\")\\n    num2: int|float = Field(..., description=\"나눌때 사용할 두번째 값\")\\n\\n@tool(\"divide_tool\", args_schema=DivideParameterSchema)\\ndef divide(num1:int|float, num2:int|float) -> int|float:\\n    \"\"\"두개 수를 받아서 나눗셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\\n    return num1 / num2',\n",
       " 'plus': StructuredTool(name='plus', description='두개 수를 받아서 덧셈한 결과를 반환하는 툴', args_schema=<class 'langchain_core.utils.pydantic.plus'>, func=<function plus at 0x000002A29C482CA0>),\n",
       " 'minus': StructuredTool(name='minus', description='두개 수를 받아서 뺄셈한 결과를 반환하는 툴', args_schema=<class 'langchain_core.utils.pydantic.minus'>, func=<function minus at 0x000002A29C481BC0>),\n",
       " 'multiply': StructuredTool(name='multiply', description='두개 수를 받아서 곱셈한 결과를 반환하는 툴', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x000002A29C482980>),\n",
       " 'BaseModel': pydantic.main.BaseModel,\n",
       " 'Field': <function pydantic.fields.Field(default: 'Any' = PydanticUndefined, *, default_factory: 'Callable[[], Any] | Callable[[dict[str, Any]], Any] | None' = PydanticUndefined, alias: 'str | None' = PydanticUndefined, alias_priority: 'int | None' = PydanticUndefined, validation_alias: 'str | AliasPath | AliasChoices | None' = PydanticUndefined, serialization_alias: 'str | None' = PydanticUndefined, title: 'str | None' = PydanticUndefined, field_title_generator: 'Callable[[str, FieldInfo], str] | None' = PydanticUndefined, description: 'str | None' = PydanticUndefined, examples: 'list[Any] | None' = PydanticUndefined, exclude: 'bool | None' = PydanticUndefined, exclude_if: 'Callable[[Any], bool] | None' = PydanticUndefined, discriminator: 'str | types.Discriminator | None' = PydanticUndefined, deprecated: 'Deprecated | str | bool | None' = PydanticUndefined, json_schema_extra: 'JsonDict | Callable[[JsonDict], None] | None' = PydanticUndefined, frozen: 'bool | None' = PydanticUndefined, validate_default: 'bool | None' = PydanticUndefined, repr: 'bool' = PydanticUndefined, init: 'bool | None' = PydanticUndefined, init_var: 'bool | None' = PydanticUndefined, kw_only: 'bool | None' = PydanticUndefined, pattern: 'str | re.Pattern[str] | None' = PydanticUndefined, strict: 'bool | None' = PydanticUndefined, coerce_numbers_to_str: 'bool | None' = PydanticUndefined, gt: 'annotated_types.SupportsGt | None' = PydanticUndefined, ge: 'annotated_types.SupportsGe | None' = PydanticUndefined, lt: 'annotated_types.SupportsLt | None' = PydanticUndefined, le: 'annotated_types.SupportsLe | None' = PydanticUndefined, multiple_of: 'float | None' = PydanticUndefined, allow_inf_nan: 'bool | None' = PydanticUndefined, max_digits: 'int | None' = PydanticUndefined, decimal_places: 'int | None' = PydanticUndefined, min_length: 'int | None' = PydanticUndefined, max_length: 'int | None' = PydanticUndefined, union_mode: \"Literal['smart', 'left_to_right']\" = PydanticUndefined, fail_fast: 'bool | None' = PydanticUndefined, **extra: 'Unpack[_EmptyKwargs]') -> 'Any'>,\n",
       " 'DivideParameterSchema': __main__.DivideParameterSchema,\n",
       " 'divide': StructuredTool(name='divide_tool', description='두개 수를 받아서 나눗셈한 결과를 반환하는 툴', args_schema=<class '__main__.DivideParameterSchema'>, func=<function divide at 0x000002A29C483D80>),\n",
       " '_i24': '# Runnable을 tool로 변환 -> as_tools\\n## args_schema 설정\\nclass WikiSearchParameterSchema(BaseModel):\\n    query: str = Field(..., description=\"Wikipedia 에서 검색할 keyword\")\\n    max_results: int = Field(description=\"검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.\")\\n\\nsearch_wiki = wikipedia_search.as_tool(\\n    args_schema=WikiSearchParameterSchema,\\n    name=\"search_wiki\",\\n    description=\"\"\"이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다. \\n\"\"\"\\n)',\n",
       " 'WikiSearchParameterSchema': __main__.WikiSearchParameterSchema,\n",
       " '_i25': 'from langchain_community.document_loaders import WikipediaLoader # 위키백과 사전 내용을 크롤링해서 문서로 반환.\\nfrom pydantic import BaseModel, Field\\nfrom langchain_core.runnables import chain\\nimport json\\n\\n@chain\\ndef wikipedia_search(inputs:dict) -> str:\\n    \"\"\"사용자 query를 위키백과사전에서 검색하고 검색 결과 중 k개 문서를 반환한다.\\n    Args:\\n        inputs(dict): query-검색할 키워드, max_results(int): 반환할 검색 결과수 를 받는다.\\n    Returns:\\n        str - 검색 결과를 json 으로 반환.\\n              형식: {\"result\":[{검색문서1}, {검색문서2}, ...]}. 검색 문서(dict) - content, url, title로 구성\\n              검색결과가 없을 경우 : {\"result\": \"결과없음\"} 반환.\\n    \"\"\"\\n    query = inputs[\"query\"]\\n    max_results = inputs.get(\"max_results\", 5)\\n    loader = WikipediaLoader(query=query, load_max_docs=max_results, lang=\"ko\")\\n    docs = loader.load() #list[Document]\\n\\n    result_list = []\\n    for doc in docs:\\n        result_list.append({\"content\":doc.page_content, \\n                            \"title\":doc.metadata.get(\\'title\\'),\\n                            \"url\":doc.metadata.get(\"source\")\\n                            })\\n    if result_list:\\n        result = {\"result\": result_list}\\n    else:\\n        result = {\"result\": \"검색 결과가 없습니다.\"}\\n\\n    # JSON 문자열로 변환해서 반환. #json.load() : json문자열을 파이썬 자료구조(dict나 list)로 변환.\\n    return json.dumps(result, ensure_ascii=False) #json.dumps() : 파이썬 자료구조(dict나 list)->json문자열.\\n    # escape_ascii=False: 한글 문자가 나오도록 처리. True: 한글이 유니코드 escape 문자로 나옴(\\\\uxxxx)',\n",
       " 'WikipediaLoader': langchain_community.document_loaders.wikipedia.WikipediaLoader,\n",
       " 'json': <module 'json' from 'C:\\\\Users\\\\Playdata\\\\AppData\\\\Roaming\\\\uv\\\\python\\\\cpython-3.12.12-windows-x86_64-none\\\\Lib\\\\json\\\\__init__.py'>,\n",
       " 'wikipedia_search': RunnableLambda(wikipedia_search),\n",
       " '_i26': '# Runnable을 tool로 변환 -> as_tools\\n## args_schema 설정\\nclass WikiSearchParameterSchema(BaseModel):\\n    query: str = Field(..., description=\"Wikipedia 에서 검색할 keyword\")\\n    max_results: int = Field(description=\"검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.\")\\n\\nsearch_wiki = wikipedia_search.as_tool(\\n    args_schema=WikiSearchParameterSchema,\\n    name=\"search_wiki\",\\n    description=\"\"\"이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다. \\n\"\"\"\\n)',\n",
       " 'search_wiki': StructuredTool(name='search_wiki', description='이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다.', args_schema=<class '__main__.WikiSearchParameterSchema'>, func=<function convert_runnable_to_tool.<locals>.invoke_wrapper at 0x000002A2C563BA60>, coroutine=<function convert_runnable_to_tool.<locals>.ainvoke_wrapper at 0x000002A2C563BB00>),\n",
       " '_i27': '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(\"gpt-5.2\").bind_tools(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       " 'tools': [StructuredTool(name='search_wiki', description='이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\\n사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\\n일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다.', args_schema=<class '__main__.WikiSearchParameterSchema'>, func=<function convert_runnable_to_tool.<locals>.invoke_wrapper at 0x000002A2C563BA60>, coroutine=<function convert_runnable_to_tool.<locals>.ainvoke_wrapper at 0x000002A2C563BB00>),\n",
       "  StructuredTool(name='search_menu', description='VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\\n    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\\n\\n    Args:\\n        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\\n    Return:\\n        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.', args_schema=<class 'langchain_core.utils.pydantic.search_menu'>, func=<function search_menu at 0x000002A2996C4360>),\n",
       "  TavilySearch(max_results=5, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'), api_base_url=None))],\n",
       " 'system_prompt': '\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n',\n",
       " 'prompt': ChatPromptTemplate(input_variables=['query'], optional_variables=['tool_messages'], input_types={'tool_messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000002A2E8A9D300>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'tool_messages': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={}), MessagesPlaceholder(variable_name='tool_messages', optional=True)]),\n",
       " '_i28': '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(\"gpt-5.2\").bind_tools(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       " '_i29': '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(\"gpt-5.2\").bind_tool(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       " '_i30': '#########################################################################\\n# Agent를 구현\\n# 레스토랑 메뉴 추천, 설명 agent\\n# \\n# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\\n#########################################################################\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_openai import ChatOpenAI\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\ntavily_search = TavilySearch(max_results=5)\\ntools = [search_wiki, search_menu, tavily_search]\\n\\nsystem_prompt = \"\"\"\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n\"\"\"\\n\\nprompt = ChatPromptTemplate(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{query}\"),\\n        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\\n    ]\\n)\\ntool_model = ChatOpenAI(model=\"gpt-5.2\").bind_tools(tools=tools)\\ntool_model_chain = prompt | tool',\n",
       " 'tool_model_chain': ChatPromptTemplate(input_variables=['query'], optional_variables=['tool_messages'], input_types={'tool_messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000002A2E8A9D300>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'tool_messages': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\n당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \\n주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\\n\\n주요 지침들(guidelines):\\n1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\\n2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\\n3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\\n4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\\n5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\\n6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\\n7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\\n8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\\n\\n- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\\n- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\\n- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={}), MessagesPlaceholder(variable_name='tool_messages', optional=True)])\n",
       " | RunnableLambda(tool),\n",
       " '_i31': 'res = tool_model_chain.invoke({\"query\":\"파스타 메뉴를 추천해주고 파스타 유래나 역사를 알려줘.\"})',\n",
       " '_i32': 'from langchain_core.tools import tool\\n# Retriever를 tool로 사용\\n# 쿼리를 입력 받아서 retriever로 검색해서 그 결과를 반환하는 tool을 직접 구현\\n@tool\\ndef search_menu(query:str) -> str:\\n    \"\"\"VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\\n    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\\n    \\n    Args:\\n        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\\n    Return:\\n        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.\\n    \"\"\"\\n    result_list = []\\n    docs = retriever.invoke(query)\\n    for doc in docs:\\n        result_list.append({\"content\":doc.page_content, \\n                            \"title\":doc.metadata[\\'menu_name\\'],\\n                            \"url\":doc.metadata[\\'source\\']\\n                            })\\n    if result_list:\\n        result = {\"result\": result_list}\\n    else:\\n        result = {\"result\":\"검색된 메뉴가 없습니다.\"}\\n    \\n    return json.dumps(result, ensure_ascii=False)',\n",
       " '_i33': 'res = tool_model_chain.invoke({\"query\":\"파스타 메뉴를 추천해주고 파스타 유래나 역사를 알려줘.\"})',\n",
       " '_i34': 'res = tool_model_chain.invoke({\"query\":\"파스타 메뉴를 추천해주고 파스타 유래나 역사를 알려줘.\"})',\n",
       " '_i35': 'globals() # 전역변수로 등록된 모든 변수, 함수들을 dictionary 제공. key: \"이름\", value: 변수/함수/클래스'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals() # 전역변수로 등록된 모든 변수, 함수들을 dictionary 제공. key: \"이름\", value: 변수/함수/클래스\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RunnableSequence' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result2 = \u001b[43mwebsearch_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m개졸려요.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m result2\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4871\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4856\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this `Runnable` synchronously.\u001b[39;00m\n\u001b[32m   4857\u001b[39m \n\u001b[32m   4858\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4868\u001b[39m \n\u001b[32m   4869\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4870\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4872\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4873\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4875\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4876\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4877\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4878\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2058\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2054\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   2055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2056\u001b[39m         output = cast(\n\u001b[32m   2057\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2058\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2059\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2060\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2061\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2062\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2066\u001b[39m         )\n\u001b[32m   2067\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2068\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:433\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    432\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4728\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input_, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4726\u001b[39m                 output = chunk\n\u001b[32m   4727\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4728\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4729\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4730\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4731\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:433\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    432\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mwebsearch_agent\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;129m@chain\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwebsearch_agent\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      3\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    Agent 전체 흐름을 처리하는 Runnable\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    사용자 질문(query)을 받아서 tool_model과 tool을 이용해서 최종 응답을 반환한다.\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m    ReAct 구조로 구성. (ReAct Loop)\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     ai_message = \u001b[43mtool_model_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 반환:1, 슬제응답 또는 \u001b[39;00m\n\u001b[32m      9\u001b[39m     messages = []\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# 만약 툴콜이 값이 있다면\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'RunnableSequence' object is not callable"
     ]
    }
   ],
   "source": [
    "result2 = websearch_agent.invoke(\"개졸려요.\")\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RunnableSequence' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result2 = \u001b[43mwebsearch_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m서울 금천구 날씨 알려줘\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4871\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4856\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this `Runnable` synchronously.\u001b[39;00m\n\u001b[32m   4857\u001b[39m \n\u001b[32m   4858\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4868\u001b[39m \n\u001b[32m   4869\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4870\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4872\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4873\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4875\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4876\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4877\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4878\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2058\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2054\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   2055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2056\u001b[39m         output = cast(\n\u001b[32m   2057\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2058\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2059\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2060\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2061\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2062\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2066\u001b[39m         )\n\u001b[32m   2067\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2068\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:433\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    432\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4728\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input_, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4726\u001b[39m                 output = chunk\n\u001b[32m   4727\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4728\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4729\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4730\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4731\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:433\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    432\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mwebsearch_agent\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;129m@chain\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwebsearch_agent\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      3\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    Agent 전체 흐름을 처리하는 Runnable\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    사용자 질문(query)을 받아서 tool_model과 tool을 이용해서 최종 응답을 반환한다.\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m    ReAct 구조로 구성. (ReAct Loop)\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     ai_message = \u001b[43mtool_model_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 반환:1, 슬제응답 또는 \u001b[39;00m\n\u001b[32m      9\u001b[39m     messages = []\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# 만약 툴콜이 값이 있다면\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'RunnableSequence' object is not callable"
     ]
    }
   ],
   "source": [
    "result2 = websearch_agent.invoke(\"서울 금천구 날씨 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mresult2\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'result2' is not defined"
     ]
    }
   ],
   "source": [
    "result2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025년 12월 31일'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.today().strftime(\"%Y년 %m월 %d일\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용자 정의 Tool 구현\n",
    "\n",
    "## @tool 사용\n",
    "- 함수로 구현하고 `@tool` 데코레이터를 사용해 tool(StructuredTool)로 정의한다.\n",
    "    - `langchain_core.tools` 모듈에 있다.\n",
    "- tool name\n",
    "    - 함수의 이름이 tool의 이름이 된다.\n",
    "- parameters\n",
    "    - 함수의 파라미터가 tool의 파라미터가 된다.\n",
    "    - **type hint**를 이용해 타입을 지정한다.  \n",
    "- description\n",
    "    - doctring이 description이 된다.\n",
    "    - RunnableBinding이 tool을 잘 찾을 수 있도록 하려면 **tool의 기능을 최대한 구체적**으로 작성한다.\n",
    "- **@tool이 적용된 함수(StructuredTool)이 tool**이므로 model에 binding 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def plus(num1:int|float, num2:int|float) -> int|float:\n",
    "    \"\"\"두개 수를 받아서 덧셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\n",
    "    return num1 + num2\n",
    "\n",
    "@tool\n",
    "def minus(num1:int|float, num2:int|float) -> int|float:\n",
    "    \"\"\"두개 수를 받아서 뺄셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\n",
    "    return num1 - num2\n",
    "\n",
    "@tool\n",
    "def multiply(num1:int|float, num2:int|float) -> int|float:\n",
    "    \"\"\"두개 수를 받아서 곱셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\n",
    "    return num1 * num2\n",
    "\n",
    "# 파라미터에 대한 자세한 설명이 들어가야 하는 경우 -> Pydantic\n",
    "from pydantic import BaseModel, Field\n",
    "class DivideParameterSchema(BaseModel):\n",
    "    num1: int|float = Field(..., description=\"나눌떄 사용할 첫번째 값\")\n",
    "    num2: int|float = Field(..., description=\"나눌때 사용할 두번째 값\")\n",
    "\n",
    "@tool(\"divide_tool\", args_schema=DivideParameterSchema)\n",
    "def divide(num1:int|float, num2:int|float) -> int|float:\n",
    "    \"\"\"두개 수를 받아서 나눗셈한 결과를 반환하는 툴\"\"\" # docstring -> tool 설명(description)\n",
    "    return num1 / num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "툴이름: divide_tool\n",
      "툴설명: 두개 수를 받아서 나눗셈한 결과를 반환하는 툴\n",
      "args schema(파라미터 설명)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'num1': {'anyOf': [{'type': 'integer'}, {'type': 'number'}],\n",
       "   'description': '나눌떄 사용할 첫번째 값',\n",
       "   'title': 'Num1'},\n",
       "  'num2': {'anyOf': [{'type': 'integer'}, {'type': 'number'}],\n",
       "   'description': '나눌때 사용할 두번째 값',\n",
       "   'title': 'Num2'}},\n",
       " 'required': ['num1', 'num2'],\n",
       " 'title': 'DivideParameterSchema',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(divide))\n",
    "print(\"툴이름:\", divide.name)\n",
    "print(\"툴설명:\", divide.description)\n",
    "print(\"args schema(파라미터 설명)\")\n",
    "divide.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 348, 'prompt_tokens': 322, 'total_tokens': 670, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CsgBra8tsZWX8OPBhBvge9y3huK3i', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b7239-6e50-7401-aa31-74d787ed54d1-0', tool_calls=[{'name': 'plus', 'args': {'num1': 3, 'num2': 5}, 'id': 'call_7bWmSEaE9CjfQliJ6oCsSpPh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 322, 'output_tokens': 348, 'total_tokens': 670, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 320}})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_model = ChatOpenAI(model=\"gpt-5-mini\").bind_tools(tools=[plus, minus, multiply, divide])\n",
    "calc_model.invoke(\"3 + 5 - 20 은 얼마야? 계산에 사용할 툴이 있으면 툴을 이용해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable을 tool로 정의\n",
    "- `Runnable객체.as_tool()`\n",
    "    - name, description, args_schema 파라미터를 이용해 tool의 이름, 설명, 스키마를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader # 위키백과 사전 내용을 크롤링해서 문서로 반환.\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.runnables import chain\n",
    "import json\n",
    "\n",
    "@chain\n",
    "def wikipedia_search(inputs:dict) -> str:\n",
    "    \"\"\"사용자 query를 위키백과사전에서 검색하고 검색 결과 중 k개 문서를 반환한다.\n",
    "    Args:\n",
    "        inputs(dict): query-검색할 키워드, max_results(int): 반환할 검색 결과수 를 받는다.\n",
    "    Returns:\n",
    "        str - 검색 결과를 json 으로 반환.\n",
    "              형식: {\"result\":[{검색문서1}, {검색문서2}, ...]}. 검색 문서(dict) - content, url, title로 구성\n",
    "              검색결과가 없을 경우 : {\"result\": \"결과없음\"} 반환.\n",
    "    \"\"\"\n",
    "    query = inputs[\"query\"]\n",
    "    max_results = inputs.get(\"max_results\", 5)\n",
    "    loader = WikipediaLoader(query=query, load_max_docs=max_results, lang=\"ko\")\n",
    "    docs = loader.load() #list[Document]\n",
    "\n",
    "    result_list = []\n",
    "    for doc in docs:\n",
    "        result_list.append({\"content\":doc.page_content, \n",
    "                            \"title\":doc.metadata.get('title'),\n",
    "                            \"url\":doc.metadata.get(\"source\")\n",
    "                            })\n",
    "    if result_list:\n",
    "        result = {\"result\": result_list}\n",
    "    else:\n",
    "        result = {\"result\": \"검색 결과가 없습니다.\"}\n",
    "\n",
    "    # JSON 문자열로 변환해서 반환. #json.load() : json문자열을 파이썬 자료구조(dict나 list)로 변환.\n",
    "    return json.dumps(result, ensure_ascii=False) #json.dumps() : 파이썬 자료구조(dict나 list)->json문자열.\n",
    "    # escape_ascii=False: 한글 문자가 나오도록 처리. True: 한글이 유니코드 escape 문자로 나옴(\\uxxxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m9 packages\u001b[0m \u001b[2min 2.17s\u001b[0m\u001b[0m\n",
      "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m wikipedia\u001b[2m==1.4.0\u001b[0m\n",
      "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m wikipedia\u001b[2m==1.4.0\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 537ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 15ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwikipedia\u001b[0m\u001b[2m==1.4.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = wikipedia_search.invoke({\"query\":\"2026년 월드컵 개최지\", \"max_results\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': [{'content': \"2026년 FIFA 월드컵(영어: 2026 FIFA World Cup, 프랑스어: Coupe du monde de football de 2026, 스페인어: Copa Mundial de Fútbol 2026)은 2026년 6월 11일부터 7월 19일까지 북아메리카 3개국(캐나다, 멕시코, 미국)에서 열릴 예정인 23번째 FIFA 월드컵이자 48개국 체제의 첫 번째 월드컵으로써 이 대회는 역사상 최초로 무려 세 개의 나라에서 공동으로 개최되는 FIFA 월드컵이다. 또한 멕시코에서는 1970년 FIFA 월드컵, 1986년 FIFA 월드컵에 이어 40년만에 세 번째로 개최된 FIFA 월드컵, 1994년 FIFA 월드컵에 이어 미국에서는 32년 만에 두 번째로 개최된 FIFA 월드컵이며 캐나다에서는 사상 처음으로 개최된 월드컵이다.\\n\\n\\n== 개최국 선정 ==\\n\\n원래는 2017년 5월 10일 말레이시아 쿠알라룸푸르에서 개최지가 결정될 예정이었지만 2018년 FIFA 월드컵과 2022년 FIFA 월드컵 유치 과정에서 일어난 비리 사건(2015년 국제 축구 연맹 부패 사건) 수사에 관한 여파로 인해 연기되었다. 2016년 2월에 취임한 잔니 인판티노 FIFA 회장이 FIFA 회장 선거에서 2026년 FIFA 월드컵 본선 참가국 수를 40개국으로 늘리겠다고 공약하여 당선되었고 2017년 1월 10일 스위스 취리히에서 열린 FIFA 이사회에서 투표를 통해 만장일치로 참가국을 48개국으로 확대하게 되었다.\\n2026년 FIFA 월드컵 본선 개최 유치 후보국의 자격은 2018년 FIFA 월드컵 개최 대륙 연맹인 유럽 축구 연맹 소속 국가 축구 협회, 2022년 FIFA 월드컵 개최 대륙 연맹인 아시아 축구 연맹 소속 국가 축구 협회를 제외하고 모두 입후보 자격이 있다. 그러므로 북중미 축구 연맹, 남미 축구 연맹, 아프리카 축구 연맹, 오세아니아 축구 연맹 소속 국가 축구 협회들은 입후보 자격이 있다. 또한 2개국 이상의 국가 축구 협회들이 FIFA 월드컵 본선 대회를 공동 개최국 후보에 출마할 수 있다.\\n개최를 희망했던 국가\\n\\n아메리카\\n 캐나다– 멕시코– 미국 (3개국 공동 개최)\\n아프리카\\n 모로코\\n\\nFIFA 총회는 2018년 6월 13일 러시아 모스크바에서 열린 회의에서 캐나다–멕시코–미국을 2026년 FIFA 월드컵 개최국으로 선정했다.\\n\\n\\n== 지역 예선 ==\\n\\n\\n=== 징계 ===\\n에콰도르는 팀 소속 선수인 바이런 카스티요의 생년월일을 허위(실제로 1995년 6월 25일생이나, 1998년 11월 10일생으로 기록)로 기재하여, 승점이 삭감되어 –3점으로 시작한다.\\n러시아는 2022년 2월 일어난 러시아-우크라이나 전쟁이 종전될 때까지 무기한 출전 자격이 박탈된다.\\n\\n\\n=== 본선 진출국 ===\\n\\n\\n=== 슬롯 할당 ===\\n2017년 3월 30일, FIFA 평의회 사무국(FIFA 회장과 6개 연맹 회장으로 구성)은 2026년 FIFA 월드컵의 슬롯 할당을 제안했다. FIFA 평의회의 비준을 위해 추천이 제출되었다.\\n제67회 FIFA 총회 이틀 전인 5월 9일, FIFA 이사회는 바레인 마나마에서 열린 회의에서 슬롯 할당을 승인했다. 여기에는 6개 팀이 FIFA 월드컵의 마지막 두 자리를 결정하는 대륙간 플레이오프 토너먼트가 포함된다.\\n\\n다수의 개최국이 존재하는 상황에서 자동 개최국 자격을 부여하는 방식에 대한 문제는 아직 해결되지 않았으며 FIFA 평의회에서 결정할 예정이다.\\n북미 3국 유치팀은 3개 개최국 모두가 자동으로 자리를 차지할 것으로 예상했다.\\n슬롯 배정 비준으로 오세아니아는 FIFA 월드컵 역사상 처음으로 월드컵 본선 진출이 보장되었다. 2026년 FIFA 월드컵은 6개 연맹이 모두 참가권을 보장받은 최초의 토너먼트가 될 것이다.\\n\\n\\n=== 대륙간 플레이오프 ===\\n6개 팀이 참가하는 플레이오프가 개최되어, FIFA 월드컵의 마지막 두 자리를 결정한다. 연맹당 1팀(유럽 제외)과 연맹의 추가 1팀으로 구성 개최 대륙(북중미)된다. FIFA 세계 랭킹에 따라 두 팀들이 시드되 시드된 팀은 시드되지 않은 4개 팀이 참가하는 첫 두 경기의 승자와 FIFA 월드컵 접전을 펼친다. 토너먼트는 개최국에서 진행되며, FIFA 월드컵의 테스트 이벤트로 사용되며, 2025년 11월과 2026년 3월의 기존 플레이오프 기간이 2026년 판의 잠정 날짜로 제안되었다.\\n\\n\\n== 본선 ==\\n4팀씩 12개조로 나누어서 조별리그를 진행하며 각 조의 1위와 2위를 차지한 24팀과 각 조 3위팀 중 상위 8팀이 32강 토너먼트에 합류한다.\\n\\n\\n== 개최 도시 및 경기장 ==\\n입찰 과정에서 41개 도시에서 43개의 기존의 완전한 기능을 갖춘 경기장과 2개의 건설 중인 경기장이 입찰의 일부로 제출(멕시코 3개 도시에 3개 경기장, 캐나다 7개 도시에 9개 경기장, 미국 34개 도시에 38개 경기장)되었다.1라운드 탈락으로 9개의 장소와 9개의 도시가 중단: 2차 예선 탈락으로 6개 도시에서 9개 경기장이 추가로 줄어들었고, FIFA가 재정 세부 사항에 대해 논의하지 않으려는 이유로 3개 도시(시카고, 미니애폴리스, 밴쿠버)에서 3개 경기장이 탈락했다. 2021년 7월 몬트리올이 중단된 후 밴쿠버는 2022년 4월 후보 도시로 복원되어 각각 고유한 도시 또는 대도시 지역(로스앤젤레스 제외)에 총 24개의 장소가 생겼다. 워싱턴 D.C.와 볼티모어는 입찰을 결합하여 DC의 FedExField를 제거하고 볼티모어의 M&T 뱅크 스타디움과 페덱스필드의 열악한 상태에 대한 우려로 선택한 경기장으로 만들었으나, 이번 입찰을 위한 FIFA 팬 페스트 이벤트는 DC 내셔널 몰에서 개최된다.\\n캐나다와 미국에는 스포츠를 염두에 두고 설계된 '축구 전용 경기장'이 있지만, 미국 최대 규모의 축구 전용 경기장인 지오디스 파크(Geodis Park)는 3만석으로 FIFA가 기준으로 정해놓은 최소 4만석에 못 미치는 수준이다. MLS 홈경기장으로 사용되는 곳은 이번 대회를 위해 30,000에서 45,500으로 확장되나, 애틀랜타의 메르세데데스-벤츠 스타디움과 시애틀의 루멘 필드와 같이 NFL과 MLS 팀이 모두 사용하는 경기장이 주로 골대 풋볼에 사용되었지만, 내셔널 풋볼 리그 팀 및 NCAA 디비전 I 대학 풋볼 프로그램을 주최한 미식 경기장과 캐나다 풋볼 리그(CFL)를 주최하는 캐나다 스타디움과 함께 모든 캐나다 및 미식 경기장이 사용되었다. 협회 축구 경기를 위한 수많은 기회와 협회 축구 이벤트를 주최하도록 설계되었다.\\n2022년 6월 16일 FIFA에서 개최 도시를 발표했다. 서부 디비전의 밴쿠버, 시애틀, 샌프란시스코, 로스앤젤레스, 과달라하라, 센트럴 디비전의 캔자스시티, 댈러스, 휴스턴, 애틀랜타, 몬테레이, 멕시코시티, 토론토, 동부 디비전의 보스턴, 뉴욕시, 필라델피아 및 마이애미(캐나다 2개, 멕시코 3개, 미국 11개)이다.\\n\\n는 이전 남자 월드컵 토너먼트에 사용된 경기장을 나타냄(미국과 멕시코만 해당).\\n은 고정식 또는 수납식 지붕이 있는 실내 경기장을 나타냄.\\n\\n\\n=== 캐나다 ===\\n\\n\\n=== 멕시코 ===\\n\\n\\n=== 미국 ===\\n\\n\\n=== 조 추첨 ===\\n추첨은 2025년 12월 5일 금요일 낮 12:00 UTC−5(EST(북미 동부 표준시))에 워싱턴 D.C.의 케네디 센터에서 진행될 것이다. 48개 팀은 12개 팀씩 4개의 포트로 나뉠 것이다. 포트 1은 개최국 3개 팀과 2025년 11월 FIFA 남자 세계 랭킹 상위 9개 팀으로 구성될 것이다. 포트 2, 3, 4는 랭킹에 따라 나머지 팀으로 구성된다. 유럽 예선 플레이오프의 4개 우승자들와 대륙간 플레이오프의 2개 승자들는 추첨 당시에는 알 수 없다. 이러한 경기는 2026년 3월에 진행될 예정이어서 자동으로 포트 4에 할당되었다. 12개 조들은 4개의 포트에서 각각 한 팀씩 선택하여 무작위로 구성된다. 같은 대륙 간 플레이오프 우승팀을 포함한 UEFA 팀을 제외하고, 같은 조에 편성될 수 없다. UEFA 팀은 조당 최소 1팀에서 최대 2팀까지만 편성되어야 한다(UEFA 플레이오프 우승팀 자리 포함).\\n3개 개최국은 일정 조정을 위해 3개 조에 미리 배정되었다. 멕시코는 A조에 편성되어 6월 11\",\n",
       "   'title': '2026년 FIFA 월드컵',\n",
       "   'url': 'https://ko.wikipedia.org/wiki/2026%EB%85%84_FIFA_%EC%9B%94%EB%93%9C%EC%BB%B5'},\n",
       "  {'content': \"2002년 FIFA 월드컵(영어: 2002 FIFA World Cup, 일본어: 2002 FIFAワールドカップ)은 17번째 FIFA 월드컵 대회로, 2002년 5월 31일에서 6월 30일까지 대한민국과 일본에서 열렸다.\\n최초로 아시아에서 열린 FIFA 월드컵 대회로 골든골 제도가 시행된 마지막 FIFA 월드컵이자 전 대회 우승국 자동 출전권이 적용된 마지막 FIFA 월드컵이기도 하다. 또한 이 대회는 역사상 최초로 두 개 이상의 나라에서 공동으로 개최된 FIFA 월드컵이기도 하다. 브라질은 결승전에서 독일을 2 – 0으로 이기고 대회 역대 최다인 5번째 우승을 차지했다. 이 대회 우승으로 브라질은 FIFA 월드컵 우승국 자격으로 2005년 FIFA 컨페더레이션스컵 참가 자격을 얻었으며, 이도 또한 해당 대회의 5번째 출전 대회이다. 튀르키예는 대한민국과의 3위 결정전 경기에서 3-2로 승리해 이 대회를 3위로 마감하였다. 에콰도르, 세네갈, 슬로베니아, 중국이 이 대회를 통해 월드컵에 처음으로 모습을 나타냈으며, 튀르키예는 1954년 이후 48년만에 본선에 모습을 드러냈다.\\n충격적인 결과와 이변이 속출한 대회로 전 대회 우승팀 프랑스가 승점 1점을 얻는데 그치고 무득점으로 조별 리그에 탈락하였고, 또다른 우승 후보인 아르헨티나 역시 조별 리그에서 살아남지 못했다. 또한 튀르키예가 깜짝 3위를 기록하였고, 공동 개최국 대한민국은 포르투갈, 이탈리아, 그리고 스페인을 차례로 무너뜨리고 준결승전까지 진출하였다. 또다른 대이변으로는 세네갈이 개막전에서 프랑스를, 16강전에서 스웨덴을 제압하고 8강에 오른 것으로 여기서 튀르키예에게 아쉽게 제동이 걸렸다. 물론, 이 대회에서 가장 강력한 모습을 보인 국가는 브라질로, 이 대회에서 5번째로 FIFA 월드컵을 우승한 최초의 국가가 되었다.\\n공식 슬로건은 '새 천년, 새 만남, 새 출발'(New Millenium, New Encounter, New Start)로 하였다.\\n\\n\\n== 개최지 선정 ==\\n\\n1991년 6월 일본에서 2002 월드컵 유치위원회를 발족하였고,1994년 한국은 월드컵 유치위원회를 조직했다,1995년 2월에 멕시코 사퇴.\\n대한민국과 일본이 1996년 5월 31일, FIFA에 의해 개최국으로 선정되었다. 본래 대한민국, 일본, 그리고 멕시코가 셋이서 따로 경합했었다. 그러나, 두 아시아 국가들이 최종 결정이 나기 전에 협력할 것을 합의하였고, 양국은 멕시코를 제치고 만장일치로 개최국이 되었다. 이 대회는 복수의 국가에서 개최하는 최초의 FIFA 월드컵이다.\\n결정이 내려지던 시점까지 일본은 단 한번도 FIFA 월드컵 본선에 출전하지 못하였다. (일본은 개최국 선정 이후인 1998년에서야 본선에 처음으로 진출하였다.) FIFA 월드컵 개최국들 대회 유치 전까지 한번도 출전하지 못한 국가는 1934년의 이탈리아와 2022년의 카타르 뿐이다. (우루과이는 1930년 초대 FIFA 월드컵을 개최함에 따라 그 전 대회가 없었으며, 이들은 1928년 하계 올림픽에서 금메달을 획득했었다.)\\n이 과정에서 되려 남아메리카가 당사국들인 대한민국과 일본보다 더 노골적으로 한쪽 국가를 지지하면서 분위기가 매우 과열되었다.\\n\\n대한민국 지지: 아르헨티나, 우루과이, 페루, 볼리비아\\n일본 지지: 브라질, 칠레, 파라과이, 에콰도르\\n이례적인 개최국 선정은 대부분 시차가 거의 없는 국가들에서 주로 축구를 하던 유럽에는 화젯거리였다. 경기는 유럽 기준으로 아침 시간에 열렸고, 일부 학교와 기업들은 경기일에는 늦게 문을 열거나 근무 시간 초에 사내 응원을 했다.\\n\\n\\n== 지역 예선 ==\\n\\n총 199개국이 2002년 FIFA 월드컵 본선행을 놓고 경합하였고, 1999년 12월 7일, 도쿄에서 예선 추첨식이 거행되었다. 전 대회 우승국 프랑스와 공동 개최국 대한민국과 일본은 자동 출전권을 획득함에 따라 예선전에서 빠졌다. 이 대회는 전 대회 우승팀(디펜딩 챔피언)이 자동 출전권을 얻은 마지막 FIFA 월드컵이다.\\nUEFA (유럽) 에 배당된 진출권 수는 14장이며, CAF (아프리카)에는 5장, CONMEBOL (남아메리카)에는 4장, AFC (아시아) 에 2장, 그리고 CONCACAF (북중미 및 카리브해) 에 3장이 배당되었다. 남은 두장은 AFC-UEFA, CONMEBOL-OFC (오세아니아) 대륙간 플레이오프를 통해 결정되었다. 4개국(중국, 에콰도르, 세네갈, 그리고 슬로베니아)이 본선에 처음으로 모습을 드러내었다. 2022년 기준으로 이 대회는 튀르키예, 중국, 아일랜드가 밟은 마지막 FIFA 월드컵 본선 무대이다.\\n튀르키예는 1954년 이후 48년 만에 본선 무대에 등장하였고, 폴란드와 포르투갈은 1986년 이후 16년만이었다. 1998년 대회에서 준결승에 진출한 네덜란드는 본선진출에 실패하였으며, 대한민국은 비유럽, 비아메리카 최초로 5대회 연속 본선 진출의 위업을 달성하였다.\\nFIFA 월드컵을 우승한 전적이 있는 7개국(우루과이, 이탈리아, 독일, 브라질, 잉글랜드, 아르헨티나, 그리고 프랑스) 모두가 본선 진출에 성공하였고, 이들이 모두 출전한 대회는 이 대회가 1986년(당시 프랑스는 아직 대회 우승을 거둔 적이 없었다.) 대회 이후로는 최초이다.\\n\\n\\n=== 본선 진출국 목록 ===\\n다음은 본선에 진출한 32개국과 각국의 2002년 5월 15일 기준의 FIFA 랭킹이다.\\n\\n\\n== 시드 배정 ==\\n\\n2002년 대회에서 시드를 받을 팀이 2001년 11월 28일에 결정되었다. 시드를 받은 국가는 A포트에 들어갔다. B포트에는 시드 배정을 받지 못한 11개의 유럽 국가들이 들어갔다. C포트에는 시드 배정을 못 받은 CONMEBOL과 AFC 소속 국가들이 편성되었다. D포트는 시드 배정을 받지 못한 CONCACAF와 CAF 소속 국가들이 들어갔다. 이 대회는 A조 톱시드로 전 대회 우승팀을 배정한 마지막 FIFA 월드컵 대회이다. 이 자리는 2006년 대회부터 개최국에게 고정적으로 배정되었다. 추첨 방식은 다음과 같다.\\n\\nA포트에 속한 팀은 전 대회 우승국인 프랑스는 A조, 공동 개최국인 대한민국과 일본은 각각 D조와 H조에 배정되며, 나머지 팀은 무작위로 추첨한다. 단, 톱 시드를 받은 남아메리카 팀인 브라질, 아르헨티나는 대한민국과 일본 양쪽에 분산 배치된다.\\nB포트에 속한 팀은 각 조에 한 팀씩 배정된다. 이 과정에서 남은 3개 팀은 한 조에 3개 이상의 유럽 팀이 들어가는 것을 방지하기 위한 차원에서 비유럽 톱 시드 팀인 대한민국, 일본, 브라질, 아르헨티나가 속한 4개 조들 중에서 3개 조에 배정된다.\\nC포트에 속한 팀은 B그룹 중 3개국이 배정되지 않은 조에 배정하며, 같은 대륙에 속한 팀이 있는 조로 배정할 수 없다. 중국은 인접성과 흥행을 고려해 대한민국에서 경기를 치르고, 이에 따라 사우디아라비아는 자연적으로 일본에서 경기를 치르게 된다.\\nD포트에 속한 팀은 각 조에 어떠한 제약 조건도 없이 무작위로 배정한다. 단 같은 대륙에 속한 팀이 대한민국이나 일본에 편중되는 것을 막기 위해 최소 2개의 아프리카 팀과 1개의 북아메리카 팀이 대한민국이나 일본에서 경기를 치를 수 있도록 배정한다.\\n2001년 12월 1일, 부산의 벡스코에서 조추첨식이 열렸고, 각국의 일정이 최종 결정되었다. 아르헨티나, 나이지리아, 잉글랜드, 그리고 스웨덴이 들어간 F조가 죽음의 조라는 평가가 나왔다.\\n\\n\\n=== 순위 규정 ===\\n복수의 국가가 승점에서 동률을 이룰 경우 다음 순서에 따라 조별 리그 순위가 결정되었다:\\n\\n조별 리그 3경기에서의 골득실차\\n조별 리그 3경기에서의 득점 횟수\\n위 조건에서도 모두 동률인 경우, 동률인 팀들만 묶어서 재고려되었고, 다음 순서로 결정되었다:\\n동률인 팀들간의 경기에서 획득한 승점\\n동률인 팀들간의 골득실차\\n동률인 팀들간의 득점 횟수\\n위의 조건이 모두 동률인 경우 FIFA의 추첨에 의해 최종 순위가 결정되었다.\\n\\n기존의 대회 본선 규정에서, 순위 규정은 다른 형식으로 결정되었는데, 상대 전적이 골득실차보다 우선이었다. 규정은 대회를 앞두고 다음과 같이 변경되었으나, 기존의 규정 또한 FIFA와 UEFA의 웹사이트 등에 확인할 수 있어서, 올바른 규정을 찾는데에 있어서 혼선을 빚었다\",\n",
       "   'title': '2002년 FIFA 월드컵',\n",
       "   'url': 'https://ko.wikipedia.org/wiki/2002%EB%85%84_FIFA_%EC%9B%94%EB%93%9C%EC%BB%B5'},\n",
       "  {'content': '2030년 FIFA 월드컵(2030 FIFA World Cup)은 2030년에 열릴 예정인 24번째 FIFA 월드컵이며, 또한 FIFA 월드컵 100주년 기념 대회이기도 하다. 2030년 월드컵은 월드컵 100주년 대회를 기념할 것이다. 역사상 두 번째로 세 개의 나라에서 공동으로 개최된 FIFA 월드컵이다.\\n\\n\\n== 개최국 선정 ==\\n\\n2030년 FIFA 월드컵 본선 개최 유치 후보국의 자격은 2022년 FIFA 월드컵 개최대륙 연맹인 아시아 축구 연맹 소속 국가 축구협회 및 2026년 FIFA 월드컵 개최대륙 연맹인 북중미카리브 축구 연맹 소속 국가 축구협회를 제외하고, 모든 국가 축구협회에 있다.\\n개최국들은 40,000명을 수용할 수 있는 전좌석 경기장들을 최소 14개 이상 보유해야 하며, 최소 7개는 기존 경기장에 있어야 한다. 개막전과 결승전은 8만 석 규모의 경기장에서 치뤄져야 하며, 준결승전은 6만 석 규모의 경기장에서 치뤄져야 한다. 개최국들은 또한 팀 베이스캠프를 위한 최소 72개의 적절한 훈련장 옵션, 경기장당 4개의 적절한 경기장별 훈련장 옵션, 2개의 적절한 심판 베이스캠프 훈련장 옵션 외에 모두 적절한 숙박 시설을 갖추고 있어야 한다. FIFA 평의회는 또한 방송 현장, 대회 관련 행사 현장, 숙박 시설과 관련된 요구 사항을 규제한다. 또한 지속 가능성, 환경 보호 및 인권도 \"레거시 기금\" 설립 조항 외에도 정부 지원, 사용할 조직 모델과 함께 협의회에서 고려되는 요소가 될 것이다.\\n\\n개최를 희망하는 국가\\n유럽과 아프리카\\n 모로코- 포르투갈- 스페인 (3개국 공동 개최 확정)\\n남아메리카\\n 우루과이- 아르헨티나- 파라과이- 칠레 (4개국 공동 개최): 1930년 우루과이에서 최초로 개최된 FIFA 월드컵 100주년을 기념하기 위해 우루과이, 아르헨티나, 파라과이, 칠레 4개국이 공동 개최를 추진하고 있다. 원래는 우루과이가 단독개최를 하려고 했으나 지금 월드컵의 규모가 1회 때와는 비교할 수 없을 정도로 거대해져 우루과이의 경제력만으로는 감당이 안되기 때문에 공동 유치로 선회했다. 우루과이와 아르헨티나는 2017년 7월 29일에 2030년 FIFA 월드컵 공동 유치 계획을 승인했다. 2017년 10월 4일에는 파라과이가 추가로 합류하였으며, 2019년 2월 14일에는 칠레가 추가로 합류함으로써 남미의 월드컵 유치 전선에 뛰어들게 되었다.\\n\\n\\n== 잠정적 개최지 ==\\n† 이전 남자 월드컵 대회에서 사용된 경기장을 뜻한다. (아르헨티나, 스페인, 우루과이 한정)\\n⋆ 신설 예정 경기장\\n+ 리모델링/개축 예정 경기장\\n\\n월드컵 100주년 기념 행사 경기 개최 도시:\\n\\n\\n== 지역 예선 ==\\n\\n\\n=== 징계 ===\\n러시아는 2022년 2월 일어난 러시아-우크라이나 전쟁이 종전될 때까지 무기한 출전 자격이 박탈된다.\\n\\n\\n=== 본선 진출국 ===\\n모든 6개 개최국들은 2030년 FIFA 월드컵에 자동본선진출할 것이다.\\n\\n\\n=== 슬롯 할당 ===\\n\\n\\n=== 대륙간 플레이오프 ===\\n6개 팀이 참가하는 플레이오프가 개최되어, FIFA 월드컵의 마지막 두 자리를 결정한다. 유럽에서 개최되어서 모든 대륙 연맹당 1팀씩 참가한다. FIFA 랭킹에 따라 시드된 팀은 시드되지 않은 4개 팀이 참가하는 첫 두 경기의 승자와 FIFA 월드컵 접전을 펼친다. 토너먼트는 개최국에서 진행된다.\\n\\n\\n== 중계권 ==\\n 대한민국 - JTBC, JTBC GOLF&SPORTS\\n\\n\\n== 각주 ==',\n",
       "   'title': '2030년 FIFA 월드컵',\n",
       "   'url': 'https://ko.wikipedia.org/wiki/2030%EB%85%84_FIFA_%EC%9B%94%EB%93%9C%EC%BB%B5'}]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_8980\\92423901.py:7: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  search_wiki = wikipedia_search.as_tool(\n"
     ]
    }
   ],
   "source": [
    "# Runnable을 tool로 변환 -> as_tools\n",
    "## args_schema 설정\n",
    "class WikiSearchParameterSchema(BaseModel):\n",
    "    query: str = Field(..., description=\"Wikipedia 에서 검색할 keyword\")\n",
    "    max_results: int = Field(description=\"검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.\")\n",
    "\n",
    "search_wiki = wikipedia_search.as_tool(\n",
    "    args_schema=WikiSearchParameterSchema,\n",
    "    name=\"search_wiki\",\n",
    "    description=\"\"\"이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\n",
    "사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\n",
    "일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다. \n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_wiki\n",
      "이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\n",
      "사용자의 질문과 관련된 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\n",
      "일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'query': {'description': 'Wikipedia 에서 검색할 keyword',\n",
       "   'title': 'Query',\n",
       "   'type': 'string'},\n",
       "  'max_results': {'description': '검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.',\n",
       "   'title': 'Max Results',\n",
       "   'type': 'integer'}},\n",
       " 'required': ['query', 'max_results'],\n",
       " 'title': 'WikiSearchParameterSchema',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(search_wiki.name)\n",
    "print(search_wiki.description)\n",
    "search_wiki.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_model = ChatOpenAI(model=\"gpt-5-mini\").bind_tools(tools=[search_wiki])\n",
    "\n",
    "res = tool_model.invoke(\"월드컵에 대한 내용을 위키백과사전에서 조회해서 정리해줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[{'name': 'search_wiki', 'args': {'query': '월드컵', 'max_results': 5}, 'id': 'call_IbMj18AW3Mwu1xTE1wqeuBFX', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "print(res.content)\n",
    "print(res.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store(Vector 저장소) tool\n",
    "\n",
    "### text loading -> Document 생성\n",
    "- 레스토랑 메뉴를 vector store에 저장한다.\n",
    "1. 메뉴 text 를 로딩한다.\n",
    "2. 각 메뉴의 내용(음식이름, 메뉴설명, 파일명)을 넣어 Document를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 Load\n",
    "import os\n",
    "# 메뉴읽어 오기\n",
    "menu_file_path = \"data/restaurant_menu.txt\"\n",
    "with open(menu_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    menu = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt'}, page_content='1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split - 메뉴별로 분리하기 위해 직접 처리\n",
    "from langchain_core.documents import Document\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "def create_documents(menu_all: str, file_name) -> list[Document]:\n",
    "    \"\"\"메뉴별로 분리 한뒤 Document로 변환. 변환된 Document들을 리스트로 반환\n",
    "    metadata: 메뉴이름, 주요 재료, 가격, source(파일이름)\n",
    "    \"\"\"\n",
    "    menu_list = menu_all.split(\"\\n\\n\")\n",
    "    menu_documents = [] # 개별 메뉴로 Document를 생성. 그것들을 저장할 list를 만듬.\n",
    "    for menu_item in menu_list:\n",
    "\n",
    "        # 메뉴 이름 추출\n",
    "        menu_name_pattern = r\"(^\\d+.\\s)([가-힣a-zA-Z\\d ]+)\" \n",
    "        # (^\\d+.\\s) : 숫자로 시작. 그다음 . 그러고 공백.\n",
    "        # 숫자가 있어서 후방 검색이 안됨.\n",
    "        menu_name_result = re.search(menu_name_pattern, menu_item)\n",
    "        menu_name = menu_name_result.group(2).strip()  # 메뉴 이름 추출 # 1은 번호\n",
    "\n",
    "        # 주요재료 추출 - text로 indexing.\n",
    "        menu_ingredient_pattern = r\"(?<=주요 재료: ).+\" # ?<= 검색할 때 쓰지만, 값은 주지마.\n",
    "        ingredients = re.search(menu_ingredient_pattern, menu_item).group().strip()\n",
    "    \n",
    "        # 가격추출\n",
    "        price_pattern = r\"(?<=가격: )[\\d,]+(?=원)\"\n",
    "        # 전방 후방탐색 동시에. 가격과 원을 검색할때 쓰지만, 값은 필요 없음.\n",
    "        price_result = re.search(price_pattern, menu_item)\n",
    "        price = int(price_result.group().replace(\",\", \"\")) # 숫자에서 쉼표 지워버림.\n",
    "\n",
    "        \n",
    "        # 메뉴 이름을 제외한 나머지는 메뉴 설명으로 간주\n",
    "        menu_doc = Document(\n",
    "            page_content=menu_item,     # 메뉴 설명을 page_content에 넣는다. metadata는 나중에 따로 따로 payload filtering 할 수있기 때문에 \n",
    "            metadata={\n",
    "                \"menu_name\": menu_name, # 메뉴 이름\n",
    "                \"price\": price,         # 가격\n",
    "                \"ingredients\": ingredients, # 재료 리스트\n",
    "                \"source\": file_name     # 메뉴가 저장된 파일 이름\n",
    "            }\n",
    "        )\n",
    "        menu_documents.append(menu_doc)\n",
    "    return menu_documents\n",
    "\n",
    "\n",
    "menu_documents = create_documents(menu, menu_file_path)\n",
    "print(len(menu_documents))\n",
    "menu_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 문서 개수: 15\n"
     ]
    }
   ],
   "source": [
    "# VectorDB 저장 및 VectorStore 생성\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "COLLECTION_NAME = \"restaurant_menu\"\n",
    "VECTOR_SIZE = 1536  # OpenAIEmbeddings의 벡터 크기\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "if client.collection_exists(COLLECTION_NAME):\n",
    "    client.delete_collection(COLLECTION_NAME)\n",
    "\n",
    "# Collection 생성\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    # 벡터 저장소에 대한 설정. - vector_config는 default이므로 이름을 안줘도 됨(default 로 잡힘) 이름을 줄 거면 {\"이름\":VectorParams()} 설정\n",
    "    vectors_config=VectorParams(\n",
    "        size=VECTOR_SIZE, \n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "vectorstore = QdrantVectorStore(\n",
    "    client=client, # QdrantClient\n",
    "    embedding=embeddings, # Embedding Model\n",
    "    collection_name=COLLECTION_NAME # 연결할 Collection 지정.\n",
    ")\n",
    "ids = vectorstore.add_documents(menu_documents)\n",
    "print(f\"저장된 문서 개수: {len(ids)}\")\n",
    "##################################################\n",
    "# Retriever 생성\n",
    "##################################################\n",
    "menu_retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3}  # 검색할 결과 개수\n",
    ")\n",
    "\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "retriever = menu_retriever.configurable_fields(\n",
    "    search_type=ConfigurableField(\n",
    "        id=\"search_type\"\n",
    "    ),\n",
    "    search_kwargs=ConfigurableField(\n",
    "        id=\"search_kwargs\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'menu_name': '부르기뇽 스튜', 'price': 28000, 'ingredients': '쇠고기, 적포도주, 양파, 당근, 베이컨', 'source': 'data/restaurant_menu.txt', '_id': '3144041d-cf60-4be6-b2b8-b4de76d74ed4', '_collection_name': 'restaurant_menu'}\n",
      "{'menu_name': '트러플 피자', 'price': 26000, 'ingredients': '트러플 오일, 모짜렐라 치즈, 얇은 피자 도우, 루꼴라', 'source': 'data/restaurant_menu.txt', '_id': 'acf79481-869a-4101-bb10-18e8c19e9113', '_collection_name': 'restaurant_menu'}\n",
      "{'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt', '_id': '00d3b857-9d24-4136-8a40-6e881018b2a4', '_collection_name': 'restaurant_menu'}\n"
     ]
    }
   ],
   "source": [
    "query=\"쇠고기를 재료로 하는 음식은 뭐가 있어?\"\n",
    "result = retriever.invoke(query)\n",
    "\n",
    "for doc in result:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "# Retriever를 tool로 사용\n",
    "# 쿼리를 입력 받아서 retriever로 검색해서 그 결과를 반환하는 tool을 직접 구현\n",
    "@tool\n",
    "def search_menu(query:str) -> str:\n",
    "    \"\"\"VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\n",
    "    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\n",
    "    \n",
    "    Args:\n",
    "        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\n",
    "    Return:\n",
    "        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.\n",
    "    \"\"\"\n",
    "    result_list = []\n",
    "    docs = retriever.invoke(query)\n",
    "    for doc in docs:\n",
    "        result_list.append({\"content\":doc.page_content, \n",
    "                            \"title\":doc.metadata['menu_name'],\n",
    "                            \"url\":doc.metadata['source']\n",
    "                            })\n",
    "    if result_list:\n",
    "        result = {\"result\": result_list}\n",
    "    else:\n",
    "        result = {\"result\":\"검색된 메뉴가 없습니다.\"}\n",
    "    \n",
    "    return json.dumps(result, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_menu\n",
      "VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\n",
      "    이 도구는 query에 맞는 식당 메뉴를 검색할 때 사용한다.\n",
      "\n",
      "    Args:\n",
      "        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\n",
      "    Return:\n",
      "        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.\n",
      "<bound method BaseModel.schema of <class 'langchain_core.tools.structured.StructuredTool'>>\n"
     ]
    }
   ],
   "source": [
    "print(search_menu.name)\n",
    "print(search_menu.description)\n",
    "print(search_menu.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_model = ChatOpenAI(model=\"gpt-5-mini\").bind_tools(tools=[search_menu])\n",
    "res = tool_model.invoke(\"식당 메뉴 중 면요리를 추천해줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'search_menu',\n",
       "  'args': {'query': '면요리'},\n",
       "  'id': 'call_3icxEAYHczcNopeViNioXr24',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Agent를 구현\n",
    "# 레스토랑 메뉴 추천, 설명 agent\n",
    "# \n",
    "# tool : tavily_search, search_wiki, search_menu => (검색 툴들.)\n",
    "#########################################################################\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "tavily_search = TavilySearch(max_results=5)\n",
    "tools = [search_wiki, search_menu, tavily_search]\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI 어시스턴트입니다. \n",
    "주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\n",
    "\n",
    "주요 지침들(guidelines):\n",
    "1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\n",
    "2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\n",
    "3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\n",
    "4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\n",
    "5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\n",
    "6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\n",
    "7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\n",
    "8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\n",
    "\n",
    "- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\n",
    "- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\n",
    "- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{query}\"),\n",
    "        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\n",
    "    ]\n",
    ")\n",
    "tool_model = ChatOpenAI(model=\"gpt-5.2\").bind_tools(tools=tools)\n",
    "tool_model_chain = prompt | tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The first argument must be a string or a callable with a __name__ for tool decorator. Got <class 'langchain_core.prompt_values.ChatPromptValue'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res = \u001b[43mtool_model_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m파스타 메뉴를 추천해주고 파스타 유래나 역사를 알려줘.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3143\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3141\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3142\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3143\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3144\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3145\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4871\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4856\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this `Runnable` synchronously.\u001b[39;00m\n\u001b[32m   4857\u001b[39m \n\u001b[32m   4858\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4868\u001b[39m \n\u001b[32m   4869\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4870\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4872\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4873\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4875\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4876\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4877\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4878\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2058\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2054\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   2055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2056\u001b[39m         output = cast(\n\u001b[32m   2057\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2058\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2059\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2060\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2061\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2062\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2066\u001b[39m         )\n\u001b[32m   2067\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2068\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:433\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    432\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4728\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input_, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4726\u001b[39m                 output = chunk\n\u001b[32m   4727\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4728\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4729\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4730\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4731\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:433\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    432\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\tools\\convert.py:372\u001b[39m, in \u001b[36mtool\u001b[39m\u001b[34m(name_or_callable, runnable, description, return_direct, args_schema, infer_schema, response_format, parse_docstring, error_on_invalid_docstring, extras, *args)\u001b[39m\n\u001b[32m    367\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _create_tool_factory(name_or_callable)\n\u001b[32m    368\u001b[39m     msg = (\n\u001b[32m    369\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe first argument must be a string or a callable with a __name__ \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    370\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfor tool decorator. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(name_or_callable)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    371\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# Tool is used as a decorator with parameters specified\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# @tool(parse_docstring=True)\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;66;03m# def my_tool():\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;66;03m#    pass\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_partial\u001b[39m(func: Callable | Runnable) -> BaseTool:\n",
      "\u001b[31mValueError\u001b[39m: The first argument must be a string or a callable with a __name__ for tool decorator. Got <class 'langchain_core.prompt_values.ChatPromptValue'>"
     ]
    }
   ],
   "source": [
    "res = tool_model_chain.invoke({\"query\":\"파스타 메뉴를 추천해주고 파스타 유래나 역사를 알려줘.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create_agent() 를 이용한 Agent 구현\n",
    "\n",
    "- create_agent()\n",
    "  - Agent 생성 및 실행을 표준화, 단순화 하기 위헤 Langchain 1.0에서 도입된 함수\n",
    "  - 0.x 버전까지는 Agent 생성 함수는 \n",
    "    1. model과 tool들을 넣어 Agent를 생성하고 \n",
    "    2. 그것을 실행하는 Executor를 생성하는 방식으로\n",
    "  - 여러 단계를 거쳐야 했다.\n",
    "  - create_agent()는 이러한 단계를 1단계로 축약한 API이다.\n",
    "\n",
    "- create_agent 설계 철학\n",
    "    1. Agent를 구성하는 모든 실행단위는 Runnable 이다.\n",
    "    2. Agent도 Runnable 이다.\n",
    "    3. Agent는 하나의 표준 팩토리 함수(생성함수)로 통합한다.\n",
    "\n",
    "## 주요 파라미터\n",
    "- https://reference.langchain.com/python/langchain/agents/\n",
    "- `model`: LLM 모델. Agent의 두뇌 역할을 하며 추론(Reasoning), 도구 선택, 최종 응답을 담당한다.\n",
    "- `tools`: Agent가 사용할 외부 도구모음. \n",
    "- `system_prompt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=ChatOpenAI(model=\"gpt-5-mini\"),\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt # system prompt에 추가될 내용.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent 호출\n",
    "res = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"human\", \"파스타 메뉴를 추천해줘. 그리고 파스타의 유래에 대해 설명해줘.\")\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='파스타 메뉴를 추천해줘. 그리고 파스타의 유래에 대해 설명해줘.', additional_kwargs={}, response_metadata={}, id='a05da80f-7c9f-4e16-a2e1-0df49b3da2fd'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 544, 'prompt_tokens': 1837, 'total_tokens': 2381, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Csk5VvzBqSqt6jr3W8B6iIWijfmwW', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b731e-096b-7422-abe4-4ac9de063b9d-0', tool_calls=[{'name': 'search_wiki', 'args': {'query': 'history of pasta origin', 'max_results': 3}, 'id': 'call_lh8gwAqymW5hHGWDsqePsJdX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1837, 'output_tokens': 544, 'total_tokens': 2381, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 512}}),\n",
       " ToolMessage(content='{\"result\": [{\"content\": \"헴프(hemp) 또는 산업용 헴프는 산업용 및 소비용으로 특별히 재배되는 칸나비스 사티바 재배품종 식물이다. 이 식물은 다양한 제품을 만드는 데 사용될 수 있다. 대나무와 함께 헴프는 지구상에서 가장 빠르게 자라는 식물 중 하나이다. 또한 50,000년 전 처음으로 사용 가능한 섬유로 방적된 식물 중 하나였다. 이는 종이, 밧줄, 직물, 옷, 생분해성 플라스틱, 도료, 단열재, 바이오 연료, 음식, 동물 사료를 포함한 다양한 상업 품목으로 정제될 수 있다.\\\\n화학형 I 대마와 헴프(유형 II, III, IV, V)는 모두 칸나비스 사티바이며 정신활성 성분인 테트라하이드로칸나비놀(THC)을 함유하고 있지만, 일반적으로 독특한 파이토케미컬 성분과 용도를 가진 별개의 재배품종 그룹을 나타낸다. 헴프는 일반적으로 총 THC 농도가 낮고, 칸나비디올(CBD) 농도가 높을 수 있으며, 이는 THC의 신경정신약물 효과를 잠재적으로 완화한다. 헴프의 합법성은 국가마다 크게 다르다. 일부 정부는 THC 농도를 규제하고 특히 낮은 THC 함량으로 재배된 헴프만 상업 생산을 허용한다.\\\\n\\\\n\\\\n== 어원 ==\\\\n\\\\n어원은 불확실하지만, 이 단어의 다양한 형태에 대한 공통적인 인도유럽조어 원천은 없는 것으로 보인다. 그리스어 용어 κάνναβις (kánnabis)는 가장 오래된 문증된 형태이며, 이전 스키타이어 또는 트라키아어에서 차용되었을 수 있다. 그 후 라틴어로, 그리고 별도로 슬라브족 언어로, 거기서부터 발트 3국 언어, 핀란드어, 게르만어로 차용된 것으로 보인다.\\\\n게르만어군에서는 그림의 법칙에 따라 첫 번째 게르만어 음운 변화에서 \\\\\"k\\\\\"가 \\\\\"h\\\\\"로 바뀌어 게르만조어 *hanapiz가 되었고, 그 후 고대 영어 형태인 hænep, henep으로 각색되었을 수 있다. 그러나 바버 (1991)는 \\\\\"칸나비스\\\\\"라는 이름의 확산이 이란 주변 남쪽에서 시작된 식물 사용의 더 최근 역사적 배경 때문이라고 주장했는데, 이는 비-THC 헴프 품종이 더 오래되고 선사시대부터 존재했기 때문이다. 또 다른 가능한 기원으로는 아시리아어 qunnabu가 있으며, 이는 기원전 1천년에 기름, 섬유, 약품의 원료를 지칭하는 이름이었다.\\\\n다른 게르만어군 언어에서 헴프의 동계어로는 네덜란드어 hennep, 덴마크어 및 노르웨이어 hamp, 사터랜드 프리슬란드어 Hoamp, 독일어 Hanf, 아이슬란드어 hampur, 스웨덴어 hampa가 있다. 이 언어들에서 \\\\\"hemp\\\\\"는 산업용 섬유 헴프 또는 마약성 대마초 품종을 지칭할 수 있다.\\\\n\\\\n\\\\n== 용도 ==\\\\n\\\\n헴프는 광범위한 상업 및 산업 제품을 만드는 데 사용된다. 헴프 씨앗은 직접 식용으로 섭취되며, 요리용, 영양 보충제, 화장품, 페인트 및 광택제의 건조유로 사용되는 기름으로도 압착된다. 기름 추출의 부산물인 헴프 씨앗박은 유리한 단백질 및 지방산 프로필로 인해 가금류, 돼지, 소, 어류 및 반려동물 사료용으로 점차 평가되고 있다.\\\\n인피 섬유는 직물 및 혼방 직물, 가구, 특수지에 적용된다. 또한 헴프크리트, 섬유 강화 단열 패널, 가구 및 자동차 부품용 바이오 복합 재료와 같은 건축 자재용 복합 재료로 가공된다. 헴프 섬유는 기타, 앰프를 포함한 악기 및 종이용 펄프와 생분해성 포장재와 같은 특수 제품에도 사용된다.\\\\n내부 목질 핵(허드 또는 쉬브)은 동물 침대, 정원 멀치, 깔짚, 경량 건축 블록 및 파티클 보드의 구성 요소로 사용된다. 헴프 오일 및 추출물은 칸나비디올(CBD)과 같은 비중독성 칸나비노이드 제품, 식이 보충제, 화장품 및 웰니스 제형에도 사용된다.\\\\n\\\\n\\\\n=== 음식 ===\\\\n\\\\n헴프 씨앗은 생으로 먹거나, 헴프 가루로 갈거나, 발아시키거나, 건조 발아 가루로 만들 수 있다. 헴프 씨앗은 또한 베이킹이나 삼씨밀크와 허브차와 같은 음료에 사용되는 슬러리로 만들 수 있다. 삼씨기름은 씨앗에서 압착 추출되며 불포화 지방산 함량이 높다.\\\\n영국에서는 환경식품농림부가 헴프를 순전히 비식품 작물로 취급하지만, 적절한 허가와 0.3% 미만의 THC 농도 증명서가 있으면 헴프 씨앗을 파종하거나 식품 또는 식품 성분으로 판매할 수 있다. 미국에서는 헴프를 식품 제품에 합법적으로 사용할 수 있으며, 2000년 기준, 일반적으로 건강 식품점이나 통신판매를 통해 판매되었다.\\\\n\\\\n\\\\n==== 영양 ====\\\\n\\\\n껍질을 벗긴 헴프 씨앗 100-그램 (3+1⁄2-온스) 분량은 2,451 킬로줄 (586 킬로칼로리)의 음식 에너지를 공급한다. 이들은 수분 5%, 탄수화물 5%, 총 지방 49%, 단백질 31%를 함유한다. 껍질을 벗긴 헴프 씨앗의 1회 제공량은 30g(테이블스푼 3개)에 해당한다.\\\\n헴프 씨앗에서 얻을 수 있는 단백질의 비율은 씨앗의 껍질을 벗기거나, 기름을 짜낸 후 남은 헴프 씨앗의 분획인 박(meal) 또는 케이크(cake)(헴프 씨앗 가루라고도 함)를 사용하여 단백질 함량을 늘릴 수 있다. 단백질은 대부분 씨앗의 내부 층에 위치하며, 껍질은 주로 섬유를 포함하므로 단백질이 적다.\\\\n헴프 씨앗은 100g당 단백질 일일 권장량의 64%를 제공하는 것으로 유명하다. 헴프 씨앗의 세 가지 주요 단백질은 에데스틴(총 단백질 함량의 83%), 알부민(13%), 그리고 β-코글리시닌(최대 5%)이다. 헴프 씨앗 단백질은 미처리(비가열) 상태에서 콩 단백질보다 소화율이 높다. 헴프 씨앗의 아미노산 프로필은 육류, 우유, 달걀, 콩과 같은 다른 단백질이 풍부한 식품의 프로필과 유사하다. 단백질 소화율 보정 아미노산 점수는 통 헴프 씨앗의 경우 0.49-0.53, 헴프 씨앗박의 경우 0.46-0.51, 껍질을 벗긴 헴프 씨앗의 경우 0.63-0.66이었다. 헴프 씨앗에서 가장 풍부한 아미노산은 글루탐산(통 씨앗의 3.74–4.58%)이며, 그 다음이 아르기닌(통 씨앗의 2.28–3.10%)이다. 통 헴프 씨앗은 퀴노아(13.0%), 치아 씨앗(18.2–19.7%), 메밀 씨앗(27.8%), 아마씨(20.9%)와 같은 다른 단백질이 풍부한 제품보다 단백질 함량이 높거나 유사한 풍부한 단백질 공급원으로 간주될 수 있다. 영양학적으로 헴프 씨앗의 단백질 분획은 콩 단백질과 같은 다른 식물성 단백질에 비해 소화율이 높다. 헴프 씨앗 단백질은 필수 아미노산의 좋은 프로필을 가지고 있지만, 이 아미노산 프로필은 콩이나 카제인보다 열등하다.\\\\n헴프 씨앗은 식이 섬유 (DV의 20%), 비타민 B 복합체, 그리고 망가니즈 (DV의 362%), 인 (DV의 236%), 마그네슘 (DV의 197%), 아연 (DV의 104%), 철분 (DV의 61%)과 같은 무기질의 풍부한 공급원이다. 헴프 씨앗 에너지의 약 73%는 지방과 필수 지방산 형태이며, 주로 불포화 지방산, 리놀레산, 올레산, 알파리놀렌산이다. 100g당 38.100g의 불포화 지방 중 오메가-3는 9.301g, 오메가-6는 28.698g이다. 일반적으로 성인용 포장재에 권장되는 1회 제공량은 약 3테이블스푼인 30g이다.\\\\n헴프는 글루텐 함량이 4.78ppm으로 낮아 글루텐 프리(<20ppm) 식품 재료로 주목받고 있다.\\\\n헴프 씨앗의 풍부한 영양 성분에도 불구하고, 씨앗에는 피트산, 트립신 억제제, 탄닌과 같은 영양 저해 물질이 통계적으로 유의미한 농도로 포함되어 있다.\\\\n\\\\n\\\\n==== 저장 ====\\\\n삼씨기름은 적절하게 보관하지 않으면 단기간 내에 산화되어 산패된다. 어둡고 밀폐된 용기에 넣어 냉장 보관하면 유통 기한이 연장된다. 빛과 열 모두 헴프 오일을 변질시킬 수 있다.\\\\n\\\\n\\\\n=== 섬유 ===\\\\n헴프 섬유는 역사적으로 광범위하게 사용되었으며, 신세계에 도입된 직후 생산량이 최고조에 달했다. 수세기 동안 밧줄에서 직물, 산업용 재료에 이르기까지 다양한 품목이 헴프 섬유로 만들어졌다. 헴프는 또한 돛 캔버스를 만드는 데 흔히 사용되었다. \\\\\"캔버스\\\\\"라는 단어는 칸나비스(cannabis)에서 유래했다. 순수한 헴프는 아마포와 비슷한 질감을 가진다. 다양한 제품에 활용할 수 있는 다용도성 덕분에 오늘날 헴프는 의류, 신발, 액세서리, 개 목줄, 가정용품 등 여러 소비재에 사용된다. 의류의 경우 헴프가 라이오셀과 혼합되는 경우도 있다. 지속 가능성 측면의 이점 또한 의류 산업과 같은 산업에서 헴프의 매력을 높인다.\\\\n\\\\n\\\\n=\", \"title\": \"헴프\", \"url\": \"https://ko.wikipedia.org/wiki/%ED%97%B4%ED%94%84\"}]}', name='search_wiki', id='a2c6e97b-38a9-4b22-87df-0703dddbec60', tool_call_id='call_lh8gwAqymW5hHGWDsqePsJdX'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 4595, 'total_tokens': 4683, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Csk5gRXMKAhjlP047jOMJuNLe16PT', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b731e-3411-7f71-b415-420ba2929272-0', tool_calls=[{'name': 'search_menu', 'args': {'query': '파스타'}, 'id': 'call_KDEsJJZLWh5vN8fGNGQW5D0l', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4595, 'output_tokens': 88, 'total_tokens': 4683, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}),\n",
       " ToolMessage(content='{\"result\": [{\"content\": \"10. 토마토 브루스케타\\\\n    - 가격: 12,000원\\\\n    - 주요 재료: 토마토, 바질, 올리브 오일, 바게트\\\\n    - 메뉴 설명: 바삭하게 구운 바게트 위에 신선한 토마토와 바질을 얹고 올리브 오일로 마무리한 간단한 요리입니다. 입맛을 돋우는 상큼한 맛이 특징입니다. 가벼운 전채로 적합합니다.\", \"title\": \"토마토 브루스케타\", \"url\": \"data/restaurant_menu.txt\"}, {\"content\": \"8. 프로방스 치킨\\\\n   - 가격: 22,000원\\\\n   - 주요 재료: 닭고기, 타임, 로즈마리, 올리브, 토마토\\\\n   - 메뉴 설명: 프랑스 프로방스 지방의 허브와 토마토 소스로 조리한 닭고기 요리입니다. 부드럽고 촉촉한 닭고기와 향긋한 허브가 입맛을 돋웁니다. 라이스나 바게트와 함께 즐기기 좋습니다.\", \"title\": \"프로방스 치킨\", \"url\": \"data/restaurant_menu.txt\"}, {\"content\": \"4. 니스 샐러드\\\\n   - 가격: 18,000원\\\\n   - 주요 재료: 참치, 방울토마토, 올리브, 삶은 달걀, 그린빈\\\\n   - 메뉴 설명: 프랑스 니스 지방의 상큼한 샐러드로, 다양한 채소와 참치를 사용해 풍성한 맛과 식감을 제공합니다. 발사믹 비네거 드레싱이 가미되어 가볍게 즐기기 좋은 요리입니다. 신선함과 영양을 동시에 잡은 메뉴입니다.\", \"title\": \"니스 샐러드\", \"url\": \"data/restaurant_menu.txt\"}]}', name='search_menu', id='3ef102d6-cc03-496b-a7d7-a90e70d0dcbc', tool_call_id='call_KDEsJJZLWh5vN8fGNGQW5D0l'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 357, 'prompt_tokens': 5063, 'total_tokens': 5420, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4480}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Csk5kdUx3vJ1AtFIhJpNjW2sYqgNe', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b731e-47b9-7152-bc59-70c44151069f-0', tool_calls=[{'name': 'search_wiki', 'args': {'query': 'pasta history origin Italy Marco Polo Arab influence', 'max_results': 5}, 'id': 'call_aZM5UAP15nnmRdhAssjaPwN3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5063, 'output_tokens': 357, 'total_tokens': 5420, 'input_token_details': {'audio': 0, 'cache_read': 4480}, 'output_token_details': {'audio': 0, 'reasoning': 320}}),\n",
       " ToolMessage(content='{\"result\": \"검색 결과가 없습니다.\"}', name='search_wiki', id='53b0f7f2-4aea-4e20-ac2a-013ca46f4401', tool_call_id='call_aZM5UAP15nnmRdhAssjaPwN3'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 287, 'prompt_tokens': 5116, 'total_tokens': 5403, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4736}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Csk5rkPnsivB5u94A0vMIYA8qrAfR', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b731e-5e34-7453-a35c-613f040228ac-0', tool_calls=[{'name': 'search_wiki', 'args': {'query': 'history of pasta', 'max_results': 5}, 'id': 'call_upXteCXFsdVyosBCxyXwKoN9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5116, 'output_tokens': 287, 'total_tokens': 5403, 'input_token_details': {'audio': 0, 'cache_read': 4736}, 'output_token_details': {'audio': 0, 'reasoning': 256}}),\n",
       " ToolMessage(content='{\"result\": [{\"content\": \"파스타(이탈리아어: pasta)는 이탈리아의 밀 식품이다. 듀럼밀 세몰라에 물을 섞거나 밀가루에 달걀을 섞어 부풀리지 않고 반대기를 지어서 국수 등의 형태로 만든 음식이며, 삶거나 구워 먹는다. 이탈리아의 주식이며, 국민 음식 가운데 하나로 여겨진다.\\\\n\\\\n\\\\n== 이름 ==\\\\n이탈리아어 \\\\\"파스타(pasta)\\\\\"는 \\\\\"반죽, 페이스트\\\\\"를 뜻하는 명사이다.\\\\n\\\\n\\\\n== 역사 ==\\\\n\\\\n2세기경 그리스의 의사 갈레노스의 저서에는 밀가루와 물을 함께 혼합해서 만든 itrion이라는 말이 언급되어 있다. 예루살렘 탈무드에 기록된 itrium은 삶은 반죽 종류로, 팔레스타인에서 3세기부터 5세기까지 먹었으며, 9세기의 시리아의 의사이자 사서학자인 Isho bar Ali가 편찬한 사전에는 아라비아 어원을 가지고 있으며, 세몰리나로 만들어 말려서 요리하는 끈같은 모양의 itriyya에 대해서 설명하고 있다. 무함마드 알 이드리시의 지리학 저서에는 1154년 시칠리아 로저 2세 시대의 자료를 편찬하면서 노르만 시칠리아에서 생산하고 수출하는 이트리야 (itriyya)에 대해 언급하고 있다.\\\\n\\\\n말단의 서부에는 Trabia라고 불리는 즐거운 곳이 있다. 이곳의 영원히 흐르는 강은 많은 밀을 흘러갈 수 있게 한다. 이 지방의 거대한 건물에서는 사람들이 칼라브리아, 무슬림과 기독교 국가에 보낼 막대한 양의 이트리야를 만든다. 매우 많은 양이 배로 수송된다.\\\\n이트리야는 이탈리아에서 trie로 알려졌는데 이 말은 tagliatelli와 같이 길다란 끈을 의미하는 말이었다. 이트리야의 형태 중 하나로 오랜 역사를 지닌 laganum (복수형 lagana)은 라틴어로 얇은 면 반죽을 뜻하며, 이탈리아에서는 \\\\\"라사냐\\\\\"로 알려졌다.\\\\n기원전 1세기 호라티우스의 저서에는 lagana를 기름으로 튀긴 얇은 반죽이며, 일상식이었다고 쓰고 있다. 2세기 때 나우크라티스의 아테나이오스의 저서에는 1세기 때 쓰여진 티아나의 크리시포스의 lagana 요리법이 나와있다. 이 요리법에서는 으깬 상추액과 밀가루로 만든 얇은 면 반죽에 양념을 한 후 기름에 바싹 튀기는 방법을 쓰고 있다. 5세기 초에 쓰여진 요리책에는 고기가 들어간 얇은 층으로 된 면 반죽이 들어가는 요리 lagana에 대해서 설명하고 있는데, 오늘날의 음식인 라사냐의 원형이라고 볼 수 있다. 그러나 이 반죽을 요리하는 과정은 지금의 드라이 파스타나 프레시 파스타와는 많이 다르다. 이탈리아 시대에서 파스타에 대한 구체적인 자료가 등장한 때는 13~14세기이다.\\\\n한편, 중국에서도 기원전 2000년부터 잡곡으로 만든 국수를 먹어왔지만, 듀럼밀은 후세까지 알려지지 않았다. 마르코 폴로가 중국에서 파스타를 들여왔다는 가설은 미국의 잡지 〈마카로니 저널〉에서 나왔다. 이 잡지는 미국의 파스타 판매를 촉진하기 위해 식품 회사 협회가 출간한 것이었다. 마르코 폴로가 동방견문록에서 \\\\\"라가나\\\\\" (lagana)와 유사한 음식에 대해서 묘사하고 있지만, 이것은 그가 잘 알고 있던 단어를 사용한 것일뿐이다. 국제 마카로니 제조업자 협회에 따르면 오늘날의 듀럼밀로 만들어진 파스타는 아랍인이 시칠리아를 지배하였을 때 들어온 것이다.\\\\n파스타는 그리스 신화에서 헤파이스토스가 파스타 제조 기구를 발명했다는 설과 기원전 5세기경에 이탈리아 중서부의 고대국가인 에트루리아족이 만들어 먹었다는 설 등 그 기원에 대해 아직까지 여러 가지 이설이 있다.\\\\n\\\\n\\\\n== 종류 ==\\\\n\\\\n\\\\n=== 재료와 제조 방식 ===\\\\n\\\\n\\\\n==== 건파스타 ====\\\\n\\\\n건파스타(乾pasta, 이탈리아어: pasta secca 파스타 세카[*]) 단순한 튜브 형태에서부터 나비넥타이 모양에 이르기까지 약 350종이 존재한다. 덥고 건조한 날씨에도 오랫동안 보관할 수 있어서 주로 이탈리아 남부에서 사용한다. 건파스타는 \\\\\"듀럼밀\\\\\"로도 불리는 경질밀(grano duro) 세몰라와 물을 사용하여 만든다. 듀럼밀을 갈아 만든 거칠고 날카로운 입자 형태의 황갈색 세몰라는 파스타를 만드는데 적합하다. 이는 듀럼밀이 글루텐을 많이 함유하고 있어 녹말 입자가 쉽게 파괴되기 어렵고 수분 흡수를 조절하며, 지나치게 부풀어 오르지 않아 파스타의 형태를 단단하게 유지하기 때문이다 대부분의 건파스타는 압출성형 공법을 통해 상업적으로 생산되지만, 집에서도 만들 수 있다. 재료는 같은 재료를 사용하여 만들어도 이탈리아의 건파스타는 일반적으로 다른 곳의 건파스타보다 훨씬 우수한데 그 이유는 특유의 압출과 건조 방식에 있다. 건파스타는 모양이 복잡할수록 소스를 잘 붙잡아두는데, 봉긋하게 솟아 있거나 움푹 팬 모양은 파스타를 구리 틀에서 짜내는 압출과정에서 만들어진다. 구리 틀은 값도 비싸고 금방 못 쓰게 되는 단점이 있지만, 이탈리아에서는 최고의 건파스타를 만들기 위해 구리 틀을 일반적으로 사용한다. 반면 철로 만든 틀을 사용하는 다른 나라들의 파스타는 면이 너무 매끈해 소스와 잘 어우러지지 못하는 경우가 많다. 건파스타를 만들 때는 온도와 시간도 매우 중요한데, 대량 생산되는 파스타는 짧은 시간에 너무 높은 온도에서 건조하기 때문에 이탈리아의 전통 파스타보다 질이 떨어진다.\\\\n\\\\n\\\\n==== 생파스타 ====\\\\n\\\\n생파스타(生pasta, 이탈리아어: pasta fresca 파스타 프레스카[*])의 경우 전통적으로 수작업을 통해 만들어지며, 때때로 간단한 기계(파스타기)의 도움을 받기도 한다. 식료품 가게에서 구입하는 생파스타는 기계에 의해 상업적으로 생산된다. 연질밀(grano tenero) 가루와 달걀에 물이나 올리브 오일을 더해 만드는 생파스타는 토양이 비옥하고 달걀이 풍부한 이탈리아 북부 지방에서 주로 사용된다. 달걀이 들어간 파스타를 \\\\\"달걀 파스타(pasta all\\'uovo)\\\\\"라 부르기도 한다. 생파스타를 만드는 반죽의 반대기는 \\\\\"스폴리아\\\\\"라 불린다. 건파스타가 주를 이루는 남부 지방에서는 특별한 날에 라비올리나 칸넬로니처럼 소를 넣은 생파스타를 만들어 먹는다. 일반적으로 그날 만든 생파스타 요리를 대접하는 것은 손님에 대한 정성과 그 집의 뛰어난 요리 솜씨를 보여주는 것이라 여겨진다. 그러나 생파스타가 건파스타보다 본질적으로 더 우수한 것은 아니다. 단지 어디에 쓰이냐에 따라 면이 달라질 뿐이다. 즉 어떤 파스타는 생파스타로만, 어떤 파스타는 건파스타로만 만들고 둘 다 가능한 것도 있다. 생파스타는 에밀리아로마냐 지방의 것을 최고로 친다. 이곳의 생파스타는 보통 크림 소스나 버터와 샐비어로 만든 간단한 소스와 함께 먹고, 여름철에는 가벼운 토마토 소스에 먹기도 한다.\\\\n\\\\n\\\\n=== 모양 ===\\\\n건파스타와  생파스타 모두 다양한 모양과 변형을 가지고 있다. 파스타의 구체적인 형태는 310개로, 기록된 파스타의 이름은 1,300개가 넘는다. 이탈리아에서 일부 파스타의 모양이나 종류는 지역에 따라 다양하다. 예를 들어 파스타 모양인 카바텔리는 마을과 지역에 따라 부르는 이름이 달라 총 28개의 이름을 가지고 있는 것으로 유명하다. 파스타의 일반적인 모양은 긴 형태, 짧은 형태, 튜브, 납작한 형태, 시트, 수프를 위한 미니어처 형태, 속을 채우는 형태, 지역 특산품, 또는 장식품 등이 포함된다.\\\\n\\\\n\\\\n==== 긴 파스타 ====\\\\n\\\\n\\\\n==== 둥지 모양 파스타 ====\\\\n\\\\n\\\\n==== 구멍 뚫린 파스타 ====\\\\n\\\\n\\\\n==== 짧은 파스타 ====\\\\n\\\\n\\\\n==== 수프용 파스타 ====\\\\n\\\\n\\\\n==== 소를 넣은 파스타 ====\\\\n\\\\n\\\\n== 요리 ==\\\\n이탈리아 요리에서 파스타는 물에 삶은 다음 소스를 곁들여 내는 파스타 아시우타(이탈리아어: pasta asciutta), 수프 그릇에 국물과 함께 담아 내는 파스타 인 브로도(이탈리아어: pasta in brodo), 오븐에 구워 조리하는 파스타 알 포르노(이탈리아어: pasta al forno) 등의 방식으로 조리한다. 파스타 샐러드를 먹기도 한다.\\\\n건파스타는 소스를 얹었을 때 소스가 면에 묻혀 있으며, 견고하고 거친 구조이기 때문에 올리브 오일을 베이스로 한 가벼운 토마토 소스, 야채소스, 해산물 소스와 어울린다. 생파스타는 소스를 흡수한다. 버터나 진한 우유, 크림을 베이스로 한 해산물, 육류, 야채 소스와 어울린다. 가늘고 긴 파스타에는 가벼운 소스가, 두껍거나 넓적한 파스타에는 육류 등을 사용한 무거운 소\", \"title\": \"파스타\", \"url\": \"https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%8A%A4%ED%83%80\"}, {\"content\": \"아마트리차나(이탈리아어: amatriciana)는 토마토, 구안찰레 (소금에 절인 돼지 볼살), 페코리노 치즈, 후추, 엑스트라 버진 올리브, 드라이 백포도주, 소금으로 만든 파스타 소스이다. 아마트리체라는 코무네(라치오주의 리에티도 지역의 산악 도시)에서 비롯한 이 소스는 오늘날 로마 음식과 이탈리아 음식에서 가장 잘 알려진 파스타 소스 중 하나이다. 이탈리아 정부는 아마트리차나를 라치오 지역 PAT로 등록했고, 전통 아마트리차나 소스는 유럽연합과 영국에 TSG(Traditional speciality guaranteed)로 등재시켰다.\\\\n\\\\n\\\\n== 발전 ==\\\\n아마트리차나는 \\'파스타 알라 그리치아\\'라는 요리에서 비롯했다. \\'그리치아\\'라는 단어의 기원은 밝혀지지 않았다. 교황령 시절 로마에서, \\'그리치\\'(grici)는 흔히 먹을 수 있는 음식을 파는 상인들을 나타내는 말이었으며, 이 이름은 이 상인들이 구스위스 연방의 소속 국가 (칸톤)인 그리조니의 영토이던 발텔리나 지역 출신이 다수였기 때문이었다. 또 다른 이론에 의하면, 아마트리체 인근 아쿠몰리의 \\'그리시아노\\'라는 프라치오네에서 이름 붙여졌다고 한다. 오늘날 \\'아마트리차나 비앙카\\'(amatriciana bianca)라고도 불린 이 소스는 여전히 관찰레 (절인 돼지 볼살)와 간 페코리노 치즈랑 같이 내어진다. 이따금, 약간의 올리브유가 레시피에 더해진다. 1960년대에, 아마트리차나 소스는 아마트리체에서 이런 방식으로 내어졌다.\\\\n첫 토마토 소스의 개발 (그리고 \\'그리치아\\'에 토마토를 접목시켜, 아마트리차나를 만들어낸 것으로 추정되는 최초 시기)은 18세기 말로 거슬러 올라간다. 토마토는 스페인을 거친 콜럼버스의 교환을 통해 유럽에 도입되었다. 토마토 소스가 들어간 파스타에 대한 최초의 기록물은 프란체스코 레오나르디가 쓴 1790년 요리책 \\'L\\'Apicio Moderno\\'에서 찾아 볼 수 있다.\\\\n아마트리차나 레시피는 로마와 아마트리체 사이의 수세기간 이어진 오랜 관계성으로 인해 19세기와 20세기 동안에 로마에서 점차 인기가 있게 되었다. 이 레시피는 다른 지역에서 유래했지만, 로마 요리의 고전으로 빠르게 자리 잡으며 좋은 반응을 얻었다. 로마냐 방언으로 이 음식의 이름은 그 지역 방언의 어두음 소실 특성에 따라 \\'마트리차나\\'가 되었다.\\\\n토마토가 덜 들어간 \\'그리치아\\'는 여전히 이탈리아 중부에서 내어지는 가운데, 토마토가 듬뿍 들어간 아마트리차나가 이탈리아 전역과 다른 곳에서 더 유명하다. 아마트리체에서 아마트리차나는 스파게티와 같이 나오지만, 부카티니가 로마에서는 더 흔하게 사용된다. 다른 종류의 건 파스타 (특히 리가토니) 역시도 사용된다.\\\\n\\\\n\\\\n== 변형 ==\\\\n아마트리차나는 구할 수 있는 재료에 따라 여러 가지 변형 형태가 존재한다. 아마트리체에서, 관찰레, 토마토를 쓰는 것이 전형적이고 양파는 선호되지 않으며, 그럼에도 로마 요리에 대한 고전책에서는 양파가 등장한다. 전 아마트리체 시장인 세르조 피로치(Sergio Pirozzi)는 \\\\\"아마트리차나에는 결코 마늘이란 있을 수 없다. 누가 그러더라도 양파도 마찬가지다.\\\\\"라고 까지 발언했다. 유명 쉐프 카를로 크라코는 껍질을 벗기지 않은 마늘 한쪽을 다른 재료들과 볶아낸 다음 서빙 전에 이를 제거하는데, 이것에 대해 자신만의 \\'비밀 재료\\'라고 하자, 아마트리체 지자체는 공식 홈페이지에 \\\\\"진정한 아마트리차나의 재료는 관찰레, 페코리노, 백포도주, 산 마르차노 토마토, 후추, 페퍼론치노뿐이다\\\\\"라고 응수하였다. 재료를 익히는 데, 올리브유가 가장 흔하게 쓰이나, \\'스트루토\\'(strutto, 라드) 역시도 잘 쓰인다. 치즈에는 \\'페코리노 로마노\\' 또는 아마트리체의 페코리노 (시빌리니 산맥이나 몬티 델라 라가 지역)를 쓸 수 있다.\\\\n\\\\n\\\\n== 사진 ==\\\\n\\\\n\\\\n== 각주 ==\\\\n\\\\n\\\\n== 참고 문헌 ==\\\\nZanini De Vita, Oretta; Fant, Maureen B. (2013). 《Sauces & Shapes: Pasta the Italian Way》. New York: W. W. Norton & Company. ISBN 978-0-393-08243-2. \\\\nBlasi, Benedetto (1923). 《Vie piazze e ville di Roma nel loro valore storico e topografico》 (이탈리아어). Roma: Libreria di scienze e lettere. \\\\nBoni, Ada (1983) [1930]. 《La Cucina Romana》 (이탈리아어). Roma: Newton Compton Editori. \\\\nGosetti Della Salda, Anna (1967). 《Le ricette regionali italiane》 (이탈리아어). Milano: Solares. \\\\nCarnacina, Luigi; Buonassisi, Vincenzo (1975). 《Roma in Cucina》 (이탈리아어). Milano: Giunti Martello. \\\\nFaccioli, Emilio (1987). 《L\\'Arte della cucina in Italia》 (이탈리아어). Milano: Einaudi. \\\\nRavaro, Fernando (2005). 《Dizionario romanesco》 (이탈리아어). Roma: Newton Compton. ISBN 9788854117921. \\\\n\\\\n\\\\n== 외부 링크 ==\\\\n 위키미디어 공용에 아마트리차나 관련 미디어 분류가 있습니다.\", \"title\": \"아마트리차나\", \"url\": \"https://ko.wikipedia.org/wiki/%EC%95%84%EB%A7%88%ED%8A%B8%EB%A6%AC%EC%B0%A8%EB%82%98\"}, {\"content\": \"《날아다니는 스파게티 괴물의 복음서》(The Gospel of the Flying Spaghetti Monster)는 바비 헨더슨이 쓴 풍자서로, 날아다니는 스파게티 괴물교 또는 파스타파리아니즘의 주요 신념을 구체화한다. 날아다니는 스파게티 괴물(Flying Spaghetti Monster, FSM)은 헨더슨이 캔자스주 교육위원회에 보낸 공개 편지에서 지적 설계의 개념을 패러디하면서 만들어졌다. 그가 편지를 자신의 웹사이트에 올리자 이는 인터넷에서 화제가 되었고, 주류 언론과 출판사들의 관심을 끌었다.\\\\n책은 창조 신화, 8개의 \\\\\"웬만하면 하지 말았으면 하는 것들\\\\\"(I\\'d Really Rather You Didn\\'ts), 전도 지침을 포함하고, 파스타파리안의 관점에서 역사와 생활방식을 논한다. 풍자를 통해 FSM의 존재를 증명함으로써 지적 설계의 대안을 제시한다.\\\\n\\\\n\\\\n== 배경 ==\\\\n캔자스주 교육위원회는 공립학교에서 진화론과 함께 지적 설계를 가르칠 것인지 논의를 시작했다. 당시 24세였던 오리건 주립 대학교 물리학과 졸업생 바비 헨더슨은 2005년에 교육위원회에 보낸 공개 편지에서 FSM에 대한 믿음을 공언함으로써 지적 설계의 개념을 패러디했다.\\\\n\\\\n저는 전국의 과학 교실, 궁극적으로 전세계에서 다음 3가지 이론에 동일한 시간이 주어질 때를 기대합니다. 즉, 시간의 3분의 1은 지적 설계에, 3분의 1은 날아다니는 스파게티 괴물주의에, 3분의 1은 압도적인 관찰 가능한 증거에 기초한 논리적 추측에 써야 합니다.\\\\n\\\\n교육위원회로부터 답장이 없자 헨더슨은 편지를 자신의 웹사이트에 올렸다. 얼마 지나지 않아 파스타파리아니즘은 인터넷에서 화제가 되었고, 뉴스 미디어의 관심을 받았다. 빌라드는 책의 출판을 위해 헨더슨에게 선금 8만 달러를 지불했다.\\\\n\\\\n\\\\n== 요약 ==\\\\n책은 파스타파리아니즘의 교리를 제시하며 창조 신화, 전도 지침, FSM의 존재에 대한 유사과학적 증거, 여러 파스타 말장난을 포함한다. 변경된 스톡 사진과 조잡한 그림을 이용해 진화론의 문제점을 지적하고, 인류 역사 속 파스타파리아니즘의 증거를 제시하고, FSM이 우리가 삶을 어떻게 살기 바라는지 공개한다. 또한 해적의 수가 감소함에 따라 지구의 기온이 상승했다고 주장한다. 많은 사람들이 할로윈에 해적으로 변장하고, 10월 31일 다음은 이전보다 일반적으로 추운 것을 이 주장의 근거로 제시한다. 이는 상관관계가 인과관계를 의미하지 않는다는 것을 보여주기 위한 것이다.\\\\n책은 \\\\\"당신이 우리를 좋아하지 않는다면, 당신의 원래 종교가 당신을 다시 데려갈 것\\\\\"이라고 말하며 독자들에게 30일 동안 파스타파리아니즘을 시도할 것을 권유한다.\\\\n\\\\n\\\\n== 파스타파리안 창조 신화 ==\\\\n보이지 않고 감지할 수 없는 FSM은 우주를 창조했다. 첫째 날에는 어둠에서 빛을 분리했다. 비행에 지치고 물을 오랫동안 밟지 못해 둘째 날에는 맥주 화산이 있는 땅을 창조했다. 맥주를 맛본 후 셋째 날에는 숙취가 있는 채로 깨어났다. 전날에 땅을 만들었다는 것을 잊어버려서 다시 땅을 창조한 후 둘째 날의 땅을 천국으로 올렸다. 이후 난쟁이를 창조해 이를 인간이라고 불렀다.\\\\n책은 창조는 5천 년 전에 일어났으나, FSM이 우리를 속이기 위해 과학적 데이터를 바꿨다고 주장한다. 또한 파스타파리아니즘은 지적 설계처럼 결론을 먼저 내리고 이를 뒷받침할 증거를 모은다고 설명한다.\\\\n\\\\n\\\\n== 모지 선장과 8개의 웬만하면 하지 말았으면 하는 것들 ==\\\\n모지 선장은 FSM으로부터 조언을 담은 10개의 석판을 받았으나, 2개는 살사산에서 내려오는 길에 떨어졌다. 이 사건은 \\\\\"파스타파리안들의 어설픈 도덕 기준을 부분적으로 설명\\\\\"한다.\\\\n\\\\n\\\\n== 평가 ==\\\\n《오스틴 크로니클》의 웨인 브레너는 책이 \\\\\"과학과 미신 사이의 지나치게 심각한 싸움에 필요한 약간의 우스꽝스러운 휴식\\\\\"이라고 평했다. 《데일리 텔레그래프》의 사이먼 싱은 책이 약간 반복적이나, 전반적으로 \\\\\"훌륭하고 도발적이며 재치 있고 중요한 보석\\\\\"이라고 칭찬했다. 한편 디스커버리 연구소의 케이시 러스킨은 책이 신약성경을 조롱한다고 비판했다.\\\\n\\\\n\\\\n== 각주 ==\", \"title\": \"날아다니는 스파게티 괴물의 복음서\", \"url\": \"https://ko.wikipedia.org/wiki/%EB%82%A0%EC%95%84%EB%8B%A4%EB%8B%88%EB%8A%94_%EC%8A%A4%ED%8C%8C%EA%B2%8C%ED%8B%B0_%EA%B4%B4%EB%AC%BC%EC%9D%98_%EB%B3%B5%EC%9D%8C%EC%84%9C\"}, {\"content\": \"이스라엘-팔레스타인 분쟁은 옛 팔레스타인 위임통치령 영토 내의 영토와 자결권을 둘러싼 현재 진행 중인 군사적 및 정치적 분쟁이다. 분쟁의 주요 측면에는 이스라엘의 서안 지구 점령 및 가자 지구, 예루살렘의 지위, 이스라엘 정착촌, 국경, 안보, 수자원 권리, 서안 지구 및 가자 지구의 허가 제도, 팔레스타인인의 이동의 자유, 그리고 팔레스타인 난민의 귀환권이 포함된다.\\\\n이 분쟁은 19세기 말 유럽에서 시온주의가 부상하면서 시작되었는데, 이 운동은 팔레스타인 (지역)을 식민지화하여 유대 국가를 건설하는 것을 목표로 했으며, 1882년 첫 유대인 정착민들이 오스만 팔레스타인에 도착한 것과 동시에 일어났다. 시온주의 운동은 1917년 영국이 발행한 밸푸어 선언에서 제국주의 세력의 지지를 얻었으며, 이 선언은 팔레스타인에 \\\\\"유대인 고향\\\\\" 건설을 지지하겠다고 약속했다. 제1차 세계 대전 중 옛 오스만 제국 영토에 대한 영국의 점령 이후, 팔레스타인 위임통치령은 영국 위임통치령으로 설정되었다. 유대인 이민 증가로 인해 유대인과 아랍인 간의 긴장이 고조되었고, 이는 공동체 간 분쟁으로 번졌다. 1936년, 아랍 봉기가 독립과 시온주의에 대한 영국의 지원 중단을 요구하며 발생했으나 영국에 의해 진압되었다. 결국 긴장은 1947년 유엔이 팔레스타인 분할안을 채택하게 했고, 이는 내전을 촉발했다.\\\\n이어진 1948년 팔레스타인 전쟁 동안, 위임통치령의 주된 팔레스타인 아랍 인구의 절반 이상이 이스라엘군에 의해 도주하거나 추방되었다. 전쟁이 끝날 무렵, 이스라엘은 옛 위임통치령 영토의 대부분에 설립되었고, 가자 지구와 서안 지구는 각각 이집트와 요르단이 통제했다. 1967년 제3차 중동 전쟁 이후, 이스라엘은 팔레스타인 영토로 통칭되는 서안 지구와 가자 지구를 점령해왔다. 이스라엘과 그 점령에 대한 두 차례의 팔레스타인 봉기가 1987년과 2000년에 각각 제1차와 제2차 인티파다로 발발했다. 이스라엘의 점령은 이스라엘이 그곳에 불법 정착촌을 건설하게 했고, 그 점령 하의 팔레스타인인들에 대한 제도화된 차별 시스템인 이스라엘 아파르트헤이트를 만들었다. 이 차별에는 팔레스타인 난민들의 귀환권과 잃어버린 재산에 대한 권리를 이스라엘이 거부하는 것이 포함된다. 이스라엘은 또한 유엔의 비난을 받았으며, 팔레스타인인 인권 침해를 저질렀다.\\\\n미국과 이스라엘을 제외한 국제사회는 1980년대부터 두 국가 해법을 기반으로 한 1967년 국경을 따르고 팔레스타인 난민들을 위한 정의로운 해결책을 모색하여 분쟁을 해결하는 데 합의해 왔다. 미국과 이스라엘은 국제법을 기반으로 분쟁을 해결하기보다는 양자 협상을 선호했다. 최근 몇 년 동안 두 국가 해법에 대한 대중의 지지가 감소했으며, 이스라엘 정책은 분쟁의 영구적인 해결책을 모색하기보다는 점령을 유지하는 데 관심을 보였다. 2007년 이스라엘은 가자 지구 봉쇄를 강화하고 서안 지구로부터의 고립 정책을 공식화했다. 그 이후 이스라엘은 가자와의 관계를 전시국제법의 관점에서 규정했으며, 점령국으로서의 지위보다는 전쟁법의 관점에서 규정했다. 2024년 7월 국제사법재판소 (ICJ)는 이스라엘이 서안 지구와 가자 지구를 불법적으로 점령하고 있다고 판결했다. ICJ는 또한 이스라엘의 정책이 모든 형태의 인종차별 철폐에 관한 국제협약을 위반한다고 결정했다.\\\\n2006년 이후 하마스와 이스라엘은 여러 차례 전쟁을 벌였다. 2023년 10월 하마스 주도 무장 단체의 공격 이후 또 다른 전쟁이 이어져 가자 지구에 광범위한 파괴, 대규모 인구 이동, 인도주의적 위기 및 임박한 기근을 초래했다. 이스라엘의 가자 지구에서의 행동은 국제법 전문가, 집단살해 연구자 및 인권 단체에 의해 집단살해로 묘사되었다.\\\\n\\\\n\\\\n== 역사 ==\\\\n\\\\n이스라엘-팔레스타인 분쟁은 19세기 말에서 20세기 초에 걸쳐 정치적 시온주의의 발전과 시온주의 정착민들의 팔레스타인 도착과 함께 시작되었다. 20세기 초에는 오스만 제국 내에서 아랍 민족주의도 성장했다. 오스만 제국과의 전쟁에서 아랍 민족주의자들의 지지를 얻기 위해 영국은 후세인-맥마흔 서한에서 팔레스타인에 독립적인 아랍 국가 설립을 지지하겠다고 약속했다. 대영 제국은 1916~1918년 아랍 반란에 많은 양의 무기를 공급했다. 아랍 반란의 지원을 받아 대영 제국은 오스만 군대를 격파하고 팔레스타인, 요르단, 시리아를 통제하게 되었다. 나중에 영국과 프랑스 정부가 독립적인 아랍 국가 건설을 허용하지 않기 위해 1916년에 사이크스-피코 협정을 비밀리에 체결했다는 사실이 밝혀졌다. 1920년 7월, 아랍 반란 지도자 중 한 명인 파이살 1세가 왕으로 있었고 영국이 용인했던 단명한 시리아 아랍 왕국은 현대 포병으로 무장한 프랑스군에 의해 진압되었다.\\\\n유대인 식민지화는 이 시기에 시작되었지만, 제1차 세계 대전 이전 10년간 더 이데올로기적인 시온주의 이민자들이 도착하기까지는 오스만 팔레스타인의 지형이 크게 변하기 시작하지 않았다. 토지 매입, 소작농 아랍인 농민의 축출, 유대인 준군사 부대와의 무력 대결은 모두 팔레스타인 주민의 영토 이탈 및 재산 박탈에 대한 두려움을 키우는 데 기여했다. 시온주의 운동 지도부는 초기부터 유대인 인구 다수를 확보하기 위해 아랍 팔레스타인 인구를 이 땅에서 \\\\\"이전\\\\\"(민족 청소의 완곡어)시키려는 생각을 가지고 있었다. 이스라엘 역사가 베니 모리스에 따르면 이전이라는 생각은 \\\\\"필연적이고 시온주의에 내재되어 있었다.\\\\\" 아랍 인구는 1880년대 첫 번째 알리야가 도착했을 때부터 이러한 위협을 느꼈다. 하임 바이츠만이 시온주의 운동에 대한 영국의 지지를 구축하려는 노력은 결국 밸푸어 선언을 확보하게 되었는데, 이는 제1차 세계 대전 중 1917년 영국 정부가 팔레스타인에 \\\\\"유대인 민족을 위한 민족적 고향\\\\\" 건설을 지지하겠다고 발표한 공개 성명이었다.\\\\n\\\\n\\\\n=== 1920년대 ===\\\\n제1차 세계 대전 종전 후 영국 위임통치령 팔레스타인이 수립되면서 대규모 유대인 이민이 시작되었고, 외국 자본의 지원을 받는 별도의 유대인 통제 경제 부문이 발전했다. 제2차 알리야의 더 열렬한 시온주의 이데올로그들은 1920년대부터 이슈브의 지도자가 되었고 유대인과 아랍 사회의 분리를 믿었다.\\\\n영국 고등판무관 허버트 새뮤얼에 의해 예루살렘의 그랜드 무프티로 임명된 아민 알 후세이니는 즉시 유대 민족 운동과 팔레스타인으로의 유대인 이민을 자신의 대의에 대한 유일한 적수로 규정했고, 1920년 예루살렘과 1921년 야파에서 유대인에 대한 대규모 폭동을 선동했다. 이러한 폭력의 결과로 유대인 준군사 조직인 하가나가 설립되었다. 1929년, 일련의 폭력적인 폭동으로 인해 유대인 133명과 아랍인 116명이 사망했으며, 헤브론과 사페드에서 상당수의 유대인 사상자가 발생했고, 헤브론과 가자에서 유대인들이 대피했다.\\\\n\\\\n\\\\n=== 1936년–1939년 아랍 봉기 ===\\\\n\\\\n1930년대 초, 팔레스타인의 아랍 민족 투쟁은 이즈 앗딘 알카삼과 같은 중동 전역의 많은 아랍 민족주의 무장 세력들을 끌어들였고, 그는 검은 손 무장 단체를 설립하고 팔레스타인 아랍 봉기 (1936년~1939년)의 기반을 다졌다. 1935년 말 알카삼이 영국군에 의해 사망한 후, 긴장은 1936년 아랍 총파업과 총불매운동으로 폭발했다. 파업은 곧 폭력으로 변질되었고, 아랍 봉기는 유대인 정착촌 경찰, 유대인 보조 경찰, 특수 야간 부대로 구성된 영국군의 도움으로 영국군에 의해 유혈 진압되었다. 봉기 진압으로 인해 성인 남성 인구의 최소 10%가 사망, 부상, 투옥 또는 망명하게 되었다. 많은 아랍 지도부의 추방과 경제 약화로 인해 팔레스타인인들은 성장하는 시온주의 운동에 맞서 싸우는 데 어려움을 겪었다.\\\\n봉기와 지속적인 공동체 간 분쟁과 관련된 비용 및 위험으로 인해 이 지역의 영국 정책이 전환되었고, 필 위원회가 임명되어 작은 유대 국가 창설을 권고했으며, 주요 시온주의 지도자들인 하임 바이츠만과 다비드 벤구리온은 나중에 확장 가능성을 염두에 두고 이를 수용했다. 뒤이은 1939년 백서는 유대 국가를 거부하고 이 지역으로의 유대인 이민을 제한하려 했으며, 이는 영국 당국과 시온주의 운동 간 관계의 분기점이 되었다.\\\\n\\\\n\\\\n=== 1940년–1947년 ===\\\\n\\\\n제2차 세\", \"title\": \"이스라엘-팔레스타인 분쟁\", \"url\": \"https://ko.wikipedia.org/wiki/%EC%9D%B4%EC%8A%A4%EB%9D%BC%EC%97%98-%ED%8C%94%EB%A0%88%EC%8A%A4%ED%83%80%EC%9D%B8_%EB%B6%84%EC%9F%81\"}, {\"content\": \"다음은 윤상의 음반 목록이다.\\\\n\\\\n\\\\n== 정규 앨범 ==\\\\n《윤상 1집》(1990, 지구레코드)\\\\n이별의 그늘\\\\n잊혀진 것들\\\\n행복을 기다리며\\\\n무지개 너머\\\\n남겨진 이야기\\\\n알 수 없는 일\\\\n한 걸음 더\\\\n시간의 얼굴\\\\n《윤상 2 (PART 1)》(1992, 지구레코드)\\\\n그래도 안녕\\\\n가려진 시간 사이로\\\\n너에게\\\\n넌 쉽게 말했지만\\\\n마지막 내게\\\\n끝으로 향한 이야기\\\\n다시 얘기를 해줘\\\\n나의 꿈속에서\\\\n《윤상 2 (PART 2)》(1993, 지구레코드)\\\\n새벽\\\\n이별 없던 세상 (featuring 노영심)\\\\n少年\\\\n3月부터 3月까지\\\\nAlone\\\\nAmen\\\\n고백\\\\n후회\\\\nCommunication\\\\n어제의 기억으로\\\\n《CLICHÈ》(2000, DMR)\\\\nCD 1 - CLICHÈ\\\\n결국...흔해 빠진 사랑얘기\\\\n문득 친구에게 (duet with 노영심)\\\\n우연히 파리에서\\\\nBack to the Real Life\\\\n사랑이란\\\\n나를 친구라고 부르는 너에게\\\\n어쩌면 너를\\\\n바람에게\\\\nCity Life\\\\n내일은 내일\\\\nBack To The Real Life (Remix)\\\\nCD 2 - REMASTERING\\\\n배반\\\\n벽\\\\n달리기\\\\n자장가\\\\n반격\\\\n언제나 그랬듯이\\\\n마지막 거짓말\\\\n악몽\\\\n기념사진\\\\n《移徙 (이사)》(2002, SM 엔터테인먼트)\\\\nIntro\\\\n소리\\\\n이사 (移徙)\\\\nRepeat\\\\nA Fairy Tale\\\\n사랑하오 (duet with 김현철)\\\\nRunner\\'s High\\\\n재회 (duet with 청안)\\\\nEL Camino\\\\n소월에게 묻기를... (duet with 정훈희)\\\\nNi Volas Interparoli\\\\n《There Is A Man...》(2003, SM 엔터테인먼트)\\\\nCD 1\\\\nIntroduction to a Man\\\\n근심가 (featuring 신예원)\\\\nGood Old Love Song: Side A\\\\n우화\\\\n어떤 사람 A\\\\n예감\\\\n작은 세상\\\\n너희들 것이니까\\\\nGood Old Love Song: Side B\\\\nMan! What a Selfish Kid...\\\\n길은 계속된다\\\\nSueño, tu voz...\\\\n근심가 (fractal La Marcha Mix)\\\\n한 남자에 관한 우화\\\\nCD 2 - INSTRUMENTAL\\\\n근심가\\\\nGood Old Love Song: Side A\\\\n우화\\\\n어떤 사람 A\\\\n예감\\\\n작은 세상\\\\n너희들 것이니까\\\\nGood Old Love Song: Side B\\\\nMan! What a Selfish Kid...\\\\n길은 계속된다\\\\nSueño, tu voz...\\\\n《그땐 몰랐던 일들》(2009, KT뮤직)\\\\n떠나자\\\\n소심한 물고기들\\\\n그때, 그래서, 넌\\\\n그땐 몰랐던 일들\\\\n입이 참 무거운 남자\\\\n편지를 씁니다\\\\n그 눈 속엔 내가\\\\n영원속에\\\\n기억의 상자를 열다\\\\n그땐 몰랐던 일들 - 아이들\\\\nMy cinema paradise\\\\n낯설지 않은 꿈\\\\nLoop 1 For an End\\\\nLoop 2 For Reboot\\\\n\\\\n\\\\n== EP ==\\\\n《Renacimiento》(1996, 지구레코드)\\\\nEco\\\\n노래 1 - 벽\\\\nJoined By The Heart\\\\nDomani Piove\\\\nI Giorni Della Musica\\\\nS’Aimer En Silence\\\\nAvec Toi\\\\nTant Qu’Elle Est La...\\\\n노래 2 - 배반\\\\n《Insensible》(1998, DMR)\\\\n언제나 그랬듯이\\\\n마지막 거짓말\\\\n악몽\\\\n기념사진\\\\n마지막 거짓말 (MK’s Version)\\\\nInsensible\\\\n《The Duets Part 1》(2014, Ode/로엔엔터테인먼트)\\\\nPrelude to waltz\\\\nWaltz(duet with DAVINK)\\\\n그 겨울로부터(duet with Tim)\\\\nRE:나에게(duet with 김성규)\\\\nWaltz(inst.)\\\\n그 겨울로부터(inst.)\\\\nRE:나에게(inst.)\\\\n\\\\n\\\\n== 싱글 ==\\\\n〈날 위로하려거든〉(2014. 9. 17., 로엔엔터테인먼트)\\\\n날 위로하려거든\\\\n날 위로하려거든 (스페이스 카우보이 Remix)\\\\n\\\\n\\\\n== 사운드트랙 ==\\\\n《파일럿》(1993, 지구레코드)\\\\nTake Off\\\\nPilot\\\\nPilot Theme\\\\n하늘끝까지\\\\n이제는 말하고 싶어\\\\n우리에게 남은 시간\\\\n다시 돌아갈 수 없음을\\\\nPilot Repeat\\\\n《누들로드》(2009, ode·KT MUSIC·KBS미디어)\\\\nOpening Theme\\\\nEpisode Title 1\\\\nQuestion\\\\nDry Climate re\\\\nSoul Food\\\\nIn To The Boundery\\\\nLost City Haihm\\\\nPalatina Church\\\\nDesert\\\\nNoodle On Fire\\\\nIcy Noodle With Is\\\\nThe Mistery Food\\\\nTaste Of China 1\\\\nMenla\\\\nBack In Asia V2\\\\nNoodle Dancing\\\\nNoodle Is String\\\\nPeople\\'s Pasta\\\\nPasta Fantasy\\\\nBeauty Of Mill Field\\\\nTaste Of Rome\\\\nEurope By String\\\\nTaste Of Italy\\\\nItalian Flavour\\\\nLack Of Noodle\\\\nChow Fun Trio\\\\nNoodles On Parade\\\\nTaste Of Japan\\\\nHistory Of Soba\\\\nTemple\\\\nTechnoodle.1\\\\nTechnoodle.2\\\\nSpace By Noodle\\\\nMain Theme\\\\nEnding Theme\\\\nNoodle Express\\\\n\\\\n\\\\n== 컴필레이션 ==\\\\n\\\\n\\\\n=== 컴필레이션 앨범 ===\\\\n《Yoon Sang Best》(2001, 동아기획)\\\\n이별의 그늘\\\\n한걸음 더\\\\n행복을 기다리며\\\\n가려진 시간 사이로\\\\n넌 쉽게 말했지만\\\\n너에게\\\\n나의 꿈속에서\\\\n새벽\\\\n후회\\\\n배반\\\\n달리기\\\\n마지막 거짓말\\\\n악몽\\\\n사랑이란\\\\n바람에게\\\\nBack To The Reallife\\\\n여름밤의 꿈\\\\n\\\\n\\\\n=== 헌정 앨범 ===\\\\n《YOONSANG SONGBOOK：Play With Him!》(2008, ode)\\\\nCD 1\\\\nIN→Play with me! (bk! & K MPM Mix)\\\\n이별 없던 세상 (김형중+haihm)\\\\n랄랄라 (소녀시대+윤상)\\\\nRunner’s high (페퍼톤스)\\\\n행복을 기다리며 (마이앤트메리)\\\\n한 걸음 더 (스윗 소로우)\\\\n배반 (노영심)\\\\n마지막 거짓말 (junø)\\\\n이별의 그늘 (Lucia of Ahn Trio+junø)\\\\n사랑이란 (엄정화+박지만)\\\\nCD 2\\\\nEl camino (정재일)\\\\n소리 (W & Whale)\\\\n넌 쉽게 말했지만 (조원선+윤상)\\\\n새벽 (유희열)\\\\n너에게 (김태형+Kayip)\\\\n가려진 시간 사이로_ (윤건)\\\\n흩어진 나날들 (캐스커)\\\\n소년 (이선균+박지만)\\\\n질주 (아스트로 비츠)\\\\nOUT→Play with him! (AtpwM mix)\\\\n\\\\n\\\\n=== 박스 세트 ===\\\\n《윤상 20th anniversary》(2011, ode)\\\\nYoonsang 20th Anniversary Project BOX SET\\\\nCD 1. 1집\\\\nCD 2. 1집 - Remastering\\\\nCD 3. 윤상 2 (PART 1)\\\\nCD 4. 윤상 2 (PART 1) - Remastering\\\\nCD 5. 윤상 2 (PART 2)\\\\nCD 6. 윤상 2 (PART 2) - Remastering\\\\nCD 7. CLICHÈ\\\\nCD 8. CLICHÈ EXTRA CD (CLICHÈ앨범의 CD2)\\\\nCD 9. CLICHÈ - Remastering\\\\nCD 10. 移徙 (이사)\\\\nCD 11. 移徙 - Remastering\\\\nCD 12. There Is A Man...\\\\nCD 13. There Is A Man... - Remastering\\\\nCD 14. 그땐 몰랐던 일들\\\\nCD 15. 그땐 몰랐던 일들 - Remastering\\\\nCD 16. Renacimiento\\\\nCD 17. Renacimiento - Remastering\\\\nCD 18. Insensible\\\\nCD 19. Insensible - Remastering\\\\nLight Version SET\\\\nCD 1. 윤상 1집 - Remastering\\\\nCD 2. 윤상 2 (PART 1) - Remastering\\\\nCD 3. 윤상 2 (PART 2) - Remastering\\\\nCD 4. CLICHÈ - Remastering\\\\nCD 5. 移徙 - Remastering\\\\nCD 6. There Is A Man... - Remastering\\\\nCD 7. 그땐 몰랐던 일들 - Remastering\\\\nCD 8. Renacimiento - Remastering\\\\nCD 9. Insensible - Remastering\\\\n\\\\n\\\\n== 노땐스(with 신해철) \", \"title\": \"윤상의 음반 목록\", \"url\": \"https://ko.wikipedia.org/wiki/%EC%9C%A4%EC%83%81%EC%9D%98_%EC%9D%8C%EB%B0%98_%EB%AA%A9%EB%A1%9D\"}]}', name='search_wiki', id='afb04e08-ab1e-46c1-bc32-18722cbb43d5', tool_call_id='call_upXteCXFsdVyosBCxyXwKoN9'),\n",
       " AIMessage(content=\"좋아요 — 바로 도와드릴게요. 먼저 확인: 현재 특정 레스토랑 메뉴를 보여달라고 하신 건 아니죠? (만약 확인할 레스토랑이 있으면 알려주시면 제가 그 가게 메뉴에서 파스타를 찾아서 추천해드릴게요.) 우선 일반적으로 인기 있는 파스타 메뉴들을 가격대(예상), 주재료, 특징 순으로 정리하고 간단한 추천 이유도 드릴게요. 그 다음에 파스타의 유래를 간단히 설명하겠습니다.\\n\\n추천 파스타 메뉴 (가격은 한국 레스토랑 기준 예상 범위입니다)\\n1) 스파게티 포모도로 (Spaghetti Pomodoro)\\n   - 가격: 12,000원 ~ 16,000원\\n   - 주재료: 스파게티 면, 신선한 토마토 소스(또는 캔 토마토), 바질, 올리브오일, 마늘\\n   - 특징: 상큼하고 가벼운 토마토 풍미, 깔끔하고 부담 없는 맛\\n   - 추천 이유: 심플해서 누구나 좋아하고 재료 본연의 맛이 살아있어 처음 파스타를 먹는 분께 좋습니다.\\n\\n2) 카르보나라 (Pasta alla Carbonara)\\n   - 가격: 14,000원 ~ 20,000원\\n   - 주재료: 달걀(노른자), 페코리노 또는 파르미지아노 치즈, 구안찰레(또는 판체타/베이컨), 흑후추, 스파게티 또는 리가토니\\n   - 특징: 크리미하지만 크림을 쓰지 않는 전통 방식, 고소하고 진한 풍미\\n   - 추천 이유: 진한 맛과 풍성한 식감으로 든든히 배를 채우고 싶을 때 좋아요.\\n\\n3) 페스토 제노베제 (Pesto Genovese)\\n   - 가격: 15,000원 ~ 22,000원\\n   - 주재료: 바질 페스토(바질, 잣, 올리브오일, 파르미지아노), 감자/그린빈(옵션), 트로피에 또는 링귀니\\n   - 특징: 신선한 바질 향과 고소한 잣, 올리브오일의 상큼함이 돋보임\\n   - 추천 이유: 허브향을 좋아하시고 가벼운 올리브오일 기반을 원할 때 탁월합니다.\\n\\n4) 해산물 링귀니 / 프루티 디 마레 (Seafood Linguine / Frutti di Mare)\\n   - 가격: 18,000원 ~ 28,000원\\n   - 주재료: 각종 해산물(홍합, 새우, 오징어 등), 토마토 또는 화이트 와인-올리브오일 베이스 소스, 링귀니\\n   - 특징: 해산물의 감칠맛이 면과 잘 어우러짐, 바다향 가득\\n   - 추천 이유: 해산물 애호가에게 추천 — 풍미가 풍부하고 씹는 맛이 좋습니다.\\n\\n5) 아글리오 에 올리오 페페론치노 (Aglio e Olio)\\n   - 가격: 10,000원 ~ 14,000원\\n   - 주재료: 스파게티 면, 올리브오일, 마늘, 페페론치노(건고추), 파슬리\\n   - 특징: 매우 심플하고 빠르게 나오는 메뉴, 깔끔하고 약간 매콤함\\n   - 추천 이유: 부담 없이 즐기기 좋고 사이드나 술안주로도 인기입니다.\\n\\n파스타의 유래 (간단 정리)\\n- 고대 기원: 기원전 고대 로마·그리스 문헌에 '라가나(lagana)' 같은 얇은 반죽 요리나, 밀가루와 물을 섞어 만든 삶은 반죽류에 대한 기록이 있습니다. 즉, 면류 비슷한 식문화는 오래전부터 존재했습니다.\\n- 중세와 아랍 영향: 중세 지중해 연안 문헌에는 아랍어 계열의 itriyya(세몰리나로 만든 건조 국수류) 관련 기록이 나오며, 특히 시칠리아 등지에서 아랍인들이 건조한 국수류를 생산·수출했다는 기록이 있습니다. 듀럼 밀(세몰리나)을 이용한 건파스타 전통은 이 시기 아랍-지중해 교류와 관련이 깊습니다.\\n- 마르코 폴로 설(잘못된 통설): 중국에서 파스타를 들여왔다는 이야기는 널리 알려졌지만 학계에서는 근거가 부족하다고 보고합니다. 사실 이탈리아와 지중해 지역에 이미 오래된 면류 전통이 있었습니다.\\n- 근대 이탈리아: 토마토가 유럽에 도입된 후(신대륙 작물 교류) 토마토 소스를 이용한 파스타 요리가 발달했고, 이탈리아 북부는 달걀을 넣은 생파스타(파스타 프레스카)를, 남부는 듀럼밀 세몰라로 만든 건파스타를 주로 발전시켜 다양한 형태의 파스타가 생겼습니다.\\n- 정리: 파스타는 단일 기원이라기보다 지중해 지역의 오래된 면(반죽) 문화와 아랍권의 건조 세몰리나 기술, 이후 토마토의 도입 등이 결합되어 오늘날의 다양한 이탈리아 파스타 전통으로 발전했습니다.\\n\\n원하시면:\\n- (1) 지금 계신 지역/레스토랑을 알려주시면 그 메뉴에서 먹기 좋은 파스타를 찾아 추천해드릴게요.\\n- (2) 위 메뉴 중 하나 골라주시면 레시피나 와인/사이드 추천도 드립니다.\\n\\n어떤 스타일(크림/토마토/오일, 고기/해산물/채식)을 원하시나요?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2038, 'prompt_tokens': 15467, 'total_tokens': 17505, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 704, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4736}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Csk664a5ufRIaKxnpn6eCPcBTUE2y', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b731e-9d6a-7e32-8336-f5b38fe4706e-0', usage_metadata={'input_tokens': 15467, 'output_tokens': 2038, 'total_tokens': 17505, 'input_token_details': {'audio': 0, 'cache_read': 4736}, 'output_token_details': {'audio': 0, 'reasoning': 704}})]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "좋아요 — 바로 도와드릴게요. 먼저 확인: 현재 특정 레스토랑 메뉴를 보여달라고 하신 건 아니죠? (만약 확인할 레스토랑이 있으면 알려주시면 제가 그 가게 메뉴에서 파스타를 찾아서 추천해드릴게요.) 우선 일반적으로 인기 있는 파스타 메뉴들을 가격대(예상), 주재료, 특징 순으로 정리하고 간단한 추천 이유도 드릴게요. 그 다음에 파스타의 유래를 간단히 설명하겠습니다.\n",
      "\n",
      "추천 파스타 메뉴 (가격은 한국 레스토랑 기준 예상 범위입니다)\n",
      "1) 스파게티 포모도로 (Spaghetti Pomodoro)\n",
      "   - 가격: 12,000원 ~ 16,000원\n",
      "   - 주재료: 스파게티 면, 신선한 토마토 소스(또는 캔 토마토), 바질, 올리브오일, 마늘\n",
      "   - 특징: 상큼하고 가벼운 토마토 풍미, 깔끔하고 부담 없는 맛\n",
      "   - 추천 이유: 심플해서 누구나 좋아하고 재료 본연의 맛이 살아있어 처음 파스타를 먹는 분께 좋습니다.\n",
      "\n",
      "2) 카르보나라 (Pasta alla Carbonara)\n",
      "   - 가격: 14,000원 ~ 20,000원\n",
      "   - 주재료: 달걀(노른자), 페코리노 또는 파르미지아노 치즈, 구안찰레(또는 판체타/베이컨), 흑후추, 스파게티 또는 리가토니\n",
      "   - 특징: 크리미하지만 크림을 쓰지 않는 전통 방식, 고소하고 진한 풍미\n",
      "   - 추천 이유: 진한 맛과 풍성한 식감으로 든든히 배를 채우고 싶을 때 좋아요.\n",
      "\n",
      "3) 페스토 제노베제 (Pesto Genovese)\n",
      "   - 가격: 15,000원 ~ 22,000원\n",
      "   - 주재료: 바질 페스토(바질, 잣, 올리브오일, 파르미지아노), 감자/그린빈(옵션), 트로피에 또는 링귀니\n",
      "   - 특징: 신선한 바질 향과 고소한 잣, 올리브오일의 상큼함이 돋보임\n",
      "   - 추천 이유: 허브향을 좋아하시고 가벼운 올리브오일 기반을 원할 때 탁월합니다.\n",
      "\n",
      "4) 해산물 링귀니 / 프루티 디 마레 (Seafood Linguine / Frutti di Mare)\n",
      "   - 가격: 18,000원 ~ 28,000원\n",
      "   - 주재료: 각종 해산물(홍합, 새우, 오징어 등), 토마토 또는 화이트 와인-올리브오일 베이스 소스, 링귀니\n",
      "   - 특징: 해산물의 감칠맛이 면과 잘 어우러짐, 바다향 가득\n",
      "   - 추천 이유: 해산물 애호가에게 추천 — 풍미가 풍부하고 씹는 맛이 좋습니다.\n",
      "\n",
      "5) 아글리오 에 올리오 페페론치노 (Aglio e Olio)\n",
      "   - 가격: 10,000원 ~ 14,000원\n",
      "   - 주재료: 스파게티 면, 올리브오일, 마늘, 페페론치노(건고추), 파슬리\n",
      "   - 특징: 매우 심플하고 빠르게 나오는 메뉴, 깔끔하고 약간 매콤함\n",
      "   - 추천 이유: 부담 없이 즐기기 좋고 사이드나 술안주로도 인기입니다.\n",
      "\n",
      "파스타의 유래 (간단 정리)\n",
      "- 고대 기원: 기원전 고대 로마·그리스 문헌에 '라가나(lagana)' 같은 얇은 반죽 요리나, 밀가루와 물을 섞어 만든 삶은 반죽류에 대한 기록이 있습니다. 즉, 면류 비슷한 식문화는 오래전부터 존재했습니다.\n",
      "- 중세와 아랍 영향: 중세 지중해 연안 문헌에는 아랍어 계열의 itriyya(세몰리나로 만든 건조 국수류) 관련 기록이 나오며, 특히 시칠리아 등지에서 아랍인들이 건조한 국수류를 생산·수출했다는 기록이 있습니다. 듀럼 밀(세몰리나)을 이용한 건파스타 전통은 이 시기 아랍-지중해 교류와 관련이 깊습니다.\n",
      "- 마르코 폴로 설(잘못된 통설): 중국에서 파스타를 들여왔다는 이야기는 널리 알려졌지만 학계에서는 근거가 부족하다고 보고합니다. 사실 이탈리아와 지중해 지역에 이미 오래된 면류 전통이 있었습니다.\n",
      "- 근대 이탈리아: 토마토가 유럽에 도입된 후(신대륙 작물 교류) 토마토 소스를 이용한 파스타 요리가 발달했고, 이탈리아 북부는 달걀을 넣은 생파스타(파스타 프레스카)를, 남부는 듀럼밀 세몰라로 만든 건파스타를 주로 발전시켜 다양한 형태의 파스타가 생겼습니다.\n",
      "- 정리: 파스타는 단일 기원이라기보다 지중해 지역의 오래된 면(반죽) 문화와 아랍권의 건조 세몰리나 기술, 이후 토마토의 도입 등이 결합되어 오늘날의 다양한 이탈리아 파스타 전통으로 발전했습니다.\n",
      "\n",
      "원하시면:\n",
      "- (1) 지금 계신 지역/레스토랑을 알려주시면 그 메뉴에서 먹기 좋은 파스타를 찾아 추천해드릴게요.\n",
      "- (2) 위 메뉴 중 하나 골라주시면 레시피나 와인/사이드 추천도 드립니다.\n",
      "\n",
      "어떤 스타일(크림/토마토/오일, 고기/해산물/채식)을 원하시나요?\n"
     ]
    }
   ],
   "source": [
    "print(res['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain에서 MCP 연동\n",
    "\n",
    "## MCP란\n",
    "\n",
    "- **MCP**(**Model Context Protocol**)는 Anthropic이 주도하여 2024년 말에 발표한 개방형 표준으로, LLM 애플리케이션이 외부 데이터 소스나 도구에 접근하는 방식을 표준화 하는 프로토콜이다.\n",
    "  - Agent가 이용할 수 있는 tool을 구현하는 방법은 framework 마다 다르기 때문에 서로 호환 되지 않는 문제가 있다. \n",
    "  - MCP는 이런 문제를 해결하기 위해 만든 표준 프로토콜이다.\n",
    "\n",
    "## MCP 아키텍처 구성 요소\n",
    "- **MCP 호스트**\n",
    "  -  AI 애플리케이션(예: LLM 채팅 애플리케이션)으로 MCP 클라이언트를 통해 여러 서버에 연결한다.\n",
    "\n",
    "- **MCP 클라이언트**\n",
    "  -  각 MCP 서버와의 연결을 유지하는 구성요소로, 서버로부터 도구/리소스/프롬프트를 가져와 LLM 모델에게 전달한다.\n",
    "\n",
    "- **MCP 서버**\n",
    "  -  외부 데이터 소스나 Tool들을 제공하는 프로그램이다. 서버는 도구, 리소스, 프롬프트를 노출하고 클라이언트와 JSON‑RPC 2.0 메시지로 통신한다.\n",
    "  -  MCP는 서버 클라이언트 간의 **로컬 프로세스 간 통신을 위한 STDIO**와 **원격 서버 접속을 위한 Streamable HTTP** 두 가지 전송 방식을 지원한다\n",
    "  -  **MCP 서버가 제공하는 것**\n",
    "     -  **도구**(**Tools**): LLM이 호출할 수 있는 함수형 작업이다. 예를 들어 “queryDatabase”, “sendEmail” 등이 있으며 각 도구는 이름, 설명, 입력 스키마를 포함한다.\n",
    "     -  **리소스**(**Resources**): 읽기 전용 데이터 소스로, 검색 색인·파일시스템·데이터베이스 등에서 컨텍스트를 제공한다.\n",
    "     -  **프롬프트**(**Prompts**): LLM 프롬프트 템플릿이나 예시를 서버에서 제공해 AI 모델의 질의를 돕는다.\n",
    "  \n",
    "\n",
    "## 사용 가능한 MCP 툴 찾기\n",
    "\n",
    "- MCP 생태계에는 수천 개의 툴 서버가 이미 공개되어 있으며, 원하는 기능의 툴을 검색하여 사용할 수 있다. \n",
    "- MCP 검색 및 서비스 사이트\n",
    "  - [PulseMCP](pulsemcp.com)\n",
    "  - [MCP 마켓](https://mcpmarket.com/ko)\n",
    "  - [MCP Servers](https://mcp.so/)\n",
    "  - [smithery](https://smithery.ai/servers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## LangChain에서 MCP 툴 연동하기\n",
    "\n",
    "- Node.js 설치\n",
    "- LangChain에서 MCP 서버와 연동하기 위해서는 Adapter lib 설치가 필요하다.\n",
    "  - `pip install langchain-mcp-adapters`\n",
    "\n",
    "###  MultiServerMCPClient \n",
    "- **MCP 클라이언트 객체**로, LangChain에서 **하나 이상의 MCP 서버를 연결하고 Tool 목록을 가져오기 위해 사용**한다.\n",
    "    - 여러 개의 MCP 서버를 **동시에 등록하고 연결**할 수 있다.\n",
    "    - 서버 설정들을 **하나의 딕셔너리**(**Dictionary**)로 묶어 전달하며, **각 개별 서버 역시 Dictionary로 설정**한다.\n",
    "    - MCP 클라이언트에 등록된 모든 서버는 이후 `get_tools()` 호출을 통해 서버가 제공하는 tool들을 **LangChain의 Tool 객체로 자동 변환해 Agent가 호출**(**사용**)할 수있게 한다.\n",
    "\n",
    "#### 개별 서버 설정 Key 정의\n",
    "- **`dict[str: 서버 별칭, dict: 서버 설정]`**\n",
    "\n",
    "| 설정 Key        | 의미                                                                  | 사용 예                            |\n",
    "| --------------- | --------------------------------------------------------------------- | ---------------------------------- |\n",
    "| **`transport`** | 서버와 통신하는 방식                                                  | `\"stdio\"` 또는 `\"streamable-http\"` |\n",
    "| **`command`**   | MCP 서버를 실행할 프로그램(프로세스)                                  | `\"python\"` 또는 `\"npx\"`            |\n",
    "| **`args`**      | command에 전달할 세부 실행 인자를 **리스트(List)**에 문자열로 순서대로 배치 | `[\"-m\", \"mcp_server_time\"]`  |\n",
    "\n",
    "- **transport 값에 따른 동작 구분**\n",
    "    - `\"stdio\"`: 로컬에서 실행되는 서버 연결\n",
    "    - `\"streamable-http\"`: 원격 MCP 서버(서비스형) 연결\n",
    "    \n",
    "    ```json\n",
    "        {\n",
    "            \"time\": {\n",
    "                \"transport\": \"stdio\",\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"-m\", \"mcp_server_time\"]\n",
    "            }\n",
    "        \n",
    "            \"github\": {\n",
    "                \"transport\": \"streamable-http\",\n",
    "                \"url\": \"https://server.smithery.ai/github\",\n",
    "            }\n",
    "        }\n",
    "    ```\n",
    "\n",
    "#### command + args 와 실행 명령어 관계\n",
    "\n",
    "| 실제 실행 명령                    | 설정으로 표현되는 방식                                             |\n",
    "| --------------------------- | -------------------------------------------------------- |\n",
    "| `python -m mcp_server_time` | `\"command\": \"python\", \"args\": [\"-m\", \"mcp_server_time\"]` |\n",
    "| `npx -y @org/server`        | `\"command\": \"npx\", \"args\": [\"-y\", \"@org/server\"]`        |\n",
    "\n",
    "* **command는 실행 프로그램**, args는 **명령 뒤에 붙는 옵션을 순서 그대로 리스트에 나열**한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m46 packages\u001b[0m \u001b[2min 316ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m6 packages\u001b[0m \u001b[2min 175ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m6 packages\u001b[0m \u001b[2min 115ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-mcp-adapters\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmcp\u001b[0m\u001b[2m==1.25.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyjwt\u001b[0m\u001b[2m==2.10.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msse-starlette\u001b[0m\u001b[2m==3.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.50.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.40.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain-mcp-adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m34 packages\u001b[0m \u001b[2min 160ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 22ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 32ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmcp-server-time\u001b[0m\u001b[2m==2025.9.25\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtzlocal\u001b[0m\u001b[2m==5.3.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install mcp_server_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter lab에서 비동기 처리를 위해서 실행.\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mcp_exam.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_exam.py\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "async def main():\n",
    "    # 1. MCP Client 생성 : 연결할 서버정보를 제공(실행)\n",
    "    client = MultiServerMCPClient(\n",
    "        {\n",
    "            \"time\": {\n",
    "                \"transport\":\"stdio\", # 통신방식\n",
    "                \"command\": \"python\", \n",
    "                \"args\": [\"-m\", \"mcp_server_time\"] # command + args 실행: python -m mcp_server_time 서버를 실행하고 연결\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    # MCP Client로부터 tool들을 가져오기.\n",
    "    tools = await client.get_tools()\n",
    "\n",
    "    # tools : list[StructuredTool-Langchain Tool 타입] \n",
    "    # - MCP 서버의 툴들을 langchain에서 사용할 수 있게 만들어서 반환.\n",
    "\n",
    "    agent = create_agent(\n",
    "        model=ChatOpenAI(model=\"gpt-5.2\"),\n",
    "        tools=tools,\n",
    "        system_prompt=\"\"\"당신은 AI Assistant입니다. 필요한 경우 등록된 도구들을 이용해 질문에 답하세요. 답변은 한국어로 하세요.\"\"\"\n",
    "    )\n",
    "    print(\">>>> 종료 하려면 !quit을 입력하세요.<<<<\")\n",
    "    while True:\n",
    "        query = input(\"질문:\")\n",
    "        if query == \"!quit\":\n",
    "            print(\">>>> 종료 <<<<\")\n",
    "            break\n",
    "        res = await agent.ainvoke({\n",
    "            \"messages\": [\n",
    "                (\"human\", query)\n",
    "            ]\n",
    "        })\n",
    "        print(res['messages'][-1].content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
