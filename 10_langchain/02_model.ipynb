{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4766ebb-432c-4bdb-8050-23df797098be",
   "metadata": {},
   "source": [
    "<!-- # Langchain은 다양한 LLM(대규모 언어 모델)을 지원한다\n",
    "-\t대규모 언어 모델(LLM, Large Language Model)을 개발하는 회사들은 사용자가 자신의 애플리케이션에서 LLM을 손쉽게 활용할 수 있도록 API(Application Programming Interface) 서비스를 제공하고 있다.\n",
    "-\t하지만 각 LLM은 고유한 API 호출 라이브러리(Library)를 제공하기 때문에, 개발자는 동일한 작업을 수행하더라도 LLM에 따라 다른 코드를 작성해야 하는 번거로움이 있다.\n",
    "-\tLangchain은 이러한 문제를 해결하기 위해 다양한 LLM의 API를 통합적으로 지원한다.\n",
    "-\t여러 LLM을 동일한 인터페이스(interface)로 호출할 수 있게 하여 특정 모델에 종속되지 않도록 하고, 필요에 따라 쉽게 다른 모델로 전환할 수 있다.\n",
    "-\tLangchain이 지원하는 주요 LLM 목록\n",
    "    - https://python.langchain.com/docs/integrations/chat/#featured-providers -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd979cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m4 packages\u001b[0m \u001b[2min 19ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain langchain-classic langchain-community python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9025ef1-ede0-4f3b-b8fe-1b9e348391ba",
   "metadata": {},
   "source": [
    "# OpenAI 모델 사용\n",
    "- https://platform.openai.com\n",
    "  \n",
    "## 결제\n",
    "1. 로그인 후 Billing 페이지로 이동.\n",
    "   - **신용카드가 등록된 경우 바로 충전할 수 있다.**\n",
    "   - setting -> Billing\n",
    "  \n",
    "   ![openai_payment.png](figures/openai_payment.png)\n",
    "   - 금액 입력 후 `continue`\n",
    "   - 다음 페이지에서 세금 포함 결제 금액 나오면 `Confirm`  한다.\n",
    "\n",
    "2. 신용카드 등록\n",
    "   - Payment methods 탭을 선택하고 카드를 등록한다. \n",
    "   \n",
    "   ![openai_payment2.png](figures/openai_payment2.png)\n",
    "\n",
    "   - 등록이 끝나면 최초 구매를 진행한다. $5 ~ $100 사이의 금액을 선택할 수 있다.\n",
    "   - 자동 충전을 설정하고 싶다면 automatic recharge 를 활성화 하고 아래 추가 설정에 입력한다. \n",
    "     - 자동 충전은 특정 금액 이하로 떨어지면 자동으로 충전한다. (**비활성화**) \n",
    "  \n",
    "   ![openai_payment3.png](figures/openai_payment3.png)\n",
    "   \n",
    "3. 수동으로 **추가 결제하기**\n",
    "   - Billing 페이지의 Overview에서 `Add to credit balance` 를 클릭한 뒤 금액을 입력하고 결제한다.\n",
    "\n",
    "## 사용량 확인\n",
    "- profile/설정 -> Usage 에서 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f99e0-d15b-4769-8d2c-b6e0a9a26237",
   "metadata": {},
   "source": [
    "## API Key 생성\n",
    "  \n",
    "![openai_create_apikey.png](figures/openai_create_apikey.png)\n",
    "\n",
    "- 로그인 -> Dashboard -> API Keys -> Create New Secreat Key\n",
    "> Settings -> API Keys\n",
    "\n",
    "## API Key 등록\n",
    "- 환경변수에 등록\n",
    "  - 변수이름: OPENAI_API_KEY\n",
    "  - 값: 생성된 키\n",
    "- dotenv를 이용해서 load\n",
    "  - Working directory에  `.env` 파일 생성하고 `OPENAI_API_KEY=생성된키` 추가한다.\n",
    "  - load_dotenv() 호출 하면 .env 파일에 있는 값을 읽은 뒤 환경변수로 등록한다.\n",
    "- **주의**\n",
    "  - 생성된 API Key는 노출되면 안된다.\n",
    "  - API Key가 저장된 파일(코드나 설정파일)이 github에 올라가 공개되서는 안된다.\n",
    "\n",
    "## 사용 비용 확인\n",
    "- settings -> Usage 에서 확인\n",
    "\n",
    "## OpenAI LLM 모델들\n",
    "-  OpenAI LLM 모델: https://platform.openai.com/docs/models\n",
    "-  모델별 가격: https://platform.openai.com/docs/pricing\n",
    "-  토큰사이즈 확인: https://platform.openai.com/tokenizer\n",
    "   -  1토큰: 영어 3\\~4글자 정도, 한글: 대략 1\\~2글자 정도\n",
    "   -  모델이 업데이트 되면서 토큰 사이즈도 조금씩 커지고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c5a12d-8e7d-4a29-ac91-edb62c56bfe7",
   "metadata": {},
   "source": [
    "## OpenAI 를 연동하기 위한 package 설치\n",
    "```bash\n",
    "pip install langchain-openai -qU\n",
    "```\n",
    "\n",
    "- OpenAI 자체 라이브러리 설치\n",
    "    - `pip install openai -qU`\n",
    "    - langchain-openai를 설치하면 같이 설치 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29772e79-1e31-421d-b5c1-625dc029c395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 69ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "704ee7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 99ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install ipykernel ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fe4e229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API Key Load -> OS 환경변수로 등록.(OPENAI_API_KEY)\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b563c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a486e5a1-6c59-499d-a275-41060c8b0a8a",
   "metadata": {},
   "source": [
    "## OpenAI Library 를 이용한 API 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9bb769-eb14-43d5-9c26-98bb77153b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI() #api key가 환경변수에 없으면 직접 입력.\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5-nano\", #사용할 모델 종류\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\":\"OpenAI의 LLM 모델 종류는 뭐가 있어?\"}\n",
    "    ]\n",
    ")\n",
    "# chat 요청 프롬프트 형식\n",
    "# \"role\":\"누가 말하는지-user,ai,system\"\n",
    "# \"content\":메세지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fb03a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CmsokvXqIox9BnRTkq143f8D8OUfK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='대략적으로 OpenAI의 LLM은 다음 계열로 정리할 수 있어요. 모델 이름은 시기에 따라 바뀌거나 신모델이 추가될 수 있으니, 최신은 OpenAI 문서를 확인하는 걸 추천합니다.\\n\\n- GPT-3 계열 (초창기 대형 언어모델)\\n  - 예시 모델: ada, babbage, curie, davinci\\n  - 용도: 일반 텍스트 생성, 요약, 문서 작성의 기초 작업 등\\n  - 특징: 비교적 저렴하고 속도가 빠르지만 가장 강력한 추론은 아니고, 간단한 작업에 적합\\n\\n- GPT-3.5 계열\\n  - 대표 모델: gpt-3.5-turbo, text-davinci-003\\n  - 용도: 대화형 챗봇, 고품질 텍스트 생성, 코드 관련 작업까지 폭넓게 사용\\n  - 특징: 더 나은 추론과 일관성, 대화에 특화된 성능 향상\\n\\n- GPT-4 계열\\n  - 대표 모델: gpt-4, gpt-4-turbo, gpt-4o\\n  - 용도: 고급 추론, 복잡한 문제 해결, 장문 작성, 다중모달 입력(일부 모델에서 이미지 입력 가능)\\n  - 특징\\n    - gpt-4: 강력한 추론과 긴 컨텍스트 처리\\n    - gpt-4-turbo: 더 저렴하고 빠른 버전, 실무 사용에 널리 쓰임\\n    - gpt-4o: 멀티모달(이미지 입력 등) 지원 가능\\n  - 주의: 비용과 속도 면에서 turbo가 일반적으로 더 선호되기도 함\\n\\n- Codex 계열 (코드 생성/보완용)\\n  - 대표 모델: code-davinci-002, code-cushman-001(또는 002 계열 등)\\n  - 용도: 코드 작성, 예시 생성, 코드 수정 및 설명\\n  - 특징: 개발자 도구나 Copilot 같은 코드 생산에 특화돼 있음\\n\\n참고 및 사용 팁\\n- ChatGPT 같은 소비자용 제품은 보통 gpt-3.5-turbo 또는 gpt-4-turbo를 기반으로 하는 경우가 많습니다.\\n- 멀티모달이 필요한 경우에는 gpt-4o를 고려합니다.\\n- 예산과 속도가 중요한 경우 gpt-3.5-turbo나 gpt-4-turbo를 우선 검토하고, 더 높은 품질이 필요하면 gpt-4 계열로 넘어가는 식으로 선택할 수 있습니다.\\n\\n원하신다면 현재 공개된 모델 목록의 최신 버전을 확인해 드리거나, 특정 용도(예: 한국어 대화, 코드 작성, 긴 문서 요약 등)에 맞춰 추천 모델 조합을 함께 정리해 드릴게요.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1765766498, model='gpt-5-nano-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=3268, prompt_tokens=18, total_tokens=3286, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2624, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11f060cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대략적으로 OpenAI의 LLM은 다음 계열로 정리할 수 있어요. 모델 이름은 시기에 따라 바뀌거나 신모델이 추가될 수 있으니, 최신은 OpenAI 문서를 확인하는 걸 추천합니다.\n",
      "\n",
      "- GPT-3 계열 (초창기 대형 언어모델)\n",
      "  - 예시 모델: ada, babbage, curie, davinci\n",
      "  - 용도: 일반 텍스트 생성, 요약, 문서 작성의 기초 작업 등\n",
      "  - 특징: 비교적 저렴하고 속도가 빠르지만 가장 강력한 추론은 아니고, 간단한 작업에 적합\n",
      "\n",
      "- GPT-3.5 계열\n",
      "  - 대표 모델: gpt-3.5-turbo, text-davinci-003\n",
      "  - 용도: 대화형 챗봇, 고품질 텍스트 생성, 코드 관련 작업까지 폭넓게 사용\n",
      "  - 특징: 더 나은 추론과 일관성, 대화에 특화된 성능 향상\n",
      "\n",
      "- GPT-4 계열\n",
      "  - 대표 모델: gpt-4, gpt-4-turbo, gpt-4o\n",
      "  - 용도: 고급 추론, 복잡한 문제 해결, 장문 작성, 다중모달 입력(일부 모델에서 이미지 입력 가능)\n",
      "  - 특징\n",
      "    - gpt-4: 강력한 추론과 긴 컨텍스트 처리\n",
      "    - gpt-4-turbo: 더 저렴하고 빠른 버전, 실무 사용에 널리 쓰임\n",
      "    - gpt-4o: 멀티모달(이미지 입력 등) 지원 가능\n",
      "  - 주의: 비용과 속도 면에서 turbo가 일반적으로 더 선호되기도 함\n",
      "\n",
      "- Codex 계열 (코드 생성/보완용)\n",
      "  - 대표 모델: code-davinci-002, code-cushman-001(또는 002 계열 등)\n",
      "  - 용도: 코드 작성, 예시 생성, 코드 수정 및 설명\n",
      "  - 특징: 개발자 도구나 Copilot 같은 코드 생산에 특화돼 있음\n",
      "\n",
      "참고 및 사용 팁\n",
      "- ChatGPT 같은 소비자용 제품은 보통 gpt-3.5-turbo 또는 gpt-4-turbo를 기반으로 하는 경우가 많습니다.\n",
      "- 멀티모달이 필요한 경우에는 gpt-4o를 고려합니다.\n",
      "- 예산과 속도가 중요한 경우 gpt-3.5-turbo나 gpt-4-turbo를 우선 검토하고, 더 높은 품질이 필요하면 gpt-4 계열로 넘어가는 식으로 선택할 수 있습니다.\n",
      "\n",
      "원하신다면 현재 공개된 모델 목록의 최신 버전을 확인해 드리거나, 특정 용도(예: 한국어 대화, 코드 작성, 긴 문서 요약 등)에 맞춰 추천 모델 조합을 함께 정리해 드릴게요.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851be9d2-58e5-464b-87cb-52f09a9a146b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7056dd-ddc5-4c0f-8653-47be64287d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f77416bf-be44-421b-bed1-c1da8512e983",
   "metadata": {},
   "source": [
    "## Langchain을 이용한 OpenAI API 호출\n",
    "\n",
    "- **ChatOpenAI**\n",
    "    - chat (대화-채팅) 기반 모델 model.\n",
    "    - Default 로 gpt-3.5-turbo 사용\n",
    "    - llm 전달 입력과 llm 응답 출력 타입:  Message\n",
    "> - **OpenAI**\n",
    ">     - 문장 완성 모델. (text completion) model\n",
    ">     - Default로 gpt-3.5-turbo-instruct 사용\n",
    ">       - instruct 모델만 사용가능\n",
    ">     - llm전달 입력과 llm 응답 출력 타입: str\n",
    "- Initializer 주요 파라미터\n",
    "    -  **temperature**\n",
    "        -  llm 모델의 출력 무작위성을 지정한다. \n",
    "        -  0 ~ 2 사이 실수를 설정하며 클 수록 무작위성이 커진다. 기본값: 0.7\n",
    "        -  정확한 답변을 얻어야 하는 경우 작은 값을 창작을 해야 하는 경우 큰 값을 지정한다.\n",
    "    -  **model_name**\n",
    "        -  사용할 openai 모델 지정\n",
    "    - **max_tokens**:\n",
    "        - llm 모델이 응답할 최대 token 수.\n",
    "        - gpt-5 모델은 추론과정을 거칠 수있고 이 경우 토큰을 소비한다. 그래서 max_tokens를 너무 작게 잡으면 응답이 안올 수있다.\n",
    "    - **api_key**\n",
    "        - OpenAI API key를 직접 입력해 생성시 사용.\n",
    "        - API key가 환경변수에 설정 되있으면 생략한다. \n",
    "-  메소드\n",
    "    - **`invoke(message)`** : LLM에 질의 메세지를 전달하며 LLM의 응답을 반환한다.\n",
    "> - **Message**\n",
    ">     - Langchain 다양한 상황과 작업 마다 다양한 값들로 구성된 입출력 데이터를 만든다. \n",
    ">     - Langchain은 그 상황들에 맞는 다양한 Message 클래스를 제공한다. 이것을 이용하면 특정 작업에 적합한 입력값을 설정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124af8a3-d624-4399-8062-35a6d60c63b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain은 인공지능 언어 모델(LLM)을 활용한 애플리케이션을 빠르고 체계적으로 만들 수 있도록 도와주는 프레임워크예요. 프롬프트 관리부터, 다중 단계 처리(체인), 에이전트가 도구를 활용하는 워크플로, 외부 데이터 소스와의 연결까지 대부분의 일반적인 패턴을 미리 구성 가능한 컴포넌트로 제공합니다.\n",
      "\n",
      "주요 포인트\n",
      "- 목적: LLM을 중심으로 하는 애플리케이션 개발의 boilerplate를 줄이고, 재사용 가능한 구성요소로 복합 워크플로를 쉽게 만들 수 있도록 함.\n",
      "- 다중 언어 지원: Python과 JavaScript/TypeScript 버전이 있어 서버 사이드나 프론트엔드/노드 환경에서도 사용 가능.\n",
      "- 핵심 아이디어: 프롬프트(템플릿) + LLM 호출을 연결하는 체인(Chain)과, 필요 시 외부 도구(API 등)을 사용할 수 있는 에이전트(Agent) 구성을 제공.\n",
      "- 모듈화된 구성 요소: \n",
      "  - Prompts: PromptTemplate 등으로 파라미터화된 프롬프트 관리\n",
      "  - Chains: LLMChain, SimpleSequentialChain, SequentialChain 등으로 단계별 흐름 구성\n",
      "  - Memory: 대화 이력이나 상태를 유지하는 메모리 모듈(예: ConversationBufferMemory)\n",
      "  - Tools/도구: 외부 API 호출이나 코드 실행 등 외부 작업을 수행하는 도구\n",
      "  - Agents와 AgentExecutor: 에이전트가 목표를 달성하기 위해 어떤 도구를 언제 쓸지 판단하고 실행\n",
      "  - Vector Stores 및 Retrieval: 벡터 데이터베이스(예: Chroma, FAISS, Pinecone 등)와 문서 로더를 활용한 RAG( Retrieval-Augmented Generation) 구성\n",
      "  - Document Loaders: PDF, Word, HTML 등 다양한 문서 소스 로딩 도구\n",
      "  - 콜백/로깅: 실행 중인 과정의 상태를 로깅하고 디버깅에 도움되는 훅\n",
      "\n",
      "주요 구성 요소 예시\n",
      "- LLMChain: 특정 프롬프트를 LLM에 전달해 한 단계의 결과를 얻는 기본 단위\n",
      "- PromptTemplate: 파라미터를 채워넣어 실행할 프롬프트를 생성\n",
      "- Memory: 대화 맥락을 유지하거나 요약하는 메모리 유틸리티\n",
      "- Tools/Tool: 외부 API 호출, 계산, 데이터베이스 조회 등 에이전트가 사용할 수 있는 작업 단위\n",
      "- AgentExecutor: 에이전트가 프롬프트를 해석하고 도구를 선택해 실행하는 실행 엔진\n",
      "- ZeroShotAgent, ReAct 계열 에이전트: 목적 달성을 위해 계획을 세우고 도구를 순차적으로 호출하는 흐름\n",
      "- VectorStore 및 Document Loader: 문서를 임베딩하고 검색해 LLM의 답변 품질을 높이는 구성\n",
      "- 랭체인 생태계: 다양한 LLM 공급자(OpenAI, Cohere, HuggingFace 등)와 도구를 표준 인터페이스로 연결\n",
      "\n",
      "사용 사례\n",
      "- 챗봇/대화형 에이전트: 대화 맥락을 기억하고 필요 시 외부 API를 호출해 정보 제공\n",
      "- 리트리벌 기반 질의 응답(RAG): 문서 컬렉션에서 관련 정보를 검색하고 LLM으로 요약·답변\n",
      "- 자동화 에이전트: 특정 목표를 달성하기 위해 도구를 조합해 작업 수행\n",
      "- 데이터 추출 및 파이프라인 구축: 문서에서 정보 추출하고 다른 시스템으로 전달하는 파이프라인 구성\n",
      "\n",
      "장점\n",
      "- 빠른 프로토타이핑과 재사용성: 동일한 구성 요소를 조합해 다양한 워크플로를 쉽게 테스트\n",
      "- 인터페이스 표준화: LLM, 메모리, 도구, 벡터 저장소 간의 통합이 일관되게 이루어짐\n",
      "- 생태계 확장성: 여러 벡터 스토어, 문서 로더, LLM 공급자와의 연동이 상대적으로 간편\n",
      "\n",
      "주의점\n",
      "- 비용 관리: LLM 호출, 벡터 데이터베이스 조회 등으로 비용이 증가할 수 있음\n",
      "- 복잡도 관리: 에이전트의 행동이 복잡해지면 디버깅이 어려워질 수 있어 로깅과 모니터링 필요\n",
      "- 데이터 보안/프라이버시: 외부 API 호출 시 데이터 처리 방식에 주의가 필요\n",
      "\n",
      "간단한 흐름 예시\n",
      "- 프롬프트를 구성하고 LLMChain으로 호출\n",
      "- 필요하면 대화를 기억하기 위한 Memory를 함께 사용\n",
      "- 문서가 필요하면 Document Loader로 로드하고, 벡터 스토어와 연결해 관련 정보를 가져옴\n",
      "- 에이전트가 목표를 가지면 Tool을 사용해 외부 작업을 수행하고 결과를 다시 LLM에 전달해 최종 답변 도출\n",
      "\n",
      "필요하면 특정 사용 사례나 간단한 예제 구조를 더 자세히 설명해줄 수 있어요. 어떤 부분이 궁금하신가요?"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "# 질의\n",
    "response = model.stream(\"Langchain은 어떤 Framework인지 설명해줘.\")\n",
    "for token in response:\n",
    "    print(token.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1948856-b1e4-4da0-9311-11f798b66a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(response))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'generator' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40ce72eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Your organization must be verified to generate reasoning summaries. Please go to: https://platform.openai.com/settings/organization/general and click on Verify Organization. If you just verified, it can take up to 15 minutes for access to propagate.', 'type': 'invalid_request_error', 'param': 'reasoning.summary', 'code': 'unsupported_value'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# reasoning 설정(gpt-5)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m## reasoning: 문제 전제 -> 논리를 전개 -> 결론을 도출 하는 과정을 스스로 계획/구성해서 답을 도출한다.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# effort: 추론의 깊이(low, medium, high), summary: 추론과정을 출력.\u001b[39;00m\n\u001b[32m      4\u001b[39m model = ChatOpenAI(\n\u001b[32m      5\u001b[39m     model = \u001b[33m\"\u001b[39m\u001b[33mgpt-5\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     reasoning={\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33meffort\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmedium\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msummary\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m     }\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m result = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLLM 모델에 대한 내용을 초심자를 위해 최대한 쉽게 설명해줘.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1382\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1380\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1381\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1384\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1385\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1386\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1387\u001b[39m ):\n\u001b[32m   1388\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1364\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1360\u001b[39m     raw_response = \u001b[38;5;28mself\u001b[39m.root_client.responses.with_raw_response.parse(\n\u001b[32m   1361\u001b[39m         **payload\n\u001b[32m   1362\u001b[39m     )\n\u001b[32m   1363\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1364\u001b[39m     raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\n\u001b[32m   1366\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1367\u001b[39m response = raw_response.parse()\n\u001b[32m   1368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.include_response_headers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\openai\\resources\\responses\\responses.py:866\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, background, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, prompt_cache_retention, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    829\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    830\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    865\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'Your organization must be verified to generate reasoning summaries. Please go to: https://platform.openai.com/settings/organization/general and click on Verify Organization. If you just verified, it can take up to 15 minutes for access to propagate.', 'type': 'invalid_request_error', 'param': 'reasoning.summary', 'code': 'unsupported_value'}}"
     ]
    }
   ],
   "source": [
    "# reasoning 설정(gpt-5)\n",
    "## reasoning: 문제 전제 -> 논리를 전개 -> 결론을 도출 하는 과정을 스스로 계획/구성해서 답을 도출한다.\n",
    "# effort: 추론의 깊이(low, medium, high), summary: 추론과정을 출력.\n",
    "model = ChatOpenAI(\n",
    "    model = \"gpt-5\",\n",
    "    reasoning={\n",
    "        \"effort\": \"medium\", \"summary\":\"auto\"\n",
    "    }\n",
    ")\n",
    "result = model.invoke(\"LLM 모델에 대한 내용을 초심자를 위해 최대한 쉽게 설명해줘.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3f02070",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-5-mini\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "태양계를 구성하는 행성들에 대해 태양에서 가까운 순서대로 알려줘.\n",
    "\n",
    "결과는 다음 답변형식에 맞춘다.\n",
    "[답변형식]\n",
    "- 행성한국어이름(영어이름): 간단한 한 줄 설명\n",
    "\"\"\"\n",
    "res = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b7d2b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 수성(Mercury): 태양에서 가장 가까운 행성으로, 작고 표면 온도 변화가 극심함.\n",
      "- 금성(Venus): 두꺼운 이산화탄소 대기와 극심한 온실효과로 매우 뜨거운 행성.\n",
      "- 지구(Earth): 생명체가 존재하는 유일한 알려진 행성으로 물이 풍부함.\n",
      "- 화성(Mars): 붉은 색을 띠며, 얇은 대기와 고대의 물 흔적이 관찰되는 행성.\n",
      "- 목성(Jupiter): 태양계에서 가장 큰 가스 거인으로 강한 자기장과 여러 큰 위성을 가짐.\n",
      "- 토성(Saturn): 뚜렷한 고리 구조를 가진 가스 거인.\n",
      "- 천왕성(Uranus): 옆으로 누운 듯한 자전축을 가진 얼음 거인으로 청록색을 띔.\n",
      "- 해왕성(Neptune): 태양계 최외곽의 얼음 거인으로 강한 바람과 짙은 푸른색을 보임.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed81fb-5249-4bd3-91b0-4f86a0a75f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reasoning\n",
    "# content에 추론 내용과 응답 내용을 묶어서 반환.\n",
    "# type: reasoning - 추론과정, text - 최종응답"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71861354-39b6-4a7d-842d-8939d3a3e5bc",
   "metadata": {},
   "source": [
    "# Hugging Face 모델 사용\n",
    "\n",
    "## Local 에 설치된 모델 사용\n",
    "- HuggingFacePipeline 에 Model id를 전달해 Model객체를 생성한다.\n",
    "- huggingface transformers 라이브러리를 이용해 model을 생성 한 뒤 HuggingFacePipeline 에 넣어 생성한다.\n",
    "- 모델이 local에 없는 경우 다운로드 받는다.\n",
    "\n",
    "### HuggingFace 모델을 사용하기 위한 package 설치\n",
    "```bash\n",
    "pip install langchain-huggingface transformers -qU\n",
    "```\n",
    "- nvidia GPU가 있는 경우 `torch cuda`  버전을 먼저 설치하고 `langchain-huggingface`를 설치 해야 한다. 아니면 `torch cpu` 버전이 설치된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a6c8929-6c61-4e85-95b9-40857fd6bff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m36 packages\u001b[0m \u001b[2min 293ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 26ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m5 packages\u001b[0m \u001b[2min 670ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-huggingface\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !uv pip install torch==2.8\n",
    "!uv pip install langchain-huggingface transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7562fc5a-6c5f-456b-aafd-ec8dbf9ef54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac58c38e699442b91df7e9f0236aa17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2972e5bed22a4f4baa6f6afe2f4a7a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"google/gemma-3-1b-it\"\n",
    "# pipe = pipeline(task=\"text-generation\", model=model_id)\n",
    "model = HuggingFacePipeline.from_model_id(\n",
    "    task=\"text-generation\",\n",
    "    model_id=model_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1601afa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Huggingface 를 소개해줘.\\n\\n**1. Hugging Face란?**\\n\\nHugging Face는 자연어 처리(NLP) 모델, 데이터셋, 그리고 관련 도구들을 제공하는 플랫폼입니다. 2016년에 설립된 이 회사는 인공지능 분야의 커뮤니티를 활성화하고, 모델 개발 및 배포를 용이하게 만드는 데 주력하고 있습니다.\\n\\n**2. 주요 기능 및 서비스**\\n\\n*   **Transformers 라이브러리:** 가장 인기 있는 라이브러리 중 하나로, 다양한 사전 훈련된 NLP 모델 (BERT, GPT, RoBERTa 등)을 제공합니다. 이를 통해 개발자는 쉽게 모델을 사용할 수 있으며, 파인튜닝을 통해 특정 작업에 최적화할 수 있습니다.\\n*   **Datasets:** 대규모 데이터셋을 쉽게 다운로드하고 활용할 수 있는 플랫폼입니다. 텍스트, 이미지, 오디오 등 다양한 데이터 형식을 지원하며, 데이터셋을 공유하고 협업할 수 있습니다.\\n*   **Spaces:** 모델을 웹사이트로 배포하고 공유할 수 있는 플랫폼입니다. 다른 사람들과 모델을 쉽게 공유하고, 테스트하고, 평가할 수 있습니다.\\n*   **Accelerate:** 여러 GPU 또는 TPU를 활용'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.invoke(\"Huggingface 를 소개해줘.\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19a83717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huggingface 를 소개해줘.\n",
      "\n",
      "**1. Hugging Face란?**\n",
      "\n",
      "Hugging Face는 자연어 처리(NLP) 모델, 데이터셋, 그리고 관련 도구들을 제공하는 플랫폼입니다. 2016년에 설립된 이 회사는 인공지능 분야의 커뮤니티를 활성화하고, 모델 개발 및 배포를 용이하게 만드는 데 주력하고 있습니다.\n",
      "\n",
      "**2. 주요 기능 및 서비스**\n",
      "\n",
      "*   **Transformers 라이브러리:** 가장 인기 있는 라이브러리 중 하나로, 다양한 사전 훈련된 NLP 모델 (BERT, GPT, RoBERTa 등)을 제공합니다. 이를 통해 개발자는 쉽게 모델을 사용할 수 있으며, 파인튜닝을 통해 특정 작업에 최적화할 수 있습니다.\n",
      "*   **Datasets:** 대규모 데이터셋을 쉽게 다운로드하고 활용할 수 있는 플랫폼입니다. 텍스트, 이미지, 오디오 등 다양한 데이터 형식을 지원하며, 데이터셋을 공유하고 협업할 수 있습니다.\n",
      "*   **Spaces:** 모델을 웹사이트로 배포하고 공유할 수 있는 플랫폼입니다. 다른 사람들과 모델을 쉽게 공유하고, 테스트하고, 평가할 수 있습니다.\n",
      "*   **Accelerate:** 여러 GPU 또는 TPU를 활용\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fdf4788",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = [\n",
    "    {\n",
    "        \"role\":\"user\", # 누가 말하는지.\n",
    "        \"content\":\"서울에 주요 여행지 3곳을 알려줘.\"\n",
    "    }\n",
    "]\n",
    "res = model.invoke(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7502ab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 서울에 주요 여행지 3곳을 알려줘.\n",
      "\n",
      "[ ]\n",
      "[ ]\n",
      "[ ]\n",
      "\n",
      "**정답:**\n",
      "\n",
      "*   **경복궁:** 한국의 대표적인 역사 유적지로, 아름다운 건축물과 정원을 자랑합니다.\n",
      "*   **북촌:** 전통적인 한옥 문화를 체험하고, 아름다운 골목길을 거닐 수 있습니다.\n",
      "*   **인사동:** 한국 전통 공예품, 기념품, 음식 등을 판매하는 상점들이 모여 있는 곳입니다.\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   이 외에도 서울에는 다양한 여행지가 많으니, 취향에 맞게 즐기시면 좋습니다.\n",
      "*   여행 전에 미리 정보를 확인하고, 안전에 유의하여 즐거운 여행 되세요.\n",
      "\n",
      "---\n",
      "\n",
      "**다음 질문에 대한 답변을 작성해주세요.**\n",
      "\n",
      "1.  경복궁과 북촌은 어떤 특징이 있나요?\n",
      "2.  인사동은 어떤 종류의 여행지를 제공하나요?\n",
      "3.  서울 여행을 계획할 때 어떤 점을 고려해야 할까요?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653f31b-82aa-462f-a140-545b5c57d485",
   "metadata": {},
   "source": [
    "# Anthropic의 Claude 모델 사용\n",
    "\n",
    "- Anthropic사의 Claude 모델은 (성능 순으로) **Haiku, Sonnet, Opus** 세가지 모델이 있다.  \n",
    "- [Anthropic사 사이트](https://www.anthropic.com/)\n",
    "- [Claude 서비스 사이트](https://claude.ai)\n",
    "- API 가격: https://docs.anthropic.com/en/docs/about-claude/pricing\n",
    "- Langchain으로 Anthropic claude 모델 사용: https://python.langchain.com/docs/integrations/chat/anthropic/\n",
    "\n",
    "## API Key 발급받기\n",
    "1. https://console.anthropic.com/ 이동 후 가입한다.\n",
    "2. 로그인 하면 Dashboard로 이동한다. Dashbord에서 `Get API Keys`를 클릭해 이동한다.\n",
    "\n",
    "![anthropic_apikey1.png](figures/anthropic_apikey1.png)\n",
    "\n",
    "1. Create key 클릭해서 API Key를 생성한다.\n",
    "\n",
    "2. 생성된 API Key를 복사한 뒤 저장. (다시 볼 수 없다.)\n",
    "   - 환경변수에 등록\n",
    "      - 변수이름: ANTHROPIC_API_KEY\n",
    "      - 값: 생성된 키\n",
    "\n",
    "## 결제 정보 등록 및 결제 (최소 $5)\n",
    "   - Settings -> Billing \n",
    "  \n",
    "![anthropic_apikey3.png](figures/anthropic_apikey3.png)\n",
    "  - 설문조사 후 카드 등록한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8174de-b6a1-423b-8cce-271917ae8dc6",
   "metadata": {},
   "source": [
    "## Anthropic의 Claude 모델 사용\n",
    "- 모델 확인: https://docs.anthropic.com/en/docs/about-claude/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8193ce-fa8b-4208-a7d9-af794044e61c",
   "metadata": {},
   "source": [
    "### Claude 모델 사용을 위한 package 설치\n",
    "\n",
    "```bash\n",
    "pip install langchain-anthropic -qU\n",
    "```\n",
    "- `anthropic`package도 같이 설치 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e3a23f-c491-4245-9013-83c5706fd4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m31 packages\u001b[0m \u001b[2min 395ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 325ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 100ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manthropic\u001b[0m\u001b[2m==0.75.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocstring-parser\u001b[0m\u001b[2m==0.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-anthropic\u001b[0m\u001b[2m==1.3.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install langchain-anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0298545f-64b9-41aa-a375-7296030bb108",
   "metadata": {},
   "source": [
    "### Langchain-antropic 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba755283-5d24-464d-8c81-21d496100256",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "\"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m model=\u001b[33m\"\u001b[39m\u001b[33mclaude-sonnet-4-5\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m llm = ChatAnthropic(\n\u001b[32m      6\u001b[39m     model=model,\n\u001b[32m      7\u001b[39m     temperature=\u001b[32m0.2\u001b[39m,\n\u001b[32m      8\u001b[39m     max_tokens=\u001b[32m1024\u001b[39m,\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m result = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAnthropic의 LLM 모델은 어떤 것이 있는지 알려주고 간단한 설명도 부탁해.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_anthropic\\chat_models.py:1319\u001b[39m, in \u001b[36mChatAnthropic._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1317\u001b[39m payload = \u001b[38;5;28mself\u001b[39m._get_request_payload(messages, stop=stop, **kwargs)\n\u001b[32m   1318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m anthropic.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1321\u001b[39m     _handle_anthropic_bad_request(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\langchain_anthropic\\chat_models.py:1175\u001b[39m, in \u001b[36mChatAnthropic._create\u001b[39m\u001b[34m(self, payload)\u001b[39m\n\u001b[32m   1173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m payload:\n\u001b[32m   1174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.beta.messages.create(**payload)\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\anthropic\\_utils\\_utils.py:282\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\anthropic\\resources\\messages\\messages.py:930\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[32m    924\u001b[39m     warnings.warn(\n\u001b[32m    925\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    926\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    927\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    928\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_sequences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:1326\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1314\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1321\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1322\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1323\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1324\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1325\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:1035\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1032\u001b[39m options = \u001b[38;5;28mself\u001b[39m._prepare_options(options)\n\u001b[32m   1034\u001b[39m remaining_retries = max_retries - retries_taken\n\u001b[32m-> \u001b[39m\u001b[32m1035\u001b[39m request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_request(request)\n\u001b[32m   1038\u001b[39m kwargs: HttpxSendArgs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:506\u001b[39m, in \u001b[36mBaseClient._build_request\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n\u001b[32m    503\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    504\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected JSON data type, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(json_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, cannot merge with `extra_body`\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m headers = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m params = _merge_mappings(\u001b[38;5;28mself\u001b[39m.default_query, options.params)\n\u001b[32m    508\u001b[39m content_type = headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:447\u001b[39m, in \u001b[36mBaseClient._build_headers\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n\u001b[32m    437\u001b[39m custom_headers = options.headers \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    438\u001b[39m headers_dict = _merge_mappings(\n\u001b[32m    439\u001b[39m     {\n\u001b[32m    440\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx-stainless-timeout\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(options.timeout.read)\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m     custom_headers,\n\u001b[32m    446\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[38;5;66;03m# headers are case-insensitive while dictionaries are not.\u001b[39;00m\n\u001b[32m    450\u001b[39m headers = httpx.Headers(headers_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\Documents\\SKN21_2\\SKN21\\10_langchain\\.venv\\Lib\\site-packages\\anthropic\\_client.py:200\u001b[39m, in \u001b[36mAnthropic._validate_headers\u001b[39m\u001b[34m(self, headers, custom_headers)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(custom_headers.get(\u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m), Omit):\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    201\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    202\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: \"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\""
     ]
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic# , Anthropic 지원하는 모델이 다른 것 같다.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "model=\"claude-sonnet-4-5\"\n",
    "llm = ChatAnthropic(\n",
    "    model=model,\n",
    "    temperature=0.2,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "result = llm.invoke(\"Anthropic의 LLM 모델은 어떤 것이 있는지 알려주고 간단한 설명도 부탁해.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb8db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161bc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1684d4b-a5f9-4e24-8263-b30d997833b0",
   "metadata": {},
   "source": [
    "# Ollama 모델 사용\n",
    "\n",
    "Ollama는 로컬 환경에서 오픈소스 LLM을 쉽게 실행할 수 있도록 지원하는 플랫폼이다.\n",
    "\n",
    "- 주요특징\n",
    "\n",
    "  - **다양한 모델 지원**: Llama 3, Mistral, Phi 3 등 여러 오픈소스 LLM을 지원.\n",
    "  - **편리한 모델 설치 및 실행**: 간단한 명령어로 모델을 다운로드하고 실행할 수 있습니다.\n",
    "  - **운영체제 호환성**: macOS, Windows, Linux 등 다양한 운영체제에서 사용 가능하다.\n",
    "\n",
    "## 설치\n",
    "- https://ollama.com/download 에서 운영체제에 맞는 버전을 설치\n",
    "-  Windows 버전은 특별한 설정 없이 바로 install 실행하면 된다.\n",
    "\n",
    "## 모델 검색\n",
    "- https://ollama.com/search\n",
    "- 모델을 검색한 후 상세페이지로 이동하면 해당 모델을 실행할 수있는 명령어가 나온다.\n",
    "\n",
    "![ollama_down.png](figures/ollama_down.png)\n",
    "\n",
    "\n",
    "## 실행 명령어\n",
    "- `ollama pull 모델명`\n",
    "  - 모델을 다운로드 받는다. (다운로드만 받고 실행은 하지 않은다.)\n",
    "- `ollama run 모델명`\n",
    "  - 모델을 실행한다. \n",
    "  - 최초 실행시 모델을 다운로드 받는다.\n",
    "  - 명령프롬프트 상에서 `프롬프트`를 입력하면 모델의 응답을 받을 수 있다.\n",
    "\n",
    "## Python/Langchain API\n",
    "- ollama api\n",
    "  - https://github.com/ollama/ollama-python\n",
    "- langchain-ollama\n",
    "  - https://python.langchain.com/docs/integrations/chat/ollama/\n",
    "- 설치\n",
    "  - `pip install langchain-ollama`\n",
    "  - `ollama` package도 같이 설치 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c2254-7dd3-48b1-9de4-d25e278a2266",
   "metadata": {},
   "source": [
    "## Langchain-ollama 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0410c58d-5d0d-42a8-a2d6-0dfa0f7772f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m27 packages\u001b[0m \u001b[2min 144ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 24ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 22ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-ollama\u001b[0m\u001b[2m==1.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mollama\u001b[0m\u001b[2m==0.6.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5b9d007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffd2dbcc-d3f6-4e30-86dd-f33db4f69a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"gemma3:1b\" # ollama run 하고 실행할 때 사용한 이름.\n",
    ")\n",
    "res = model.invoke(\"안녕하세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832b1cd0-e201-478f-85ae-f7ab40c778dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 안녕하세요. 무엇을 도와드릴까요? 😊 \n",
      "\n",
      "무엇을 궁금하거나 이야기하고 싶으신가요?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "366ffdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Two tailor girls are wandering around outside, appearing drowsy and aimless. It’s implied that the story is focusing on their isolated presence. The context suggests a possibly whimsical or atmospheric scene.', additional_kwargs={}, response_metadata={'model': 'gemma3:1b', 'created_at': '2025-12-16T00:48:22.9930419Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1787256900, 'load_duration': 730903300, 'prompt_eval_count': 52, 'prompt_eval_duration': 32972200, 'eval_count': 40, 'eval_duration': 1001122100, 'logprobs': None, 'model_name': 'gemma3:1b', 'model_provider': 'ollama'}, id='lc_run--019b24a1-2cd4-77a1-9f10-4f8453b0f98b-0', usage_metadata={'input_tokens': 52, 'output_tokens': 40, 'total_tokens': 92})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "다음 내용을 3문장으로 요약해줘.\n",
    "\n",
    "<요약할 내용>\n",
    "Two tailor park girls round the outside.\n",
    "Without me.\n",
    "Sleepy\n",
    "</요약할 내용>\n",
    "\"\"\"\n",
    "res = model.invoke(prompt)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b1d44",
   "metadata": {},
   "source": [
    "# Gemini\n",
    "- 모델: https://ai.google.dev/gemini-api/docs/models?hl=ko\n",
    "- 가격정책: https://ai.google.dev/gemini-api/docs/pricing?hl=ko\n",
    "\n",
    "## API Key 생성\n",
    "\n",
    "1. https://aistudio.google.com/api-keys\n",
    "    - 연결 후 로그인(구글계정)\n",
    "2. `API Key 만들기` 선택\n",
    "   \n",
    "    ![img](figures/gemini_api1.png)\n",
    "\n",
    "3. `키이름 지정`하고 `가져온 프로젝트 선택`에서 프로젝트 선택(없으면 만든다) 하고 키 만들기\n",
    "4. 키가 생성되면 왼쪽에 복사 아이콘을 클릭하면 키가 복사된다.\n",
    "\n",
    "## 환경변수\n",
    "- `GOOGLE_API_KEY` 환경변수에 생성된 API Key를 등록한다.\n",
    "## 설치\n",
    "- `pip install langchain_google_genai`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b2e8fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m36 packages\u001b[0m \u001b[2min 447ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m9 packages\u001b[0m \u001b[2min 305ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m9 packages\u001b[0m \u001b[2min 112ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcachetools\u001b[0m\u001b[2m==6.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfiletype\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-auth\u001b[0m\u001b[2m==2.43.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-genai\u001b[0m\u001b[2m==1.55.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-google-genai\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1\u001b[0m\u001b[2m==0.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1-modules\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrsa\u001b[0m\u001b[2m==4.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18500ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", # 무료: 분당 60회, 하루 1000회까지 무료\n",
    ")\n",
    "res = model.invoke(\"gemini와 gemma 모델의 차이는 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ecad9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini와 Gemma는 모두 Google이 개발한 AI 모델이지만, 목적, 규모, 접근성, 라이선스 등 여러 면에서 중요한 차이를 가집니다.\n",
      "\n",
      "다음 표는 두 모델의 주요 차이점을 요약합니다.\n",
      "\n",
      "| 구분                  | Gemini                                                                                                         | Gemma                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "| **목적 및 역할** | 구글의 최상위 AI 모델. 복합적인 기능을 종합적으로 제공하는 데 주력. | 특정 규모에서 최적화된 성능과 경량성을 강조. 연구자 및 개발자를 위한 모델. |\n",
      "| **규모 및 성능** | 매우 크고 강력한 멀티모달 모델. 텍스트, 코드, 이미지, 오디오 등 다양한 형태의 정보 처리 가능. GPT-4와 경쟁. | Gemini 모델의 연구에서 파생된 경량형 모델. 2B(20억), 7B(70억) 등 비교적 적은 파라미터로 다양한 디바이스에서 효율적으로 구동 가능. |\n",
      "| **모델 종류 및 아키텍처** | **비공개(Proprietary)** 모델. 구체적인 아키텍처와 학습 데이터는 공개되지 않음. | **개방형(Open Model)**. Apache 2.0 라이선스로 모델 가중치(weights)를 공개하여 상업적 및 연구용으로 사용 가능. |\n",
      "| **접근성 및 배포** | 주로 **클라우드 API(Google Cloud Vertex AI)** 또는 **Google 제품(Bard/Gemini Advanced)**을 통해 접근. 로컬 배포는 불가능. | 모델 가중치가 공개되어 **로컬 머신, 엣지 디바이스, 클라우드 환경** 등에서 직접 다운로드하여 배포 및 실행 가능. Hugging Face 등에서 쉽게 접근. |\n",
      "| **라이선스**      | **상업적 라이선스**. 구글의 서비스 약관에 따라 사용.                                                 | **Apache 2.0 라이선스**. 매우 관대한 오픈소스 라이선스로, 모델을 자유롭게 사용, 수정, 배포 가능 (일부 사용 제한은 존재).        |\n",
      "| **주요 사용 사례** | 고성능 AI 비서, 복잡한 문제 해결, 창의적 콘텐츠 생성, 멀티모달 이해 및 생성, 대규모 엔터프라이즈 AI 애플리케이션 개발. | 소규모/엣지 디바이스에서의 AI 배포, 특정 태스크에 대한 미세 조정(fine-tuning), 개인 개발자 및 연구자의 실험, 교육용, 비용 효율적인 AI 솔루션. |\n",
      "| **대상 사용자**   | 일반 사용자, 대기업 및 스타트업, 구글 클라우드 사용자, 최첨단 AI 기술을 활용하려는 개발자.                          | 개인 개발자, 연구자, 학계, 스타트업, 로컬 환경에서 AI 모델을 실행하거나 커스터마이징하려는 사용자.                                   |\n",
      "\n",
      "### 요약하자면:\n",
      "\n",
      "*   **Gemini**는 Google의 **플래그십(Flagship)이자 최첨단 범용 AI 모델**로, 가장 강력하고 다양한 기능을 제공하지만 클라우드 기반으로만 접근 가능하며 라이선스도 상업적입니다.\n",
      "*   **Gemma**는 Gemini의 연구를 기반으로 **'개방형'으로 출시된 경량형 모델 패밀리**입니다. 더 작고 효율적이며, 가중치가 공개되어 개발자와 연구자들이 자유롭게 다운로드하여 커스터마이징하고 로컬에 배포할 수 있도록 고안되었습니다.\n",
      "\n",
      "따라서 Gemini는 '구글의 모든 역량이 집약된 고성능 AI 서비스'에 가깝고, Gemma는 '구글의 AI 기술을 외부 개발자들이 활용하고 확장할 수 있도록 제공하는 도구'에 가깝다고 볼 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404e667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Gemini와 Gemma는 모두 Google에서 개발한 대규모 언어 모델(LLM)이지만, **목적, 규모, 기능, 그리고 접근 방식에서 중요한 차이점**을 가집니다. 쉽게 비유하자면, Gemini가 Google의 '주력 프리미엄 스마트폰'이라면, Gemma는 '그 스마트폰의 핵심 기술을 계승한 보급형/개발자용 부품 키트'에 가깝습니다.\n",
       "\n",
       "다음은 주요 차이점들을 비교한 것입니다.\n",
       "\n",
       "---\n",
       "\n",
       "### Gemini (제미니)\n",
       "\n",
       "*   **목적:** Google의 **가장 강력하고 최첨단**의 범용 인공지능 모델로, 인간 수준의 추론 능력과 다양한 인지 작업을 수행하는 것을 목표로 합니다.\n",
       "*   **규모 및 성능:** 매우 크고 강력하며, 다양한 작업에 걸쳐 최고 수준의 성능을 발휘합니다. (Ultra, Pro, Nano 등 다양한 크기로 제공되어 특정 환경에 최적화될 수 있습니다.)\n",
       "*   **모달리티:** 진정한 **멀티모달(Multimodal)** 모델입니다. 텍스트뿐만 아니라 이미지, 오디오, 비디오 등 다양한 형태의 정보를 이해하고 생성할 수 있습니다.\n",
       "*   **접근 방식 및 사용:**\n",
       "    *   주로 **API를 통해 서비스**됩니다 (Google Cloud Vertex AI).\n",
       "    *   Google의 제품(예: Gemini Advanced, Google Workspace, Google Pixel)에 직접 통합되어 사용됩니다.\n",
       "    *   일반 사용자가 모델 가중치(weights)를 직접 다운로드하여 로컬에서 실행하거나 커스터마이징하는 것은 불가능합니다. **폐쇄형(Proprietary)** 모델입니다.\n",
       "*   **오픈 소스 여부:** **아닙니다.** Google의 독점 기술이며, 내부적으로 개발 및 유지보수됩니다.\n",
       "*   **주요 대상:** 최신 AI 기술을 필요로 하는 기업, 개발자 (API 사용자), 그리고 Google 서비스 사용자.\n",
       "\n",
       "---\n",
       "\n",
       "### Gemma (젬마)\n",
       "\n",
       "*   **목적:** Gemini의 핵심 기술과 연구를 기반으로 \"책임감 있는 오픈 모델(responsible open models)\" 생태계를 확장하고, **개발자 및 연구자들이 Google의 최첨단 AI를 활용하여 혁신을 이룰 수 있도록** 돕는 것을 목표로 합니다.\n",
       "*   **규모 및 성능:** Gemini에 비해 **더 작고 경량화된 모델**입니다 (초기 2B, 7B 파라미터 모델). 이는 로컬 환경, 에지 디바이스 또는 리소스가 제한된 환경에서 실행하기에 적합합니다. 물론 성능도 매우 뛰어나지만 Gemini Ultra와 같은 최상위 모델만큼은 아닙니다.\n",
       "*   **모달리티:** 주로 **텍스트 기반** 모델입니다. 강력한 텍스트 생성, 코드 생성, 번역 등의 기능을 제공합니다. (미래에는 멀티모달 기능이 추가될 가능성도 있습니다.)\n",
       "*   **접근 방식 및 사용:**\n",
       "    *   **모델 가중치(weights)가 공개**되어 개발자 및 연구자들이 직접 다운로드하여 사용할 수 있습니다 (Hugging Face, Google AI Studio, Kaggle 등).\n",
       "    *   로컬에서 모델을 실행하거나, 필요에 따라 **미세 조정(fine-tuning)**하여 특정 작업에 최적화할 수 있습니다.\n",
       "    *   상업적 및 연구 목적으로 자유롭게 사용할 수 있습니다.\n",
       "*   **오픈 소스 여부:** **\"책임감 있는 오픈 모델\"**로 분류됩니다. 이는 모델 가중치 및 코드의 상당 부분이 공개되어 있지만, 완전히 개방된 오픈 소스 라이선스(예: Apache 2.0)와는 약간 다를 수 있습니다. (사용 조건은 라이선스를 확인해야 합니다.)\n",
       "*   **주요 대상:** AI 연구자, 로컬 또는 온디바이스 AI 애플리케이션 개발자, 특정 도메인에 맞게 AI 모델을 커스터마이징하려는 개발자.\n",
       "\n",
       "---\n",
       "\n",
       "### 요약 비교 테이블\n",
       "\n",
       "| 특징         | Gemini (제미니)                                   | Gemma (젬마)                                             |\n",
       "| :----------- | :------------------------------------------------ | :------------------------------------------------------- |\n",
       "| **목적**     | 최첨단 범용 AI, 복잡한 문제 해결, Google 제품 통합 | 오픈 모델 생태계 확장, 개발자/연구원 활용 및 커스터마이징 |\n",
       "| **규모**     | 매우 크고 강력 (Ultra, Pro, Nano)                 | 상대적으로 작고 경량화 (2B, 7B)                          |\n",
       "| **모달리티** | 진정한 멀티모달 (텍스트, 이미지, 오디오, 비디오)  | 주로 텍스트 기반                                         |\n",
       "| **접근/사용** | API를 통한 서비스, Google 제품 통합, 폐쇄형       | 모델 가중치 공개, 다운로드/로컬 실행/미세 조정 가능      |\n",
       "| **오픈 소스** | 독점, 폐쇄형                                      | \"책임감 있는 오픈 모델\" (모델 가중치 공개)               |\n",
       "| **대상**     | 기업, API 개발자, Google 서비스 사용자            | AI 연구자, 온디바이스/로컬 AI 개발자, 커스터마이징 개발자 |\n",
       "\n",
       "---\n",
       "\n",
       "**결론적으로,** Gemini는 Google의 최상위 AI 기술력을 집약한 프리미엄 모델로, Google의 생태계 내에서 다양한 기능을 제공하는 반면, Gemma는 그 기술의 일부를 대중에게 \"오픈\"하여 더 많은 개발자와 연구자들이 AI 기술을 직접 활용하고 발전시킬 수 있도록 돕는 역할을 합니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown # 주피터 노트북 기능\n",
    "\n",
    "Markdown(res.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
