{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-in Dataset\n",
    "\n",
    "-   파이토치는 분야별 공개 데이터셋을 종류별로 torchvision, torchtext, torchaudio 모듈을 통해 제공한다.\n",
    "-   모든 built-in dataset은 [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)의 하위클래스로 구현되있다.\n",
    "    -   [computer vision dataset](https://pytorch.org/vision/stable/datasets.html)\n",
    "    -   [audio dataset](https://pytorch.org/audio/stable/datasets.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Built-in dataset Loading\n",
    "\n",
    "torchvision 모듈을 통해 다양한 오픈소스 이미지 데이터셋을 loading할 수 있는 Dataset 클래스를 제공한다.\n",
    "\n",
    "-   각 Dataset 클래스의 주요 매개변수 (클래스들 마다 약간의 차이가 있다.)\n",
    "    -   **root**: str\n",
    "        -   Raw data를 저장할 디렉토리 경로\n",
    "    -   **train**: bool\n",
    "        -   True일경우 Train set을 False일 경우 Test set을 load\n",
    "    -   **download**: bool\n",
    "        -   True이면 root에 지정된 경로에 raw 데이터를 인터셋에서 download할지 여부. 이미 저장되 있는 경우 download하지 않는다.\n",
    "    -   **transform**: function\n",
    "        -   Loading한 이미지를 변환하는 function.\n",
    "            -   Normalization이나 data Agumentation 처리를 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "mnist_data_dir = \"datasets/MNIST\"\n",
    "mnist_data_dir = r\"c:/temp\"\n",
    "mnist_trainset = datasets.MNIST(\n",
    "    root=mnist_data_dir, # raw data의 위치.\n",
    "    download=True,       # root에 지정한 경로에 없을 경우 다운받을지 여부\n",
    "    train=True,          # True: train set, False: test set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: datasets/MNIST\n",
       "    Split: Train"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(mnist_trainset, Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset의 총 데이터개수를 조회 - len()\n",
    "len(mnist_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28>, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 데이터를 조회 -> indexing\n",
    "mnist_trainset[0]  # 개별데이터는 x(input)과 y(output)로 구성되어 tuple(x,  y)로 반환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAklEQVR4AWIY1IBZSEiormO91LL/3+tBDmUBESAsx2ZlIxAMYj2ZFPj54kEQixFEMDAwGO7lh7L+JX1lePb+JpQHBkK3/4LAsW3fP4L5qETAnOy/f89yM2jPQhWHAD7GWX+jIEwYyQRjMHz6/5EhBcGFi0MB976/blAmFkr548MFOTD3Y8gHfvj7t1wSQxgKdHf9/TtNGsrBoARi//zdjSEKBz///nSAcuBhC+HrhZiyMFw7BOGgkoCpT3n69+/fX9tQRcE8iaK7oOA96QfmoRDiTldBUscCMQNJaDU4Vg4HcKLoAHHM1zwC6frSyg3iITDYtYGBDAzXN//t+YAQpyULAEUXXoDz1Y8qAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 데이터 조회\n",
    "x0 = mnist_trainset[0]\n",
    "\n",
    "# 첫번째 데이터 이미지 확인\n",
    "x0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 데이터 label 확인\n",
    "x0[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0 - zero': 0,\n",
       " '1 - one': 1,\n",
       " '2 - two': 2,\n",
       " '3 - three': 3,\n",
       " '4 - four': 4,\n",
       " '5 - five': 5,\n",
       " '6 - six': 6,\n",
       " '7 - seven': 7,\n",
       " '8 - eight': 8,\n",
       " '9 - nine': 9}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################################\n",
    "# Target class 값 조회\n",
    "######################################################################\n",
    "# class index(id) - class name\n",
    "## class index(class id): 인코딩 된 label의 클래스, \n",
    "## class name: 실제 class의 이름.\n",
    "### 0-setosa 의 경우 0: class index, setosa: class name\n",
    "\n",
    "mnist_trainset.class_to_idx\n",
    "# dict: key-class name, value: class index\n",
    "# class name으로 class index를 조회할 수있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset.class_to_idx['2 - two']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 - zero',\n",
       " '1 - one',\n",
       " '2 - two',\n",
       " '3 - three',\n",
       " '4 - four',\n",
       " '5 - five',\n",
       " '6 - six',\n",
       " '7 - seven',\n",
       " '8 - eight',\n",
       " '9 - nine']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset.classes \n",
    "# list: index-class index, value-class name\n",
    "# class index로 class 이름을 조회할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8 - eight'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset.classes[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset의 transform 매개변수를 이용한 데이터 전처리\n",
    "\n",
    "- Dataset을 생성할 때, **원본 데이터를 제공하기 전 수행할 전처리 과정**을 함수(callable) 형태로 정의한다.\n",
    "- 이 함수(callable)는 **입력 데이터 하나**를 매개변수로 받아, 전처리된 결과를 반환하도록 구현한다.\n",
    "- transform 매개변수에는 데이터 파이프라인을 구성하는 함수나 callable 객체를 설정한다.\n",
    "\n",
    "### torchvision에서 제공하는 주요 transform\n",
    "\n",
    "- `torchvision.transforms.ToTensor`\n",
    "  - PIL 이미지(PIL Image)나 넘파이 배열(NumPy ndarray)을 FloatTensor(float32 Tensor)로 변환한다.\n",
    "  - 이미지 픽셀의 값(intensity)을 \\[0., 1.\\] 범위로 비례 조정한다.\n",
    "  - 이미지의 형태(shape)를 (채널, 높이, 너비) 순서로 변경한다.\n",
    "  - 자세한 내용은 [torchvision transforms 공식 문서](https://pytorch.org/vision/stable/transforms.html) 참고.\n",
    "\n",
    "- `torchvision.transforms.Normalize`\n",
    "  - 각 채널별로 지정된 평균(mean)을 빼고, 표준편차(standard deviation)로 나누어 정규화(normalization)를 수행한다.\n",
    "  - `ToTensor()`로 변환된 데이터를 입력받아 추가 변환을 적용한다.\n",
    "\n",
    "- `torchvision.transforms.Compose`\n",
    "  - 여러 변환을 순차적으로 적용하고 싶을 때, `Compose` 클래스를 사용해 변환들을 하나로 묶는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset2 = datasets.MNIST(\n",
    "    root=mnist_data_dir, \n",
    "    download=True,       \n",
    "    train=True,\n",
    "    transform=transforms.ToTensor()  # 전처리 callable 전달.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_2 = mnist_trainset2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "tensor(0.) tensor(1.)\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# ToTensor()의 전처리 작업.\n",
    "print(x0_2[0].type())  # PIL.Image, np.ndarray -> pytorch Tensor 로 변환\n",
    "print(x0_2[0].min(), x0_2[0].max()) # 0 ~ 1 사이로 scaling. (MinMaxScaling)\n",
    "print(x0_2[0].shape) # channel first 로 shape을 변경. (channel, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToTensor() -> Normalize()\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=0.5, std=0.5)  # 모든 채널에 동일한 값을 적용: 상수., 채널별로 다른 값 적용: 리스트.\n",
    "])\n",
    "\n",
    "mnist_trainset3 = datasets.MNIST(\n",
    "    root=mnist_data_dir, \n",
    "    download=True,       \n",
    "    train=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method type of Tensor object at 0x0000017D3D7B0500> tensor(-1.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "x_3 = mnist_trainset3[0][0]\n",
    "print(x_3[0].type, x_3[0].min(), x_3[0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: CIFAR10 Dataset loading\n",
    "- `datasets.CIFAR10` 이용\n",
    "-   CIFAR10 Built-in dataset 을 LOADING 후 다음을 확인하시오.\n",
    "    1. Dataset loading\n",
    "    1. train dataset, test dataset의 데이터 개수 확인\n",
    "    1. class index - class name 확인\n",
    "    1. train set의 이미지 5장을 출력. label의 이름을 title로 출력.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_data_dir = \"datasets/CIFAR10\"\n",
    "cifar10_data_dir = r\"c:/temp2\"\n",
    "cifar10_trainset = datasets.CIFAR10(\n",
    "    root=cifar10_data_dir, # raw data의 위치.\n",
    "    download=True,       # root에 지정한 경로에 없을 경우 다운받을지 여부\n",
    "    train=True,          # True: train set, False: test set\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.2314, 0.1686, 0.1961,  ..., 0.6196, 0.5961, 0.5804],\n",
       "          [0.0627, 0.0000, 0.0706,  ..., 0.4824, 0.4667, 0.4784],\n",
       "          [0.0980, 0.0627, 0.1922,  ..., 0.4627, 0.4706, 0.4275],\n",
       "          ...,\n",
       "          [0.8157, 0.7882, 0.7765,  ..., 0.6275, 0.2196, 0.2078],\n",
       "          [0.7059, 0.6784, 0.7294,  ..., 0.7216, 0.3804, 0.3255],\n",
       "          [0.6941, 0.6588, 0.7020,  ..., 0.8471, 0.5922, 0.4824]],\n",
       " \n",
       "         [[0.2431, 0.1804, 0.1882,  ..., 0.5176, 0.4902, 0.4863],\n",
       "          [0.0784, 0.0000, 0.0314,  ..., 0.3451, 0.3255, 0.3412],\n",
       "          [0.0941, 0.0275, 0.1059,  ..., 0.3294, 0.3294, 0.2863],\n",
       "          ...,\n",
       "          [0.6667, 0.6000, 0.6314,  ..., 0.5216, 0.1216, 0.1333],\n",
       "          [0.5451, 0.4824, 0.5647,  ..., 0.5804, 0.2431, 0.2078],\n",
       "          [0.5647, 0.5059, 0.5569,  ..., 0.7216, 0.4627, 0.3608]],\n",
       " \n",
       "         [[0.2471, 0.1765, 0.1686,  ..., 0.4235, 0.4000, 0.4039],\n",
       "          [0.0784, 0.0000, 0.0000,  ..., 0.2157, 0.1961, 0.2235],\n",
       "          [0.0824, 0.0000, 0.0314,  ..., 0.1961, 0.1961, 0.1647],\n",
       "          ...,\n",
       "          [0.3765, 0.1333, 0.1020,  ..., 0.2745, 0.0275, 0.0784],\n",
       "          [0.3765, 0.1647, 0.1176,  ..., 0.3686, 0.1333, 0.1333],\n",
       "          [0.4549, 0.3686, 0.3412,  ..., 0.5490, 0.3294, 0.2824]]]),\n",
       " 6)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_trainset[0]\n",
    "# for i in range(5):\n",
    "#     cifar10_trainset[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cifar10_trainset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cifar10_trainset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32) float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_21396\\2500860097.py:3: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  a = np.array(cifar10_trainset[0][0])  # PIL.Image -변환-> ndarray\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "a = np.array(cifar10_trainset[0][0])  # PIL.Image -변환-> ndarray\n",
    "print(a.shape, a.dtype) # image shape (height, width). uint8(부호없는 int - 0 ~ 255)\n",
    "a.min(), a.max() #a\n",
    "\n",
    "tensor_PIL = transforms.ToPILImage()\n",
    "image = tensor_PIL(cifar10_trainset[0][0])\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: c:/temp2\n",
       "    Split: Train"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(cifar10_trainset, Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=32x32>, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_testset = datasets.CIFAR10(\n",
    "    root=cifar10_data_dir, # raw data의 위치.\n",
    "    download=True,       # root에 지정한 경로에 없을 경우 다운받을지 여부\n",
    "    train=False,          # True: train set, False: test set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: c:/temp2\n",
       "    Split: Test"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_trainset.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader 생성\n",
    "\n",
    "-   DataLoader\n",
    "    -   모델이 학습하거나 추론할 때 Dataset의 데이터를 batch size 개수단위로 모아서 모델에 제공한다.\n",
    "    -   initalizer속성\n",
    "        -   dataset: 값을 제공하는 Dataset 타입 객체\n",
    "        -   batch_size: 한번에 값을 제공할 batch 크기\n",
    "        -   shuffle: 에폭마다 데이터셋을 섞을 지 여부 (default: False)\n",
    "        -   drop_last: 마지막 배치의 데이터개수가 batch_size 설정보다 적을 경우 제공할 지 여부(False-기본값, 제공한다. True: 제공하지 않는다.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "mnist_train_loader = DataLoader(mnist_trainset2, batch_size=1000, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 수 조회\n",
    "len(mnist_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset 구현\n",
    "\n",
    "사용자가 보유한 데이터를 이용하여 커스텀 Dataset을 생성할 수 있다.\n",
    "\n",
    "## 구현 방법\n",
    "1. `torch.utils.data.Dataset` 클래스를 상속하는 새로운 클래스를 정의한다.\n",
    "\n",
    "2. `__init__(self, ...)`\n",
    "   - Dataset 객체 생성 시 필요한 설정을 초기화한다.\n",
    "   - 예를 들어, 데이터 저장 경로, transform 설정 여부 등을 초기화한다.\n",
    "\n",
    "3. `__len__(self)`\n",
    "   - 전체 데이터의 개수를 반환하도록 구현한다.\n",
    "   - DataLoader가 배치를 생성할 때 이 정보를 사용한다.\n",
    "\n",
    "4. `__getitem__(self, index)`\n",
    "   - index에 해당하는 데이터 포인트를 반환한다.\n",
    "   - 입력(input, X)과 출력(output, y)을 튜플 형태로 반환한다.\n",
    "   - transform이 설정되어 있을 경우, 변환된 입력 데이터를 반환한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MyDataSet:\n",
    "    def __init__(self):\n",
    "        self.x_data = torch.FloatTensor([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5]])\n",
    "        self.y_data = torch.FloatTensor([[2], [4], [6], [8], [10]])\n",
    "        self.len = self.x_data.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "\n",
    "my_dataset = MyDataSet()\n",
    "len(my_dataset)  # 데이터셋의 총 데이터 개수 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset2:\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x_data = x\n",
    "        self.y_data = y\n",
    "        self.len = self.x_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5]])\n",
    "y = torch.FloatTensor([[2], [4], [6], [8], [10]])\n",
    "\n",
    "my_dataset2 = MyDataset2(X, y)\n",
    "print(len(my_dataset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 생성\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(my_dataset2, batch_size=2, shuffle=True, drop_last=True)\n",
    "\n",
    "for data in dataloader:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메모리상의 Tensor, ndarray 타입의 데이터를 이용해 Dataset생성\n",
    "이미 loading된 데이터셋을 Dataset으로 생성\n",
    "-   torch.utils.data.TensorDataset 이용\n",
    "-   parameter\n",
    "    -   input: Tensor\n",
    "    -   output: Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iris = pd.read_csv(\"data/iris.data\", \n",
    "                   header=None, \n",
    "                   names=[\"sepal length\", \"sepal width\", \"petal lenth\", \"petal width\", \"label\"])\n",
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop(columns='label').values\n",
    "y = iris['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y값을 label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y_le = LabelEncoder()\n",
    "y = y_le.fit_transform(y)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test set 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "# (X, y) : X/y는 Tensor 타입\n",
    "trainset = TensorDataset(\n",
    "    torch.tensor(X_train), # input\n",
    "    torch.tensor(y_train), # output\n",
    ")\n",
    "testset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 성능 평가를 위한 데이터셋 분리\n",
    "\n",
    "-   **Train 데이터셋 (훈련/학습 데이터셋)**\n",
    "    -   모델을 학습시킬 때 사용할 데이터셋.\n",
    "-   **Validation 데이터셋 (검증 데이터셋)**\n",
    "    -   모델의 성능 중간 검증을 위한 데이터셋\n",
    "-   **Test 데이터셋 (평가 데이터셋)**\n",
    "    -   모델의 성능을 최종적으로 측정하기 위한 데이터셋\n",
    "    -   **Test 데이터셋은 마지막에 모델의 성능을 측정하는 용도로 한번만 사용한다.**\n",
    "\n",
    "## 검증(validation), 평가(test) 데이터셋을 나누는 이유\n",
    "\n",
    "-   모델을 훈련하고 성능 검증했을 때 원하는 성능이 나오지 않으면 모델의 여러 설정(하이퍼파라미터)들을 수정한 뒤에 다시 훈련시키고 검증을 하게 된다. 그리고 원하는 성능이 나올때 까지 설정변경->훈련->검증을 반복하게 된다. 이 작업이 **모델링(Modeling)** 이다.\n",
    "-   위 사이클을 반복하게 되면 검증 결과를 바탕으로 설정을 변경하게 되므로 검증 할 때 사용한 데이터셋(Test set)에 모델이 맞춰서 훈련하는 것과 동일한 효과를 내게 된다.(설정을 변경하는 이유가 Test set에 대한 결과를 좋게 만들기 위해 변경하므로) 그래서 Train dataset과 Test dataset 두 개의 데이터셋만 사용하게 되면 **모델의 성능을 제대로 평가할 수 없게 된다.** 그래서 데이터셋을 train set, validation set, test set으로 나눠 train set 와 validation set을 사용해 훈련과 검증을 해 모델을 최적화 한 뒤 마지막에 test set으로 최종 평가를 한다.\n",
    "\n",
    "> -   **(Parameter)머신러닝 모델 파라미터**\n",
    ">     -   성능에 영향을 주는 값으로 최적화의야 하는 대상내는 값을 찾아야 한다.\n",
    ">         -   **하이퍼파라미터(Hyper Parameter)**\n",
    ">             -   사람이 직접 설정해야하는 파라미터 값으로 주로 어떻게 모델을 학습시킬지에 대한 모델설정 값이다.\n",
    ">             -   딥러닝에서는 학습률, Epoch수, batch size, optimizer, loss 함수 등 다양한 하이퍼파라미터가 있다.\n",
    ">         -   **파라미터(Parameter)**\n",
    ">             -   모델의 함수를 데이터에 맞추기 위한 값으로 학습을 통해 찾는 변수.\n",
    ">             -   딥러닝 모델에서는 weight와 bias 가 파라미터다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 분리\n",
    "\n",
    "### torch.utils.data.Subset을 이용\n",
    "\n",
    "-   Dataset의 일부를 가지는 부분집합 데이터셋을 생성\n",
    "-   주로 사용하는 곳\n",
    "    1. 데이터 셋을 분리\n",
    "    2. 전체 데이터 셋에서 일부 데이터를 추출 할 때\n",
    "    3. 데이터셋에서 특정 데이터만 골라서 추출할 때 (ex: 특정 class만 추출하는 경우)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.arange(1, 11).reshape(5, 2)\n",
    "outputs = torch.arange(5).reshape(5, 1)\n",
    "inputs.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(inputs, outputs)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset의 5개중에 3개를 골라서 Subset 생성.\n",
    "sub1 = Subset(dataset, [1, 2, 4])   # (가져올Dataset, 가져올 index들)\n",
    "sub2 = Subset(dataset, [0, 3])\n",
    "len(sub1), len(sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sub1:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sub2:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "trainset = datasets.MNIST(\"datasets\", train=True, download=True)\n",
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_index = torch.randperm(len(trainset)) # 0 ~ 지정한정수: 섞어서 반환.\n",
    "train_index = all_index[:50000]  # 50000, 10000\n",
    "valid_index = all_index[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_trainset2 = Subset(trainset, train_index)\n",
    "m_valid2 = Subset(trainset, valid_index)\n",
    "len(m_trainset2), len(m_valid2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random_split() 함수 이용\n",
    "\n",
    "-   Dataset객체와 나눌 데이터셋들의 원소 개수를 리스트로 묶어서 전달하면 Shuffle후 나눈 뒤 그 결과를 Subset객체들을 리스트에 담아 반환한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "sub1, sub2, sub3 = random_split(\n",
    "     trainset, # 나눌대상  Dataset\n",
    "     [40000, 10000, 10000], # [몇개씩으로 나눌지 개수]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sub1), len(sub2), len(sub3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "455.111px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
