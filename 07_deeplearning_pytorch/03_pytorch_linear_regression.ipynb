{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LinearRegression from Scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구현할 것\n",
    "- 공부시간과 성적간의 관계를 모델링한다.\n",
    "    - **머신러닝 모델(모형)이란** 수집한 데이터를 기반으로 입력값(Feature)와 출력값(Target)간의 관계를 하나의 공식으로 정의한 함수이다. 그 공식을 찾는 과정을 **모델링**이라고 한다.\n",
    "    - 이 예제에서는 공부한 시험시간으로 점수를 예측하는 모델을 정의한다.\n",
    "    - 입력값과 출력값 간의 관계를 정의할 수있는 다양한 함수(공식)이 있다. 여기에서는 딥러닝과 관계가 있는 **Linear Regression** 을 사용해본다.\n",
    "\n",
    "# 데이터 확인\n",
    "- 입력데이터: 공부시간\n",
    "- 출력데이터: 성적\n",
    "\n",
    "|공부시간|점수|\n",
    "|-|-|\n",
    "|1|20|\n",
    "|2|40|\n",
    "|3|60|\n",
    "\n",
    "우리가 수집한 공부시간과 점수 데이터를 바탕으로 둘 간의 관계를 식으로 정의 할 수 있으면 **내가 몇시간 공부하면 점수를 얼마 받을 수 있는지 예측할 수 있게 된다.**   \n",
    "수집한 데이터를 기반으로 앞으로 예측할 수있는 모형을 만드는 것이 머신러닝 모델링이다.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습(훈련) 데이터셋 만들기\n",
    "- 모델을 학습시키기 위한 데이터셋을 구성한다.\n",
    "- 입력데이터와 출력데이터을 각각 다른 행렬로 구성한다.\n",
    "- 하나의 데이터 포인트의 입력/출력 값은 같은 index에 정의한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형회귀 (Linear Regression)\n",
    "- Feature들의 가중합을 이용해 Target을 추정한다.\n",
    "- Feature에 곱해지는 가중치(weight)들은 각 Feature가 Target 얼마나 영향을 주는지 영향도가 된다.\n",
    "    - 음수일 경우는 target값을 줄이고 양수일 경우는 target값을 늘린다.\n",
    "    - 가중치가 0에 가까울 수록 target에 영향을 주지 않는 feature이고 0에서 멀수록 target에 많은 영향을 준다.\n",
    "- 모델 학습과정에서 가장 적절한 Feature의 가중치를 찾아야 한다.\n",
    "      \n",
    "\n",
    "\\begin{align}\n",
    "&\\large \\hat{y} = W\\cdot X + b\\\\\n",
    "&\\small \\hat{y}: \\text{모델추정값}\\\\\n",
    "&\\small W: \\text{가중치}\\\\\n",
    "&\\small X: \\text{Feature(입력값)}\\\\\n",
    "&\\small b: \\text{bias(편향)}\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train dataset 구성\n",
    "- Train data는 feature(input)와 target(output) 각각 2개의 행렬로 구성한다.\n",
    "- Feature의 행은 관측치(개별 데이터)를 열을 Feature(특성, 변수)를 표현한다. 이 문제에서는 `공부시간` 1개의 변수를 가진다.\n",
    "- Target은 모델이 예측할 대상으로 행은 개별 관측치, 열은 각 항목에 대한 정답으로 구성한다.   \n",
    "  이 문제에서 예측할 항목은 `시험점수` 한개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X_train = torch.tensor([[1], [2], [3]], dtype=torch.float32)    # 공부시간\n",
    "y_train = torch.tensor([[20], [40], [60]], dtype=torch.float32) # 시험점수\n",
    "X_train.size(), y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUninstalled \u001b[1m2 packages\u001b[0m \u001b[2min 2.07s\u001b[0m\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip uninstall torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m13 packages\u001b[0m \u001b[2min 65ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 2.61s\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.23.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install torch==2.8 torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =[1,2,3]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파라미터 (weight, bias) 정의\n",
    "- 학습대상/최적화 대상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1]) torch.Size([1])\n",
      "tensor([[0.0168]], requires_grad=True)\n",
      "tensor([0.5387], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "weight = torch.randn(1, 1, requires_grad=True) # feature에 곱할 값. \n",
    "# 1 : (가중치) 위에서 feature가 한개이므로 숫자 1로 지정.\n",
    "# 1 : 숫자 1로 지정\n",
    "# 1 : 입력 feature 갯수,  1 : 출력값(예측 결과)의 갯수\n",
    "bias = torch.randn(1, requires_grad=True)\n",
    "print(weight.size(), bias.size())\n",
    "print(weight)\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#추론\n",
    "pred = X_train @ weight + bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.],\n",
       "        [40.],\n",
       "        [60.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1776.5629], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 오차계산\n",
    "loss = torch.mean((y_train - pred) ** 2, dim=0)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient 계산 -> loss에 대한 weight, bias의 순간변화율(gradient) 를 계산.\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-182.1032]]), tensor([-77.8756]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.grad, bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m lr = \u001b[32m0.1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m weight.data = \u001b[43mweight\u001b[49m.data - weight.grad * lr\n\u001b[32m      3\u001b[39m weight.data\n",
      "\u001b[31mNameError\u001b[39m: name 'weight' is not defined"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "weight.data = weight.data - weight.grad * lr\n",
    "weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.3777])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.data = bias.data - bias.grad * lr\n",
    "bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "weight = torch.randn(1, 1, requires_grad=True)\n",
    "bias = torch.randn(1, requires_grad=True)\n",
    "\n",
    "# 추론 모델\n",
    "def linear_model(X):\n",
    "    return X @ weight + bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss(오차) 계산 함수\n",
    "def mse_loss_fn(pred, y):\n",
    "    return torch.mean((y-pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습\n",
    "1. 모델을 이용해 추정한다.\n",
    "   - pred = model(input)\n",
    "1. loss를 계산한다.\n",
    "   - loss = loss_fn(pred, target)\n",
    "1. 계산된 loss를 파라미터에 대해 미분하여 계산한 gradient 값을 각 파라미터에 저장한다.\n",
    "   - loss.backward()\n",
    "1. optimizer를 이용해 파라미터를 update한다.\n",
    "   - optimizer.step()  \n",
    "1. 파라미터의 gradient(미분값)을 0으로 초기화한다.\n",
    "   - optimizer.zero_grad()\n",
    "- 위의 단계를 반복한다.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 1~4 : 1 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/2000] - loss: 1596.5850\n",
      "[100/2000] - loss: 5.0854\n",
      "[200/2000] - loss: 3.1425\n",
      "[300/2000] - loss: 1.9418\n",
      "[400/2000] - loss: 1.1999\n",
      "[500/2000] - loss: 0.7415\n",
      "[600/2000] - loss: 0.4582\n",
      "[700/2000] - loss: 0.2831\n",
      "[800/2000] - loss: 0.1750\n",
      "[900/2000] - loss: 0.1081\n",
      "[1000/2000] - loss: 0.0668\n",
      "[1100/2000] - loss: 0.0413\n",
      "[1200/2000] - loss: 0.0255\n",
      "[1300/2000] - loss: 0.0158\n",
      "[1400/2000] - loss: 0.0097\n",
      "[1500/2000] - loss: 0.0060\n",
      "[1600/2000] - loss: 0.0037\n",
      "[1700/2000] - loss: 0.0023\n",
      "[1800/2000] - loss: 0.0014\n",
      "[1900/2000] - loss: 0.0009\n",
      "last: tensor([[-0.0065]]) tensor([0.0148])\n",
      "[1999/2000] - loss: 0.0005\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000 # train set을 몇번 학습(파라미터 업데이트)시킬지.\n",
    "lr = 0.01 #learning rate\n",
    "for epoch in range(epochs):\n",
    "    #1. 추론(예측)\n",
    "    pred = linear_model(X_train)\n",
    "    #2.오차계산\n",
    "    loss = mse_loss_fn(pred, y_train)\n",
    "    #3. 파라미터들(weight, bias)에 대한 gradient 계산\n",
    "    loss.backward()\n",
    "    #4. 파라미터 업데이트\n",
    "    weight.data = weight.data - lr * weight.grad\n",
    "    bias.data = bias.data - lr * bias.grad\n",
    "    if epoch == epochs-1:\n",
    "        print(\"last:\", weight.grad, bias.grad)\n",
    "    #5. gradient 초기화\n",
    "    weight.grad = None\n",
    "    bias.grad = None\n",
    "    # 100 epoch마다 loss를 출력\n",
    "    if epoch % 100 == 0 or epoch == epochs-1:\n",
    "        print(f\"[{epoch}/{epochs}] - loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[19.9707]]), tensor([0.0666]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.data, bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 99.9262],\n",
      "        [139.8721]])\n"
     ]
    }
   ],
   "source": [
    "# 추론\n",
    "# gradient 함수를 구하지 않는다.\n",
    "with torch.no_grad():\n",
    "    new_X = torch.tensor([[5], [7]], dtype=torch.float32)\n",
    "    pred = linear_model(new_X)\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중 입력, 다중 출력\n",
    "- 다중입력: Feature가 여러개인 경우\n",
    "- 다중출력: Output 결과가 여러개인 경우\n",
    "\n",
    "다음 가상 데이터를 이용해 사과와 오렌지 수확량을 예측하는 선형회귀 모델을 정의한다.  \n",
    "[참조](https://www.kaggle.com/code/aakashns/pytorch-basics-linear-regression-from-scratch)\n",
    "\n",
    "\n",
    "|온도(F)|강수량(mm)|습도(%)|사과생산량(ton)|오렌지생산량|\n",
    "|-|-|-|-:|-:|\n",
    "|73|67|43|56|70|\n",
    "|91|88|64|81|101|\n",
    "|87|134|58|119|133|\n",
    "|102|43|37|22|37|\n",
    "|69|96|70|103|119|\n",
    "\n",
    "```\n",
    "사과수확량  = w11 * 온도 + w12 * 강수량 + w13 * 습도 + b1\n",
    "오렌지수확량 = w21 * 온도 + w22 * 강수량 + w23 *습도 + b2\n",
    "```\n",
    "\n",
    "- `온도`, `강수량`, `습도` 값이 **사과**와, **오렌지 수확량**에 어느정도 영향을 주는지 가중치를 찾는다.\n",
    "    - 모델은 사과의 수확량, 오렌지의 수확량 **두개의 예측결과를 출력**해야 한다.\n",
    "    - 사과에 대해 예측하기 위한 weight 3개와 오렌지에 대해 예측하기 위한 weight 3개 이렇게 두 묶음, 총 6개의 weight를 정의하고 학습을 통해 가장 적당한 값을 찾는다.\n",
    "        - `개별 과일를 예측하기 위한 weight들 @ feature들` 의 계산 결과를  **Node, Unit, Neuron** 이라고 한다.\n",
    "        - 두 과일에 대한 Unit들을 묶어서 **Layer** 라고 한다.\n",
    "- 목적은 우리가 수집한 train 데이터셋을 이용해 **정확한 예측을 위한 weight와 bias 들**을 찾는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataset\n",
    "- Train data는 feature(input)와 target(output) 각각 2개의 행렬로 구성한다.\n",
    "- Feature의 행은 관측치(개별 데이터)를 열을 Feature(특성, 변수)를 표현한다. 이 문제에서는 `온도, 강수량, 습도` 세개의 변수를 가진다.\n",
    "- Target은 모델이 예측할 대상으로 행은 개별 관측치, 열은 각 항목에 대한 정답으로 구성한다. 이 문제에서 예측할 항목은 `사과수확량, 오렌지 수확량` 2개의 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  input: 생산환경 (temp, rainfall, humidity) : (5, 3)\n",
    "environs = [\n",
    "    [73, 67, 43], \n",
    "    [91, 88, 64], \n",
    "    [87, 134, 58], \n",
    "    [102, 43, 37], \n",
    "    [69, 96, 70]\n",
    "]\n",
    "\n",
    "# Targets: 생산량 - (apples, oranges) - (5, 2)\n",
    "apple_orange_output = [\n",
    "    [56, 70], \n",
    "    [81, 101], \n",
    "    [119, 133], \n",
    "    [22, 37], \n",
    "    [103, 119]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]), torch.Size([5, 2]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Dataset을 torch.Tensor로 생성\n",
    "X = torch.tensor(environs, dtype=torch.float32)\n",
    "y = torch.tensor(apple_orange_output, dtype=torch.float32)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m13 packages\u001b[0m \u001b[2min 48ms\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m numpy \u001b[2m(12.2MiB)\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m numpy\n",
      "\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 556ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m13 packages\u001b[0m \u001b[2min 3.90s\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==12.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.15.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73.,  67.,  43.],\n",
       "        [ 91.,  88.,  64.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weight와 bias\n",
    "- weight: 각 feature들이 생산량에 영향을 주었는지의 가중치로 feature에 곱해줄 값.\n",
    "    - 사과, 오렌지의 생산량을 구해야 하므로 가중치가 두개가 된다.\n",
    "    - weight의 shape: `(3, 2)`\n",
    "- bias는 모든 feature들이 0일때 생산량이 얼마일지를 나타내는 값으로 feature와 weight간의 가중합 결과에 더해줄 값이다.\n",
    "    - 사과, 오렌지의 생산량을 구하므로 bias가 두개가 된다.\n",
    "    - bias의 shape: `(2, )`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression model\n",
    "모델은 weights `w`와 inputs `x`의 내적(dot product)한 값에 bias `b`를 더하는 함수.\n",
    "\n",
    "$$\n",
    "\\hspace{2.5cm} X \\hspace{1.1cm} \\cdot \\hspace{1.2cm} W \\hspace{1.2cm}  + \\hspace{1cm} b \\hspace{2cm}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left[ \\begin{array}{cc}\n",
    "73 & 67 & 43 \\\\\n",
    "91 & 88 & 64 \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "69 & 96 & 70\n",
    "\\end{array} \\right]\n",
    "%\n",
    "\\cdot\n",
    "%\n",
    "\\left[ \\begin{array}{cc}\n",
    "w_{11} & w_{21} \\\\\n",
    "w_{12} & w_{22} \\\\\n",
    "w_{13} & w_{23}\n",
    "\\end{array} \\right]\n",
    "%\n",
    "+\n",
    "%\n",
    "\\left[ \\begin{array}{cc}\n",
    "b_{1} & b_{2} \\\\\n",
    "b_{1} & b_{2} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "b_{1} & b_{2} \\\\\n",
    "\\end{array} \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "$w_{11},\\,w_{12},\\,w_{13}$: 사과 생산량 계산시 각 feature들(생산환경)에 곱할 가중치   <br>\n",
    "$w_{21},\\,w_{22},\\,w_{23}$: 오렌지 생산량 계산시 각 feature들(생산환경)에 곱할 가중치    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/kgmyhGit/image_resource/main/deeplearning/figures/3_unit_layer.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight/bias 를 정의 -> 초기값은 random 값을 이용해서 생성.\n",
    "weight = torch.randn(3, 2, requires_grad=True)\n",
    "bias = torch.randn(2, requires_grad=True)\n",
    "\n",
    "weight.size(), bias.size()\n",
    "# weight: (3:input feature개수  ,  2:output 개수)\n",
    "# bias  : (2:output 개수, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2174,  0.5123],\n",
       "        [ 0.3846, -0.3597],\n",
       "        [-0.0671, -0.4833]], requires_grad=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2495, -0.4627], requires_grad=True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73.,  67.,  43.],\n",
       "        [ 91.,  88.,  64.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한번 학습(최적화)\n",
    "## 추론\n",
    "pred = X @ weight + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  5.7630,  -7.9486],\n",
       "        [  8.5169, -16.4304],\n",
       "        [ 27.4796, -32.1259],\n",
       "        [ -9.3677,  18.4393],\n",
       "        [ 15.9728, -33.4773]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pred.size())\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9543.7471, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loss 계산(MSE)\n",
    "loss = torch.mean((pred - y)**2) # 전체 추론한 결과의 평균오차를 계산.\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss를 가지고 파라미터들(weight들, bias들)의 gradient 계산.\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2174,  0.5123],\n",
       "        [ 0.3846, -0.3597],\n",
       "        [-0.0671, -0.4833]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -5485.9819,  -8631.2988],\n",
       "        [ -6342.3081, -10623.8477],\n",
       "        [ -3871.9595,  -6360.9590]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.2495, -0.4627]), tensor([ -66.5271, -106.3086]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.data, bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 업데이트\n",
    "lr = 0.00001\n",
    "weight.data = weight.data - lr * weight.grad\n",
    "bias.data = bias.data - lr * bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1625,  0.5986],\n",
       "        [ 0.4480, -0.2535],\n",
       "        [-0.0284, -0.4197]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2489, -0.4616])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 업데이트된 파라미터로 추정 -> loss 계산\n",
    "pred2 = X @ weight + bias\n",
    "loss2 = torch.mean((pred2 - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9543.7470703125 6691.7646484375\n"
     ]
    }
   ],
   "source": [
    "print(loss.item(), loss2.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.randn(3, 2, requires_grad=True)\n",
    "bias = torch.randn(2, requires_grad=True)\n",
    "\n",
    "## 모델 정의\n",
    "def model(X):\n",
    "    return X @ weight + bias\n",
    "\n",
    "## loss 함수(MSE)\n",
    "def loss_fn(pred, y):\n",
    "    return torch.mean((pred - y)**2) # 전체 오차의 평균."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0001/5000] - 21877.03516\n",
      "[0101/5000] - 307.67975\n",
      "[0201/5000] - 171.04639\n",
      "[0301/5000] - 118.33372\n",
      "[0401/5000] - 91.61832\n",
      "[0501/5000] - 74.22965\n",
      "[0601/5000] - 61.14329\n",
      "[0701/5000] - 50.66256\n",
      "[0801/5000] - 42.07299\n",
      "[0901/5000] - 34.97640\n",
      "[1001/5000] - 29.09731\n",
      "[1101/5000] - 24.22213\n",
      "[1201/5000] - 20.17823\n",
      "[1301/5000] - 16.82346\n",
      "[1401/5000] - 14.04033\n",
      "[1501/5000] - 11.73142\n",
      "[1601/5000] - 9.81581\n",
      "[1701/5000] - 8.22664\n",
      "[1801/5000] - 6.90820\n",
      "[1901/5000] - 5.81437\n",
      "[2001/5000] - 4.90693\n",
      "[2101/5000] - 4.15409\n",
      "[2201/5000] - 3.52951\n",
      "[2301/5000] - 3.01134\n",
      "[2401/5000] - 2.58146\n",
      "[2501/5000] - 2.22482\n",
      "[2601/5000] - 1.92892\n",
      "[2701/5000] - 1.68346\n",
      "[2801/5000] - 1.47981\n",
      "[2901/5000] - 1.31085\n",
      "[3001/5000] - 1.17069\n",
      "[3101/5000] - 1.05440\n",
      "[3201/5000] - 0.95793\n",
      "[3301/5000] - 0.87789\n",
      "[3401/5000] - 0.81149\n",
      "[3501/5000] - 0.75641\n",
      "[3601/5000] - 0.71071\n",
      "[3701/5000] - 0.67278\n",
      "[3801/5000] - 0.64133\n",
      "[3901/5000] - 0.61523\n",
      "[4001/5000] - 0.59358\n",
      "[4101/5000] - 0.57562\n",
      "[4201/5000] - 0.56071\n",
      "[4301/5000] - 0.54836\n",
      "[4401/5000] - 0.53810\n",
      "[4501/5000] - 0.52959\n",
      "[4601/5000] - 0.52253\n",
      "[4701/5000] - 0.51668\n",
      "[4801/5000] - 0.51181\n",
      "[4901/5000] - 0.50779\n",
      "[5000/5000] - 0.50447\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "lr = 0.00001  # 1e-5\n",
    "for epoch in range(epochs):\n",
    "    # 1. 추론\n",
    "    pred = model(X)\n",
    "    \n",
    "    # 2. loss 계산\n",
    "    loss = loss_fn(pred, y)\n",
    "    # 3. 파라미터 들의 gradient 계산\n",
    "    loss.backward()\n",
    "    # 4. 파라미터 업데이트\n",
    "    weight.data = weight.data - lr * weight.grad\n",
    "    bias.data = bias.data - lr * bias.grad\n",
    "    # 5. gradient 초기화\n",
    "    weight.grad = None\n",
    "    bias.grad = None\n",
    "    ## 100 epoch, 마지막 epoch에서 loss를 출력 => 학습 과정 log를 출력\n",
    "    if epoch % 100 == 0 or epoch == epochs-1:\n",
    "        print(f\"[{epoch+1:04d}/{epochs}] - {loss.item():.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 보면 처음에는 개선량이 큰데, 점점 줄어듬. 첫 값이 랜덤값이라서."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3941, -0.2769],\n",
       "         [ 0.8493,  0.8004],\n",
       "         [ 0.6883,  0.9120]]),\n",
       " tensor([-0.6791, -2.7750]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weight.data, bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.0546,  69.8592],\n",
       "        [ 82.2513, 100.8372],\n",
       "        [118.7677, 133.2930],\n",
       "        [ 21.1116,  37.1464],\n",
       "        [101.8461, 118.8047]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 데이터로 추론\n",
    "p = model(X)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x = torch.tensor([68, 82, 56], dtype=torch.float32)\n",
    "new_x = new_x.unsqueeze(dim=0)\n",
    "new_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 57.0546,  69.8592],\n",
      "        [ 82.2513, 100.8372],\n",
      "        [118.7677, 133.2930],\n",
      "        [ 21.1116,  37.1464],\n",
      "        [101.8461, 118.8047]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model(new_x)\n",
    "    \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch built-in 모델을 사용해 Linear Regression 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [[73, 67, 43], \n",
    "     [91, 88, 64], \n",
    "     [87, 134, 58], \n",
    "     [102, 43, 37], \n",
    "     [69, 96, 70]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor(\n",
    "    [[56, 70], \n",
    "    [81, 101], \n",
    "    [119, 133], \n",
    "    [22, 37], \n",
    "    [103, 119]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.Linear\n",
    "Pytorch는 torch.nn.Linear 클래스를 통해 Linear Regression 모델을 제공한다.  \n",
    "torch.nn.Linear에 입력 feature의 개수와 출력 값의 개수를 지정하면 random 값으로 초기화한 weight와 bias들을 생성해 모델을 구성한다.\n",
    "- `torch.nn.Linear(input feature의 개수 , output 값의 개수)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer와 Loss 함수 정의\n",
    "- **Optimizer**: 계산된 gradient값을 이용해 파라미터들을 업데이트 하는 함수\n",
    "- **Loss 함수**: 정답과 모델이 예측한 값사이의 차이(오차)를 계산하는 함수.\n",
    "  - 모델을 최적화하는 것은 이 함수의 값을 최소화하는 것을 말한다. \n",
    "- `torch.optim` 모듈에 다양한 Optimizer 클래스가 구현되있다.\n",
    "- `torch.nn` 또는 `torch.nn.functional` 모듈에 다양한 Loss 함수가 제공된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1114] DLL 초기화 루틴을 실행할 수 없습니다. Error loading \"c:\\Users\\Playdata\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 선형회귀 모델을 정의. torch.nn.Linear 클래스\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      5\u001b[39m model = nn.Linear(\u001b[32m3\u001b[39m, \u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# 3: input feature 개수, 2: output 수\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\__init__.py:281\u001b[39m\n\u001b[32m    277\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    279\u001b[39m         kernel32.SetErrorMode(prev_error_mode)\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Libraries can either be in\u001b[39;00m\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# path/nvidia/lib_folder/lib or\u001b[39;00m\n\u001b[32m    288\u001b[39m     \u001b[38;5;66;03m# path/nvidia/cuXX/lib (since CUDA 13.0) or\u001b[39;00m\n\u001b[32m    289\u001b[39m     \u001b[38;5;66;03m# path/lib_folder/lib\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\__init__.py:264\u001b[39m, in \u001b[36m_load_dll_libraries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    260\u001b[39m     err = ctypes.WinError(last_error)\n\u001b[32m    261\u001b[39m     err.strerror += (\n\u001b[32m    262\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m Error loading \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m or one of its dependencies.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    263\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    266\u001b[39m     is_loaded = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: [WinError 1114] DLL 초기화 루틴을 실행할 수 없습니다. Error loading \"c:\\Users\\Playdata\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "# 선형회귀 모델을 정의. torch.nn.Linear 클래스\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Linear(3, 2)  # 3: input feature 개수, 2: output 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4063,  0.4480, -0.0565],\n",
       "        [ 0.3550,  0.5531,  0.5037]], requires_grad=True)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.2737, -0.0201], requires_grad=True)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 함수\n",
    "loss_fn = torch.nn.MSELoss()  # 클래스\n",
    "# loss_fn = torch.nn.functional.mse_loss # 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4063,  0.4480, -0.0565],\n",
      "        [ 0.3550,  0.5531,  0.5037]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2737, -0.0201], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for a in model.parameters():\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer (torch.optim 모듈에 정의): weight.data = weight.data - lr * weight.grad\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), # 최적화 대상 파라미터들을 model에서 조회해서 전달.\n",
    "    lr = 0.00001,       # Learning Rage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.4063,  0.4480, -0.0565],\n",
       "         [ 0.3550,  0.5531,  0.5037]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2737, -0.0201], requires_grad=True)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0001/5000] - 557.4327392578125\n",
      "[0101/5000] - 143.0001220703125\n",
      "[0201/5000] - 55.01811981201172\n",
      "[0301/5000] - 27.855144500732422\n",
      "[0401/5000] - 18.180072784423828\n",
      "[0501/5000] - 13.762025833129883\n",
      "[0601/5000] - 11.109319686889648\n",
      "[0701/5000] - 9.192716598510742\n",
      "[0801/5000] - 7.682383060455322\n",
      "[0901/5000] - 6.451747894287109\n",
      "[1001/5000] - 5.43704891204834\n",
      "[1101/5000] - 4.597002983093262\n",
      "[1201/5000] - 3.900576114654541\n",
      "[1301/5000] - 3.3229355812072754\n",
      "[1401/5000] - 2.843738317489624\n",
      "[1501/5000] - 2.446216344833374\n",
      "[1601/5000] - 2.1164069175720215\n",
      "[1701/5000] - 1.8427997827529907\n",
      "[1801/5000] - 1.6157970428466797\n",
      "[1901/5000] - 1.4274770021438599\n",
      "[2001/5000] - 1.2712451219558716\n",
      "[2101/5000] - 1.1416248083114624\n",
      "[2201/5000] - 1.0340931415557861\n",
      "[2301/5000] - 0.9448819160461426\n",
      "[2401/5000] - 0.8708664774894714\n",
      "[2501/5000] - 0.8094626665115356\n",
      "[2601/5000] - 0.7585242986679077\n",
      "[2701/5000] - 0.7162575721740723\n",
      "[2801/5000] - 0.6811956167221069\n",
      "[2901/5000] - 0.6521039009094238\n",
      "[3001/5000] - 0.6279724836349487\n",
      "[3101/5000] - 0.6079555749893188\n",
      "[3201/5000] - 0.5913448333740234\n",
      "[3301/5000] - 0.5775630474090576\n",
      "[3401/5000] - 0.5661278367042542\n",
      "[3501/5000] - 0.5566437244415283\n",
      "[3601/5000] - 0.5487756133079529\n",
      "[3701/5000] - 0.5422459244728088\n",
      "[3801/5000] - 0.5368295311927795\n",
      "[3901/5000] - 0.5323388576507568\n",
      "[4001/5000] - 0.5286116600036621\n",
      "[4101/5000] - 0.5255199670791626\n",
      "[4201/5000] - 0.522953987121582\n",
      "[4301/5000] - 0.5208247303962708\n",
      "[4401/5000] - 0.5190576314926147\n",
      "[4501/5000] - 0.517592191696167\n",
      "[4601/5000] - 0.5163769721984863\n",
      "[4701/5000] - 0.5153724551200867\n",
      "[4801/5000] - 0.5145305395126343\n",
      "[4901/5000] - 0.5138367414474487\n",
      "[5000/5000] - 0.5132665634155273\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 추론\n",
    "    pred = model(inputs)  \n",
    "    # loss 계산\n",
    "    loss = loss_fn(pred, targets) # torch.nn.functional.mse_loss(pred, targets) # (모델추정값, 정답)\n",
    "    # gradient 계산\n",
    "    loss.backward()\n",
    "    # 파라미터 업데이트: optimizer.step()\n",
    "    optimizer.step() # optimizer가 weight.data = weight.data - lr * weight.grad 이걸 해줌.\n",
    "    # 파라미터 초기화 \n",
    "    optimizer.zero_grad() # optimizer가 w.grad=None, b.grad=None 를 해줌.\n",
    "    # 현재 epoch 학습 결과를 log로 출력\n",
    "    if epoch % 100 == 0 or epoch == epochs-1:\n",
    "        print(f\"[{epoch+1:04d}/{epochs}] - {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 => gradient 계산을 할 필요가 없다. ==> grad_fn을 만들 필요가 없다. 그래서 torch.no_grad() 블록에서 추론 작업을 실행한다.\n",
    "with torch.no_grad():\n",
    "    pred = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.1243,  70.3083],\n",
       "        [ 82.1908, 100.6456],\n",
       "        [118.7946, 133.0155],\n",
       "        [ 21.1137,  37.0316],\n",
       "        [101.8191, 119.0809]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 로직을 함수 구현\n",
    "def train(inputs, targets, epochs, model, loss_fn, optimizer):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # 추론\n",
    "        pred = model(inputs)\n",
    "        # loss 계산\n",
    "        loss = loss_fn(pred, targets) # torch.nn.functional.mse_loss(pred, targets) # (모델추정값, 정답)\n",
    "        # gradient 계산\n",
    "        loss.backward()\n",
    "        # 파라미터 업데이트: optimizer.step()\n",
    "        optimizer.step()\n",
    "        # 파라미터 초기화 w.grad=None, b.grad=None\n",
    "        optimizer.zero_grad()\n",
    "        # 현재 epoch 학습 결과를 log로 출력\n",
    "        if epoch % 100 == 0 or epoch == epochs-1:\n",
    "            print(f\"[{epoch+1:04d}/{epochs}] - {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train(inputs, targets, 5000, model, nn.functional.mse_loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
