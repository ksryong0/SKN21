{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a428c5a3",
   "metadata": {},
   "source": [
    "# naver_movie_commot_classifier/nsmc.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20daec17",
   "metadata": {},
   "source": [
    "네이버영화 댓글 감성분석\n",
    "\n",
    "- https://github.com/e9t/nsmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf66f55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.10.19 environment at: c:\\Users\\Playdata\\Documents\\SKN21\\08_NLP-자연어처리\\.venv4\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m15 packages\u001b[0m \u001b[2min 111ms\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m scipy \u001b[2m(39.3MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m scikit-learn \u001b[2m(8.5MiB)\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m scikit-learn\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m scipy\n",
      "\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 1.61s\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m13 packages\u001b[0m \u001b[2min 690ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.11.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.2.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.15.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install requests pandas scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b1b6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.10.19 environment at: c:\\Users\\Playdata\\Documents\\SKN21\\08_NLP-자연어처리\\.venv4\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m5 packages\u001b[0m \u001b[2min 102ms\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m kiwipiepy \u001b[2m(2.4MiB)\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m kiwipiepy\n",
      "\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 196ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 31ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkiwipiepy\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkiwipiepy-model\u001b[0m\u001b[2m==0.22.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install kiwipiepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c46c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/e9t/nsmc/refs/heads/master/ratings.txt\"\n",
    "res = requests.get(url)\n",
    "if res.status_code == 200:\n",
    "    str_id = StringIO(res.text) # 메모리의 문자열(str)으로부터 값을 읽을 수 있는 InputStream\n",
    "    df = pd.read_csv(str_id, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba66658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecc5f960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        200000 non-null  int64 \n",
      " 1   document  199992 non-null  object\n",
      " 2   label     200000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e4ee7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    100000\n",
       "0    100000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2cedfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    8\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f7e784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 제거\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a94fd250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, document, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복된 댓글(document) 확인\n",
    "df[df.duplicated(subset=[\"document\"], keep=False)].sort_values('document')\n",
    "# keep : False - 모든 중복행들을 True, \"first\", \"last\" (중복된 것들 중 첫번째/마지막 것만 True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1446cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복된 댓글이 있는 행은 하나만 남기고 제거\n",
    "df = df.drop_duplicates(subset='document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ceadfe3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194543, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa719606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b47eec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.10.19 environment at: c:\\Users\\Playdata\\Documents\\SKN21\\08_NLP-자연어처리\\.venv4\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m5 packages\u001b[0m \u001b[2min 81ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 33ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkiwipiepy\u001b[0m\u001b[2m==0.22.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install kiwipiepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce3421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "apt-get update\n",
    "apt-get install g++ openjdk-8-jdk python-dev pyhon3-dev\n",
    "pip3 install jpype1\n",
    "pip3 install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a8d7eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31merror:\u001b[0m unrecognized subcommand '\u001b[33mapt-get\u001b[0m'\n",
      "\n",
      "\u001b[1m\u001b[32mUsage:\u001b[0m \u001b[1m\u001b[36muv\u001b[0m \u001b[36m[OPTIONS]\u001b[0m \u001b[36m<COMMAND>\u001b[0m\n",
      "\n",
      "For more information, try '\u001b[1m\u001b[36m--help\u001b[0m'.\n"
     ]
    }
   ],
   "source": [
    "!uv apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d659337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env JAVA_HOME \"/usr/lib/jvm/java-8-openjdk-amd64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc60e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 댓글 토큰화 처리 클래스\n",
    "# 1. 다운로드\n",
    "# 2. 기본적인 전처리 진행\n",
    "# 3. 형태소기반 토큰화 진행\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "class NSMCTokenizer:\n",
    "\n",
    "    def __init__(self, save_path:str):\n",
    "        # save_path : 데이터셋 다운 후 저장할 디렉토리 경로.\n",
    "        self.kiwi = Kiwi(num_workers=-1) # num_works: 병렬처리 시 사용할 cpu 개수. -1 : 모두\n",
    "\n",
    "        # nsmc 데이터셋을 loading - load_nsmc_dataset() 메소드 이용\n",
    "        df = self.load_nsmc_dataset(save_path)\n",
    "\n",
    "        # 전처리 + 형태소 기반 토큰화\n",
    "        self.nsmc_df = self.preprecess(df)\n",
    "\n",
    "    def load_nsmc_dataset(self, save_path:str=\"data\")->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        NSMC 데이터셋을 다운받아서 저장 및 DataFrame으로 반환.\n",
    "        Args:\n",
    "            save_path: 데이터셋 csv파일을 저장할 디렉토리\n",
    "        Returns:\n",
    "            pd.DataFrame\n",
    "                네이버 영화댓글 감성분석 Dataset.\n",
    "                feature: id-댓글 ID, document: 댓글내용, label: Target(0:부정, 1:긍정)\n",
    "\n",
    "        Raise:\n",
    "            Exception: 파일을 다운받지 못하면 발생\n",
    "        \"\"\"\n",
    "        # 디렉토리 생성\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        file_path = os.path.join(save_path, 'ratings.txt')\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep='\\t', encoding='UTF-8')\n",
    "        except:\n",
    "            #Exception 발생: csv파일이 없는 경우 -> 다운로드\n",
    "            if os.path.exists(file_path): #True : 있는 파일/디렉토리, False:없다.\n",
    "                os.remove(file_path)\n",
    "                \n",
    "            url = \"https://raw.githubusercontent.com/e9t/nsmc/refs/heads/master/ratings.txt\"\n",
    "            res = requests.get(url)\n",
    "            if res.status_code == 200:\n",
    "                # file_path에 저장 후 DataFrame생성\n",
    "                with open(file_path, 'wt', encoding='utf-8') as fw:\n",
    "                    fw.write(res.text)\n",
    "\n",
    "                df = pd.read_csv(file_path, sep='\\t', encoding='utf-8')\n",
    "\n",
    "            else:\n",
    "                # 다운시 문제 발생\n",
    "                raise Exception(\"csv 파일을 다운받지 못했습니다. status 코드:\", res.status_code)\n",
    "        return df\n",
    "    def tokenize(self, doc: str) -> str:\n",
    "        \"\"\"\n",
    "        개별 댓글을 받아서 공백 처리, 토큰화 처리한 결과를 다시 string으로 만들어서 반환.\n",
    "\n",
    "        Args:\n",
    "            doc: str-처리할 댓글 문서 1개\n",
    "        Returns:\n",
    "            str - 처리 결과\n",
    "        \"\"\"\n",
    "        doc = self.kiwi.space(doc)\n",
    "        token_list = []\n",
    "        try:\n",
    "            # 토큰화: 원형(lemma)을 저장.\n",
    "            for token in self.kiwi.tokenize(doc):\n",
    "                token_list.append(token.lemma)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return ' '.join(token_list)\n",
    "    \n",
    "    def preprocess(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Dataset 전처리 + 토큰화 작업\n",
    "        전처리 : 결측치 제거, 댓글 중복데이터(중복행) 삭제\n",
    "        토큰화 : tokenize() 메소드를 이용해서 토큰화작업\n",
    "        Args :\n",
    "            df: pd.DataFrame - 전처리 대상 DataFrame\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame - 전처리 결과\n",
    "            \n",
    "        \"\"\"\n",
    "        res_df = df.dropna() #결측치 처리\n",
    "        res_df = res_df.drop_duplicates(subset=\"document\") # 중복행 제거\n",
    "        \n",
    "        # 공백 교정, 토큰화 -> tokenize()\n",
    "        res_df['document'] = res_df['document'].apply(self.tokenize)\n",
    "\n",
    "        # document에 글자수가 0인 행들 제거\n",
    "\n",
    "        res_df['document'].str.strip()\n",
    "\n",
    "        drop_idx=res_df[res_df['document'].str.strip().str.len() == 0].index\n",
    "        res_df = res_df.drop(index=drop_idx).reset_index(drop=True)\n",
    "        return res_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ffc591b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 문자열 타입 Series.str.메소드 \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# -> str accessor: Series의 원소들을 일괄처리.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# accessor: str(문자열처리), dt(일시-datatime타입 시리즈), plot: 시각화\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241m.\u001b[39mnsmc_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlen()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "# 문자열 타입 Series.str.메소드 \n",
    "# -> str accessor: Series의 원소들을 일괄처리.\n",
    "# accessor: str(문자열처리), dt(일시-datatime타입 시리즈), plot: 시각화\n",
    "a.nsmc_df['document'].str.strip().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e029a515",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Cannot open extract.mdl for WordDetector",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      2\u001b[0m s \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 4\u001b[0m nsmc \u001b[38;5;241m=\u001b[39m \u001b[43mNSMCTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m s, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m초\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m, in \u001b[0;36mNSMCTokenizer.__init__\u001b[1;34m(self, save_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, save_path:\u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# save_path : 데이터셋 다운 후 저장할 디렉토리 경로.\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkiwi \u001b[38;5;241m=\u001b[39m \u001b[43mKiwi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# num_works: 병렬처리 시 사용할 cpu 개수. -1 : 모두\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# nsmc 데이터셋을 loading - load_nsmc_dataset() 메소드 이용\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_nsmc_dataset(save_path)\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\Documents\\SKN21\\08_NLP-자연어처리\\.venv4\\lib\\site-packages\\kiwipiepy\\_wrap.py:587\u001b[0m, in \u001b[0;36mKiwi.__init__\u001b[1;34m(self, num_workers, model_path, integrate_allomorph, load_default_dict, load_typo_dict, load_multi_dict, model_type, typos, typo_cost_threshold, enabled_dialects)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`typos` should be one of (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasic\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinual\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasic_with_continual\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlengthening\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasic_with_continual_and_lengthening\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, TypoTransformer), but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypos\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    585\u001b[0m enabled_dialects \u001b[38;5;241m=\u001b[39m _convert_dialect(enabled_dialects)\n\u001b[1;32m--> 587\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintegrate_allomorph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_default_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_typo_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_multi_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrtypos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtypo_cost_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43menabled_dialects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_global_config \u001b[38;5;241m=\u001b[39m KiwiConfig(integrate_allomorph\u001b[38;5;241m=\u001b[39mintegrate_allomorph)\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_path \u001b[38;5;241m=\u001b[39m model_path\n",
      "\u001b[1;31mException\u001b[0m: Cannot open extract.mdl for WordDetector"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s = time.time()\n",
    "\n",
    "nsmc = NSMCTokenizer(\"data\")\n",
    "\n",
    "print(time.time() - s, \"초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415f9e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nsmc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnsmc\u001b[49m\u001b[38;5;241m.\u001b[39mtokenize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m이 영화는 정말 재미있다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nsmc' is not defined"
     ]
    }
   ],
   "source": [
    "nsmc.tokenize(\"이 영화는 정말 재미있다.\")\n",
    "nsmc.tokenize(\"이 시리즈는 전작보다 항상 더 잘나온다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a579b3be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nsmc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m############모델링\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# dataset 분리\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mnsmc\u001b[49m\u001b[38;5;241m.\u001b[39mnsmc_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nsmc' is not defined"
     ]
    }
   ],
   "source": [
    "############모델링\n",
    "# dataset 분리\n",
    "df = nsmc.nsmc_df.copy()\n",
    "X = df['document']\n",
    "y = df['label']\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b095ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test/validation set으로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train\n",
    ")\n",
    "\n",
    "y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f919a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# 모델 생성\n",
    "# pipleline: 전처리 - TfidfVectorizer, 모델: LogisticRegression\n",
    "########################################################################\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tiv = TfidfVectorizer()\n",
    "model = LogisticRegression()\n",
    "steps = [\n",
    "    (\"TF-IDF\", tiv),\n",
    "    (\"model\", model)\n",
    "]\n",
    "pipeline = Pipeline(steps=steps, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4693423",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dab42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = pipeline(X_valid)\n",
    "# accuracy_score(pred, y_valid)\n",
    "validation_score = pipeline.score(X_valid, y_valid)\n",
    "# 기본 metrics를 계산. 분류:accuracy, 회귀:r2_score\n",
    "validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70bb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = pipeline.score(X_train, y_train)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29abea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = pipeline.score(X_test, y_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d41ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiv = pipeline.steps[0][1]\n",
    "vocab = tiv.get_feature_names_out()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# 새로운 데이터 추론\n",
    "##################################\n",
    "def predict(pipeline, *comments):\n",
    "    # 1. 기본 전처리 - nsmc.tokenize()\n",
    "    # 2. 추론\n",
    "    pre_comment = [nsmc.tokenize(comment) for comment in comments]\n",
    "    pred = pipeline.predict(pre_comment)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffd7f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(\n",
    "    pipeline,\n",
    "    \"이영화 별로다.\",\n",
    "    \"아무 생각 없이 봤는데 시간가는줄 모르고 봤다.\",\n",
    "    \"배우들 연기가 끝내준다.\",\n",
    "    \"내 소중한 시간이....\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
