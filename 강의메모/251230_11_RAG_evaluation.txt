Naive Rag?
질문-검색 + 질문 -> 체인에 넣음 ??

질문에 대한 임베딩 벡터로 유사도 검색이 잘 안되더라
1. ?
2. 검색하기 전에 질문을 변경해봄. 멀티쿼리 리트리버, 셀프쿼리 리트리버가 이 역할.
질문을 바꿔봄
+필터링도 가능.

검색 결과가 마음에 안 들 때?
Rerank. 검색되서 나온 결과물들을 정제화해줌. 그걸 다시 LLM 체인에 넣음.
초기검색단계에서 추출된 후보 문서들의 순위를 재조정.

그래도 결과가 별로면 모델이 문제일 수도 있음.
아니면 잘못된 모델을 사용했거나?

api를 쓴다는건 LLM모델한테 쿼리를 보내서 결과를 받겠다.
chat-gpt를 쓰냐 api를 쓰냐는, 구조화된 걸 쓰냐 안쓰냐의 차이.

프롬프트로 LLM의 knowledge cutoff를 메꿀 수 있다. 그런 방법중에 하나가 RAG
------------
RAG 평가 개요

검색 단계 평가:문서는 잘 검색된건지

평가 지표

생성쪽 : answer

답변이 질문에 관련된 답변이냐? Answer relevancy

우리가 보내준 문서 안에서 답을 찾아서 주는게 RAG의 목적. 답변이 Context에서 추론할 수 있는건지. 
답변이 Context에 있는 내용인지? Faithfulness

Context가 유저 질문과 관련된 내용인지? Context Precision

Context가 정답하고 관련이 있는지? Context Recall

계산방법은 기억이 안날수도 있음.
평가 지표들을 왜 보는지. 어떤 의미인지. 어떻게 해석해야 하는지. 모델을 어떻게 개선시킬 수 있는지.

도커->컨테이너->qdrant

똑같은 프롬프트를 여러번 써도 됨.

합성 데이터셋 : 모델->데이터셋. 딥러닝 모델이 만들어준 데이터셋.

함수 A와 함수 B가 있으면
함수 A			함수 B

동기적 방식:함수 A가 끝나면 함수 B가 동작하기 시작. 함수 A와 B는 연관성은 없음. 쉬는 시간에는 기다려야 함.
비동기적 방식:함수 A하고 B하고 C하고 같이 실행시킴. 쉬는 시간이 없음. I/O. 크롤링에서 많이 사용.
너무 빨리 바뀌면 DDos하는줄 알고 IP가 막힐수도 있음. 그런게 없으면 비동기가 훨씬 빠름.


------------






