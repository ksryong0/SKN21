랭체인:선형적.
엣지:관계
노드:연산

랭그래프:조건, 분기 처리 가능. 
노드:기능(함수).
엣지:기능들을 연결해주는 흐름. 
컨디셔널엣지:조건에 따라 실행되는.

랭체인에서는 건너뛰기가 안됨.
스테이트그래프:누가 끝나면 누가 일하고. 그다음에 누가 끝나면 누가 일하고 등록함. 실행환경을 관리. 등록된 노드들과 연결된 엣지들을 바탕으로 일을 실행.
스테이트:일하는 동안 각 노드들의 데이터 공유장소. 딕셔너리로 구성됨. 
랭그래프 순서
1. State 설계(TypedDict 또는 Pydantic을 이용). 이후 State에 설계된 값만 입력 가능.
2. 노드(호출할 함수)들 정의. 일이 끝나면 스테이트에 있는 값을 리턴.
3. StateGraph 정의. dict 설계도.
add_edge에서 END는 생략 가능하지만, START는 생략 불가.
노드에서 딕셔너리로 스테이트에 리턴해야함.

START->챗봇
add_conditional_edges:조건함수

랭그래프에서 메모리 관리:세션에 대한 메모리 관리.
대화 세션 스레드:작업시작~종료.
파일에 저장도 가능.

-------------------------복습----------------------------------

HITL(Human In The Loop) : 노드들이 일을 할 때 보통은 사용자가 개입하는건 없음. 특정 시점에 노드를 일시정지 하겠다. 그러고 승인하거나 리젝트를 함. 사람의 개입.

에이젠트를 만들떄는 사람의 개입은 최소화해야함. 하지만 일 시키는건 사람이라서, 어느 시점에 확인하고 승인하거나 거절해야함.

HITL사용시점
1. 승인
2. 모호성 해결 및 명확화
프롬프트가 모호함. 
3.데이터 보정
4.정책/규제 준수 검증
5. 도구실행 전 확인
6. 피드백
1,5을 많이 사용함.

인터럽트에서 끝난거와 invoke에서 끝난거 차이:인터럽트는 멈췄던 일을 계속 할 수 있다.

message
name
age
address

next?resume했을 떄 누가 일할 것인지에 대한 정보.

나름 여러번 얘기 하심
resume했을 때 시작은 처음부터 다시 함.

툴들 중에 호텔을 검색해주는 툴도 있음.
-----------------------
멀티모달

uv pip uninstall python-magic-bin
uv pip uninstall python-magic

uv pip install python-magic-bin

uv run streamlit run app.py

C:\Users\Playdata\Documents\SKN21_2\SKN21\10_langchain\streamlit\04_multimodal\data\barchart.png
이 그래프의 내용을 분석해줘.

gpt모델은 멀티모달로 보낼 때 파일이름을 보내야 함.

-----------------------

11_1_LLM 파인튜닝 개요

파운데이션 모델:대규모 데이터로 사전학습된 범용 인공지능 모델.
이미지보다는 텍스트가 데이터가 많음. 이미지는 비슷한데, 텍스트는 나라마다 언어부터가 다름.

대규모 모델

파운데이션모델은 범용지식에 대해서는 잘 하는데, 특정 부분에 대해서는 잘 못함. 제네럴리스트 느낌.
파인튜닝:특정 부분에 대해서 최적화. 범용성이 떨어질 수 있음. 고성능 하드웨어가 필요
->양자화:모델의 크기를 줄임. 타입을 바꿔서 모델이 사용하는 메모리 크기를 줄임.

1234=1.234*10^3
가수:1.234
지수:3
floating point는 지수와 가수를 따로 저장.

근데 컴퓨터는 2진법이기 때문에 2진수로 바꿔서 저장.
지수는 값의 스케일을 가리킴. 값의 범위.
가수는 유효숫자의 갯수. 정밀도를 가리킴.
양자화해서 데이터 타입이 바뀌면 지수부가 문제가 됨. 스케일이 작아지는거니까.
->BF16이 등장:지수부를 똑같이 8로 쓰고. 가수부를 줄임. 스케일은 유지하고, 정밀도는 포기. 

!uv venv .venv --python=3.12
!uv pip install bitsandbytes transformers accelerate hf_xet tqdm ipywidgets ipykernel

Absmax Quantization:-128~127로 양자화. 변환하려는 값 중 가장 큰 값 하나를 min 또는 max에 맞춤.
다른 값들을 -128~127로 맞추겠다. 

양자화:Q=round
스케일팩터를 곱한값이 -128보다 작으면(ex:-128.6) -128로 고정
-128~127인 이유는 int8이 표현할 수 있는 숫자 범위라서.
역양자화를 할 때 양자화때 값을 반올림해서 값이 정확하게 유지되지는 않음.
메모리에 모델을 로드할 때, int8로 저장되어 있다.

양자화과정
대표값은 중앙값을 많이 쓴다.
구역을 나눠서 대표값을 지정.

0번인덱스의 값이 -0.783 이라면,
실제 값을 양자화한값이 -0.783이라면 0으로 저장.
실제 값을 절대값 max로 나누면.
인덱스와 absmax값을 같이 저장.
메모리에 올라올때 저장 용량을 줄여줌.
역양자화를 해도 대표값으로 복원되기때문에 완벽하게 원래 값으로 복원되지는 않는다.

load_in_4bit, load_in_8bit 둘다쓰면안됨. 둘다쓰면 4비트가 우선.
4bit는 bnb
8bit는 llm이라고 앞에 붙음.
이상치에 취약. 정밀도가 더 떨어짐
->그래서 이상치를 정하는 threshold로 정해줌. 이상치는 변환하지 않고 float로 그대로 둠.

----------------------

PEFT(Parameter-Efficient Fine-Tuning)
어댑터 튜닝-LoRA(LowRank Adaptation). 베이스 모델의 파라미터의 옆에 adapter 행렬을 만듬. 베이스모델의 파라미터들보다 작음. 이 adapter를 학습시켜서 비슷한 성능을 냄. 사전학습된 모델의 가중치를 동결. 얘와 연결된 lowrank adapter를 만들어서 학습시킴.

LORA

X->추론W->히든스테이트
베이스모델만 쓸수도 있고 어댑터를 같이 쓸수도 있고.
W0은 프리트레인드 파라미터.
어댑터는 크기가 작은 두 개의 행렬로 구성됨. 이걸 A와 B로 표현.
d가 256차원
W0가 d, d 행렬이다 -> d,8
A : 들어갈 때는 d이지만 나올때는 8. 작은거로 나옴.
B: 8, 256

d가 256개라고 치면
Weight : d*d=65536

장점:효율적으로 파인튜닝이 가능. 범용모델을 파인튜닝하는거보다 훨씬 빠름. 요새 가장 많이쓰는 기법.
어댑터가 모델하고 붙어있는게 아님. 어댑터와 모델을 따로 관리할 수 있음. 범용모델 자체를 건들지 않았기 때문에, 원리 잘 대답하던 애들도 잘 대답함.

r차원의 입력. 8로 많이 사용.

QLoRA : 양자화를  LoRA



