컨텍스트벡터 : Feature
인코더는 컨텍스트 벡터를 출력으로 나오고, 디코더는 최종 결과물도 나와야됨.
티쳐 포싱을 안쓰면 학습이 잘 안됨. 오래해야됨.
디코더단에서, 결과가 틀린게 나오더라도, 원래 정답을 넣어주는 거. 학습이 제대로 되도록.
티쳐 포싱을 무조건 적용하는게 아니고, 원래 순서대로도 학습시켜야함. 랜덤으로 티쳐포싱을 했다 안했다 해야함.

챗봇은 정량적인 평가보다 정성적 평가가 중요함. 항상 똑같은 대답만 함. 그래서 단어를 바꿔가는 작업을 해야함. 답이 항상 똑같이 나오는게 좋은건가? 평가하기가 어려움.

Seq2Seq의 문제
Context Vector 크기가 고정된 것. 개별적 토큰을 생성할 떄, 디코더가 인코더의 고정된 컨텍스트 벡터만 본다. 그래서 성능이 안나오는 거 같다.
->어텐션 메카니즘
인코더의 원래 단어들에 대해, 어떤 단어들에 주의를 기울여야 되는지 다시 체크. 입력토큰의 어떤 단어의 히든스테이트에 집중해야하는지 다시 체크. 문맥은 컨텍스트벡터로 볼 수 있음. 집중하거나 주의를 기울여야되는 단어는 없는지 체크.
기존 Seq2Seq, 인코더-디코더 구조에서는 컨텍스트벡터가 나오면 인코더 단의 토큰들을 볼 필요가 없었음. 전체문장에서 필요한 글자에만 집중, 기억하겠다. 


I am a boy
나는 소년 이다.

전체적인 맥락이 중요할때도 있지만, 집중해야하는 부분도 있음.

RNN-gru
나는 | 어텐션밸류(인코더의 히든스테이트들(h1 h2 h3)과 계산한 값)
