경사하강법

최적화(모델을 데이터에 맞추는 작업을 하는거. 오차 최소화가 목표)
오차계산
loss(cost) 함수
모델이 잘 예측해야 오차가 줄어듬

학습을 통해 찾아야 되는 값 -> 파라미터(weight)
세로축 cost : 오차

y^=w1x1+w2x2+...+b
w와 b를 찾아야함.

피쳐가 많아서 오버피팅발생 했을 때 해결방안
학습이 덜 되도록 규제하여 모델복잡도 낮춤.
w를 줄여서(|w|를 줄여서) 파라미터의 영향력을 낮춤. -> 오차가 줄어듬
MSE(오차)+W들 합계

피쳐가 적어서 언더피팅 발생시 해결방안
|w|를 올림. 피쳐를 늘림. 기존 피쳐를 거듭제곱함. 피쳐끼리 곱함.

L1규제(Lasso) : 

L2규제(Ridge) : 

어제배운거
----------
로지스틱회귀

선형회귀 알고리즘을 이용한 이진분류 모델.
odds함수로부터 시그모이드 함수가 만들어짐.

바이너리 크로스 엔트로피
L(W)=-1/m(

C값이 작을수록 강한 규제

로지스틱회귀 모르겠다...
-------------------
군집
x, y값으로 함수를 찾는 과정.
정답이 없으니까 평가가 어렵다.

이상치가 있으면 센터가 이상하게 잡힌다.
k-means는 fit만 하면됨. transform 필요 없음

inertia 속성?
K별로 inertia값을 조회해서, inertia가 급격히 떨어지는 지점이 적정 군집수이다.

강의자료 그래프를 보면 k 가 2->3으로 갈떄 inertia가 급격히 떨어지므로 3이 최적의 군집수라고 할 수 있다.

군집 평가지표
실루엣 계수
음수: 잘못된 그룹에 할당됨.
0 : 경계
1에 가까움 : 센터

b(i) > a(i)
b(i) = a(i) 두 군집의 경계에 있다.
--------------------------
uv pip install ipykernel


------------------------
머신러닝은 전처리가 중요. 
하지만, 전처리가 어렵다. 고양이 사진을 예를들면 고양이가 반만 나오거나, 누워있거나, 서있거나, 사람이랑 있거나, 배경이랑 있거나 등등 정해져있지 않다. 사람이보면 고양이지만, 컴퓨터가 보면 숫자임. 분류해야 되는 물체도 너무 많음.
특징벡터가 잘 들어와야 머신러닝의 성능이 좋아짐.
특징 추출기를 잘 만들기가 어렵다. 기존 머신러닝에서의 문제점임.

딥러닝은 머신이 전처리를 해줌. 사람이 하는거보다 전처리를 더 잘함. 대신 데이터가 많아야되고 시간도 많이걸림. 하지만 GPU의 발전으로 가능. 

**딥러닝은 비정형 데이터에서 성능이 좋다.**
딥러닝은 특징추출기, 분류기를 한군데 넣어버림.
딥러닝이 특징을 잘 추출하기 위한 전제조건:딥러닝은 데이터가 많아야 함. 다양한 데이터가 필요.

딥러닝은 선형회귀모델을 여러개만들어서 연결.
일종의 앙상블 구조임
x->선형회귀모델1->선형회귀모델2->선형회귀모델3
최적화알고리즘:경사하강법

사이킷런은 전체단계를 fit해서 x_train, y_train에 넣어줬는데
딥러닝 파이토치는 fit 흐름을 코드에 넣어줘야함.

gpu

driver
cuda
cudnn

uv pip install torch torchvision

torch : 파이토치 루트 모듈

import torch해서 에러났을 때.
uv pip uninstall torch torchvision
uv pip install torch==2.8 torchvision

randperm : 수동으로 데이터 섞고 싶을 때 많이 사용.

trainset->tensor
모델->파라미터(weight, bias)

데이터가 같은데(cpu? gpu?) 올라가 있어야됨.

구글 드라이브
신규->더보기->Colaboratory->설치

신규->colaboratory 클릭
주피터 랩 개발환경 제공해줌.
위에 런타임->런타임 유형변경->T4 GPU->저장
월 만원. 돈 낸만큼 씀. 10달러

squeeze() 보통 더미축 다 제거.
unsqueeze() 보통 맨앞이나 맨 뒤에 더미축 추가.