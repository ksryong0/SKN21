강사님 강조
1. 인코더-디코더
Seq2Seq2 구조 이해가 중요

2. 어텐션 구조 이해 중요
3. 트랜스포머도 중요

세세한거보다 큰 틀은 이해해야함.
각 단계에서 뭘 하는지.
코드적인거는 죽 보면 됨.
GRU이런거 몰라도됨..
--------------------------------
12. transformer

attention is all you need

기존 RNN모델의 문제점
병렬처리가 안되고, 하나씩 순차적으로 처리해야됨 -> 시간이 오래걸림
트랜스포머 레이어들을 엄청 많이 만든거를 LLM 이라고 함.

Seq2Seq의 문제
장기기억 소실. 문장이 길어지면 앞에거를 까먹음.
->어텐션으로 해결

RNN을 아예 안쓰고 어텐션 구조로 만들어서 병렬처리를 해보자 -> 트랜스포머

포지셔널 인코딩이 왜 필요한지? 사인함수 코사인함수를 왜 쓰는지?

아래 애들은 Linear임
add norm
feed forward
multi-head 어텐션

셀프어텐션에서
쿼리,키,밸류 를 왜 쓰는지

큰 틀을 먼저 이해하고 세부적인거는 나중에 찾아볼 것.

포지셔널 인코딩. 위치 인코딩?
RNN은 모델 자체가 문장이나 시계열데이터의 순서를 넣어서 계산.
트랜스포머는 모델에 통째로 집어넣어버림.
->순서가 사라져버리는 문제가 발생.
->포지셔널 인코딩으로 해결.
포지셔널 인코딩이란? 순서값을 생성하는 거.
토큰->임베딩모델->임베딩벡터(임베딩벡터에 순서값을 더해줌)
포지셔널임베딩:임베딩할때 포지셔널인코딩도 넣음
포지셔널 인코딩할때 사인함수, 코사인함수 이용.

pos:토큰의 위치
i:임베딩벡터의 몇번째 인덱스냐.
사인-코사인 함수 쓰는 이유:주기함수의 문제. 똑같은 값이 나옴. 순서를 구별할 수 없음.
사인함수와 코사인 함수를 같이 씀. 사인함수.
인덱스
(0	1)		(2	3)		(4	5)
사인	코사인	사인	코사인	사인	코사인

멀티헤드어텐션 또는 셀프어텐션. 셀프 생략하기도 함.

Seq2Seq 어텐션에서는 디코더가 문장을 만들때, 인코더의 특성값을 확인. 디코더가 인코더의 히든스테이트에 대해 어텐션. 

트랜스포머에서는 인코더가 자기꺼로 들어온거에 대해 어텐션하므로 셀프어텐션이라고 함.

트랜스포머 레이어도 피쳐 찾는거임. 출력값은 피쳐값.

나는 소년 이다.->트랜스포머에 들어감->피쳐 벡터 추출
추출하는 목적에 따라 결과값이 달라짐.

어텐션을 자기 자신하고 함. 한 단어가 자기가 속한 문장과 어떤 관계가 있는지 어텐션을 함.

X*w1
X*w2
X*w3
다른 가중치. 
쿼리 키 밸류.
쿼리 키 행렬곱->스케일링->마스크(옵션. 패딩처리)->소프트맥스->밸류랑 소프트맥스를 행렬곱.
쿼리 키는 attn-weight를 계산하려고 이용됨.
밸류는 input embedding(현재문장).

원래 문장에 어텐션 웨이트를 곱해줌.
피쳐 벡터를 만들 때 어텐션 웨이트를 행렬곱 함.
결과는 문장의 특성값.

왜 셀프 어텐션이냐?
어텐션 웨이트를 만들 때, key와 쿼리를 씀.
컨텍스트 벡터 추출시 key 쿼리 계산한거에 밸류를 이용.
키 쿼리 밸류를 문장 하나로 만듬. 자기 자신으로 만든다.
어디에 집중해야하는지 계산해서 컨텍스트 벡터를 뽑아냄.
셀프 어텐션(Q,K,V) = Context Vector

쿼리 키 밸류가 3개씩 있음
문장에 대한 특성값

어텐션 웨이트는 먼저 어텐션 스코어를 계산.

어텐션스코어
쿼리 키 내적. 

어텐션스코어에 소프트맥스를 씌움. 
4. attention value
Value:

왜 멀티헤드냐?여러개로 쪼개서 만들겠다. K Q V를 쪼갬. 쪼개서 계산해서 다시 붙임.
쪼개는 이유? 여러관점에서 정보를 추출할 수 있다.
쪼갰을 때 나머지가 생기면 안됨.

마스크드 어텐션
디코더는 원래 문장을 만드는게 목적.한번에 만날수가없음.

마이너스 무한대로 바꾸는 이유. 소프트맥스 넣으면 0으로 바뀌니까.
디코더는 코잘마스크? 미래 토큰 정보 차단. 오토 리그레시브 관계
문장이 하나씩 추가됨->하나의 토큰이 만들어졌을 때, 문장 구성하는

어텐션스코어 관계를 만들기 위해?

markdown perview mermaid support 

extension 설치:머메이드?
markdown 

쫙 늘렸다가 다시 줄여서 내보냄.

FFN
피드포워드에 따로따로 처리.
각 토큰이 512개 차원. 토큰별로 처리를 따로.
개별적인 단어의 특성을 찾아보자.
포인트와이즈:하나씩 개별적으로 처리

멀티헤드어텐션 후 add.
Norm(Layer Normalization):행 단위로 함. 자연어에서는 문장 단위 정규화.

배치 노말라이제이션:컬럼별로 정규화를 함.
스킵커넥션
레지듀얼 커넥션

레이어 쌓는거에 한계가 있음. 20개정도는 개선됨. 넘어가면 오히려 성능이 떨어짐. trainset 성능이 떨어짐.
레지넷:이미지 경진대회. 105개 레이어를 쌓음. 그레디언트 배니싱 해결해줌. 숫자가 작아지면 다시 증폭시킴. 

Fine Tuning:학습한 데이터로 재학습시키는게 성능면에서 좋으니까.
LLM은 파인 튜닝 자체가 물리적으로 불가능. GPT4점대부터는 LLM의 파라미터가 조 단위.

제로샷 전이학습 : LLM에서 사용? 있는거 그대로 씀
전이학습 : 추출기는 그대로 쓰고, 추론기만 새로 만들어서 학습.
------------------
허깅페이스 알아둬야할것! 강사님 강조!

프리트레인드 모델이 무엇인지 왜 이용해야되는지. 방식 세가지가 무엇이고 어떤건지.
--------------------
