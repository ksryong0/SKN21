정형 데이터 : 이메일
비정형 데이터 : 음성, 자연어

전통적 방식
데이터				-> 컴퓨터	-> 결과
프로그램(함수, 알고리즘)

머신러닝
데이터				-> 컴퓨터	-> 프로그램(알고리즘, 모델, 규칙)
결과

x	->	y의 예측 값

정확도가 다른 이유 : 데이터셋이 랜덤값으로 들어가기 때문에. 사람마다 컴퓨터마다 다름.

데이터셋

학습데이터셋->모델 <-평가할 데이터셋
				- 검증(validation) 데이터 셋
				- 테스트 데이터 셋

b(하이퍼파라미터 : 사람이 직접 지정) * x + a(데이터를 통해 찾음)

fit은 자동으로 학습

사람이 수동으로 모델을 바꿔서 학습
두번째 학습->평가 및 검증
		테스트값 보니 만약 값이 좋아짐 -> 하지만 성능 업그레이드가 더필요 -> 반복 -> 원하는 성능 나옴->그럼 그걸 쓰면 됨

최종평가시 모델 업그레이드 전의 테스트 데이터(validation set)가 필요.
trainset으로 테스트하고 validation set으로 검증. trainset 수정하고 반복.

토이데이터셋 : 사이킷런에서 제공하는 연습용 데이터 셋
모집단 비율대로 테스트셋과 validation set의 데이터 비율을 설정.

a*x + b
a(하이퍼 파라미터 : 사람이 임의로 바꾸면서 넣어주는 값)

머신러닝에서 하이퍼파라미터 정할 때, 일단 그냥 해봄. 경험적으로..
모델링을 아트라고 부름.

나중에 validation set과 train set도 비교해봄.
train set하고 val set이 비슷한게 가장 좋음.
train set과 validation set 중에는 validation set의 값이 더 좋은(높은)게 좋음.
train set > val set : 과대적합. 안좋은거.

전체적 데이터 수가 작으면, 값이 1만 바뀌어도 accuracy 차이가 크다. 실제적으로는 안큰데.

val set과 test set 두 가지로 나눠서 테스트하는 이유?

데이터 양이 적을 때, 이상치가 한쪽으로 다 몰리고, train set과 val set이 정상적으로 몰리면, 성능이 아주 좋은거로 결과가 나와버림.
데이터 양이 많아야함.

K-겹
모든 폴드가 한번씩은 트레이닝이 되도록.
하나씩 모든 데이터를 10번 학습.

y값이 연속->Kfold
y값이 범위. 분류->StratifiedKFold

보스턴->회귀문제->

KFold(n_splits=K
K : 몇개로 나늘지

리스트, 튜플:값을 들고있다가 줌
제너레이터:값을 제공하는 알고리즘, 로직만 갖고있음. 값을 안갖고 있음. 예)range함수. 얘는 값을 안갖고있음.

구현부에 yield가 들어가면 제너레이터. yield는 리턴같은 애임. 연결되서 일함
yield 1하면 1로 리턴되는데, 여기서 다시 그 함수를 실행하면 yield 1 다음부터 다시 실행됨. 함수랑 다르게 유지.
위와 같은 흐름을 코루틴이라고 함.

함수
메인루틴->함수 실행->메인루틴

코루틴
메인함수->함수실행->중간결과->메인함수->함수실행->중간결과 밑에줄부터 다시 실행->중간결과2

제너레이터가 하나의 객체로 생각.

회귀는 얼마나 적게 틀리냐.
이름이 중요,

MSE(Mean Square Error)는 작을수록 좋다. 정확도는 클수록 좋다.

train valid test 를 왜 분리하는지?

Hold out->Data 양이 많을수록 좋음?
K-F Cross Validation
- KFold, Stratified K Fold(분류)
cross_val_score
cross_validate

데이터 전처리 : 모델의 성능에 영향을 가장 많이 줌. 학습을 위한 데이터로 정제. 

s.fit() : 
s.transform : 
fit_transform : fit 하고 transform함.

유클리드 디스턴스:두 점 사이의 거리. (a-b)^2 를 루트씌움.
